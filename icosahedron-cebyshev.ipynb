{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "574efd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from numpy.linalg import norm\n",
    "import os\n",
    "from scipy.linalg import eigh, qr, null_space, norm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from scipy.sparse import eye, kron, identity, csr_matrix, csc_matrix, lil_matrix, dok_matrix, issparse, coo_matrix\n",
    "from scipy.sparse.linalg import eigsh, eigs, lobpcg, LinearOperator, ArpackNoConvergence\n",
    "from scipy.optimize import curve_fit\n",
    "from qutip import Qobj, ptrace, entropy_vn, qeye, tensor\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import sympy as sp\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f949390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauli_x():\n",
    "    \"\"\"Pauli X matrix.\"\"\"\n",
    "    return np.array([[0, 1], [1, 0]])\n",
    "\n",
    "def pauli_z():\n",
    "    \"\"\"Pauli Z matrix.\"\"\"\n",
    "    return np.array([[1, 0], [0, -1]])\n",
    "\n",
    "def icosahedral_bonds(): #12 vertices\n",
    "    \"\"\"\n",
    "    Defines the connectivity of a true 12-vertex icosahedral molecular structure.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple (i, j) represents a bond between spin i and spin j.\n",
    "    \"\"\"\n",
    "    bonds = [\n",
    "        (0, 2), (0, 4), (0, 5), (0, 8), (0, 9),\n",
    "        (1, 3), (1, 6), (1, 7), (1, 10), (1, 11),\n",
    "        (2, 6), (2, 7), (2, 8), (2, 9), (3, 4),\n",
    "        (3, 5), (3, 10), (3, 11), (4, 5), (4, 8),\n",
    "        (4, 10), (5, 9), (5, 11), (6, 7), (6, 8),\n",
    "        (6, 10), (7, 9), (7, 11), (8, 10), (9, 11)\n",
    "    ]\n",
    "    return bonds\n",
    "\n",
    "\n",
    "def transverse_field_ising_icosahedral(N, J, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an icosahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the icosahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 12:\n",
    "        raise ValueError(\"Icosahedral molecules typically have N = 12 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get icosahedral bonds\n",
    "    bonds = icosahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for icosahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def ising_icosahedron(N, J):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an icosahedral molecular structure without transverse field.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the icosahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        \"\"\"\n",
    "    if N != 12:\n",
    "        raise ValueError(\"Icosahedral molecules typically have N = 12 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get icosahedral bonds\n",
    "    bonds = icosahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for icosahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def transverse_field_icosahedral(N, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an icosahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the icosahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 12:\n",
    "        raise ValueError(\"Icosahedral molecules typically have N = 12 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get icosahedral bonds\n",
    "    bonds = icosahedral_bonds()\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "'''\n",
    "def partial_trace_qubit(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits.\"\"\"\n",
    "    keep_dims = np.prod([dims[i] for i in keep])\n",
    "    trace_dims = np.prod([dims[i] for i in range(len(dims)) if i not in keep])\n",
    "    rho = rho.reshape([keep_dims, trace_dims, keep_dims, trace_dims])\n",
    "    return np.trace(rho, axis1=1, axis2=3).reshape([keep_dims, keep_dims])\n",
    "\n",
    "def partial_trace_qubit_torch(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits using PyTorch.\"\"\"\n",
    "    keep_dims = torch.prod(torch.tensor([dims[i] for i in keep]))\n",
    "    trace_dims = torch.prod(torch.tensor([dims[i] for i in range(len(dims)) if i not in keep]))\n",
    "    rho = rho.view(keep_dims, trace_dims, keep_dims, trace_dims)\n",
    "    # Compute the partial trace\n",
    "    traced_rho = torch.zeros((keep_dims, keep_dims), dtype=rho.dtype)\n",
    "    for i in range(trace_dims):\n",
    "        traced_rho += rho[:, i, :, i]\n",
    "    #return traced_rho.view(keep_dims, keep_dims)\n",
    "    return traced_rho'''\n",
    "\n",
    "def isket_numpy(arr):\n",
    "    \"\"\"\n",
    "    Check if a NumPy array is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: np.ndarray, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(\"Input must be a NumPy array\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_numpy(Q, sel, dims): # numpy function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using NumPy.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: numpy object, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - numpy object, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = np.asarray(dims[0], dtype=np.int32).ravel()\n",
    "    nd = len(rd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = np.array([sel])\n",
    "    else:\n",
    "        sel = np.asarray(sel)\n",
    "    sel = list(np.sort(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = (rd[sel]).tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(np.arange(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = (rd[qtrace]).tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = list(rd)\n",
    "    if isket_numpy(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        vmat = (Q\n",
    "                .reshape(rd)\n",
    "                .transpose(sel + qtrace)\n",
    "                .reshape([np.prod(dkeep), np.prod(dtrace)]))\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat.dot(vmat.conj().T)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        rhomat = np.trace(Q\n",
    "                          .reshape(rd + rd)\n",
    "                          .transpose(qtrace + [nd + q for q in qtrace] +\n",
    "                                     sel + [nd + q for q in sel])\n",
    "                          .reshape([np.prod(dtrace),\n",
    "                                    np.prod(dtrace),\n",
    "                                    np.prod(dkeep),\n",
    "                                    np.prod(dkeep)]))\n",
    "    return rhomat\n",
    "\n",
    "\n",
    "def ptrace_sparse(psi_sparse, keep, dims):\n",
    "    \"\"\"\n",
    "    Compute the partial trace over arbitrary subsystems using sparse matrix operations.\n",
    "\n",
    "    Args:\n",
    "        psi_sparse (scipy.sparse matrix): Full density matrix of shape (D, D), where D = product(dims)\n",
    "        keep (list of int): Subsystems to keep (indices, 0-indexed)\n",
    "        dims (list of int): List of subsystem dimensions, e.g., [2]*n for n qubits\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: Reduced density matrix over kept subsystems\n",
    "    \"\"\"\n",
    "    if not issparse(psi_sparse):\n",
    "        raise ValueError(\"psi_sparse must be a scipy.sparse matrix\")\n",
    "    n = len(dims)\n",
    "    D = np.prod(dims)\n",
    "    if psi_sparse.shape != (D, D):\n",
    "        raise ValueError(\"Density matrix shape does not match dims\")\n",
    "    trace = [i for i in range(n) if i not in keep]\n",
    "    d_keep = np.prod([dims[i] for i in keep])\n",
    "    # Prepare output\n",
    "    data = []\n",
    "    row_idx = []\n",
    "    col_idx = []\n",
    "\n",
    "    # Precompute bit masks\n",
    "    def idx_to_bits(idx):\n",
    "        return np.array(list(np.binary_repr(idx, width=n))).astype(int)\n",
    "    \n",
    "\n",
    "    psi_sparse = psi_sparse.tocoo()\n",
    "    for i, j, val in zip(psi_sparse.row, psi_sparse.col, psi_sparse.data):\n",
    "        bi = idx_to_bits(i)\n",
    "        bj = idx_to_bits(j)\n",
    "\n",
    "\n",
    "        # Only sum terms where traced-out subsystems agree\n",
    "        if np.all(bi[trace] == bj[trace]):\n",
    "            # Extract kept bits and convert to reduced indices\n",
    "            #print('condition met for i, j:', i, j)\n",
    "            i_red_bits = bi[keep]\n",
    "            j_red_bits = bj[keep]\n",
    "            i_red = int(\"\".join(i_red_bits.astype(str)), 2)\n",
    "            j_red = int(\"\".join(j_red_bits.astype(str)), 2)\n",
    "\n",
    "\n",
    "            data.append(val)\n",
    "            row_idx.append(i_red)\n",
    "            col_idx.append(j_red)\n",
    "    \n",
    "    return coo_matrix((data, (row_idx, col_idx)), shape=(d_keep, d_keep)).tocsr()\n",
    "\n",
    "\n",
    "def isket_torch(arr):\n",
    "    \"\"\"\n",
    "    Check if a PyTorch tensor is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: torch.Tensor, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, torch.Tensor):\n",
    "        raise ValueError(\"Input must be a PyTorch tensor\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_torch(Q, sel, dims): # torch function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: torch.Tensor, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = torch.tensor(dims[0], dtype=torch.int32).flatten()\n",
    "    nd = len(rd)\n",
    "    #print(\"rd\", rd)\n",
    "    #print(\"nd\", nd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = torch.tensor([sel])\n",
    "    else:\n",
    "        sel = torch.tensor(sel)\n",
    "    sel = torch.sort(sel).values.tolist()\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = rd[sel].tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(range(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = rd[qtrace].tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = rd.tolist()\n",
    "    if isket_torch(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        reshaped_Q = Q.reshape(rd)\n",
    "        #print(reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(sel + qtrace)\n",
    "        #print(transposed_Q.shape)\n",
    "        vmat = transposed_Q.reshape([torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dtrace))])\n",
    "        #print(vmat.shape)\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat @ vmat.conj().T\n",
    "        #print(rhomat.shape)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        reshaped_Q = Q.reshape(rd + rd)\n",
    "        #print(\"reshaped_Q\", reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(qtrace + [nd + q for q in qtrace] + sel + [nd + q for q in sel])\n",
    "        #print(\"transposed_Q\", transposed_Q.shape)\n",
    "        reshaped_transposed_Q = transposed_Q.reshape([torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))])\n",
    "        #print(\"reshaped_transposed_Q\", reshaped_transposed_Q.shape)\n",
    "        #rhomat = torch.trace(reshaped_transposed_Q)\n",
    "        rhomat = torch.einsum('iikl->kl', reshaped_transposed_Q)\n",
    "        # Trace out the first two dimensions\n",
    "        #rhomat = torch.zeros((torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))), dtype=Q.dtype)\n",
    "        #for i in range(reshaped_transposed_Q.shape[0]):\n",
    "        #    for j in range(reshaped_transposed_Q.shape[1]):\n",
    "        #        rhomat += reshaped_transposed_Q[i, j, :, :]\n",
    "        #print(\"rhomat\", rhomat.shape)\n",
    "    return rhomat\n",
    "\n",
    "def entanglement_entropy(psi, subsystem, total_size):\n",
    "\n",
    "    '''Computes the bipartite entanglement entropy of a pure state.\n",
    "    \n",
    "    Parameters:\n",
    "    psi : np.array\n",
    "        The wavefunction (state vector) of the full system.\n",
    "    subsystem_size : int\n",
    "        The number of qubits in subsystem A.\n",
    "    total_size : int\n",
    "        The total number of qubits in the system.\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        The von Neumann entanglement entropy S_A.'''\n",
    "    \n",
    "    psi_matrix =  np.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_numpy(psi_matrix, subsystem, [[2]*total_size, [2]*total_size])  # Partial trace over B\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rho_A)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch(psi, subsystem, total_size):\n",
    "    \"\"\"\n",
    "    Computes the bipartite entanglement entropy of a pure state using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), the wavefunction (state vector) of the full system.\n",
    "    - subsystem_size: int, the number of qubits in subsystem A.\n",
    "    - total_size: int, the total number of qubits in the system.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), the von Neumann entanglement entropy S_A.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(psi, torch.Tensor):\n",
    "        psi = torch.tensor(psi, dtype=torch.complex64)\n",
    "    \n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Compute the density matrix |psi><psi|\n",
    "    psi_matrix = torch.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_torch(psi_matrix, subsystem, [[2] * total_size, [2] * total_size])  # Partial trace over B\n",
    "\n",
    "    #rho_A = rho_A.to(dtype=torch.float64)\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigvals = torch.linalg.eigvalsh(rho_A)\n",
    "\n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "\n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_qutip(psi, subsystem, total_size):\n",
    "    \n",
    "    # Convert the wavefunction to a QuTiP Qobj\n",
    "    density_matrix = np.outer(psi, psi.conj())\n",
    "    density_matrix_qobj = Qobj(density_matrix, dims=[[2]*total_size, [2]*total_size])\n",
    "\n",
    "    rho_A = ptrace(density_matrix_qobj, subsystem)\n",
    "    # Compute the von Neumann entropy S_A\n",
    "    entropy = entropy_vn(rho_A, base=2)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_np_ptrace(rdm):\n",
    "    # rdm already computed and converted to numpy\n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rdm)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch_ptrace(rdm):\n",
    "\n",
    "    eigvals = torch.linalg.eigvalsh(rdm)\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entanglement_entropy_qutip_torch(psi, N):\n",
    "    \"\"\"\n",
    "    Compute the von Neumann entanglement entropy using qutip.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), state vector of a quantum system.\n",
    "    - N: int, total number of qubits.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), von Neumann entropy.\n",
    "    \"\"\"\n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Convert PyTorch tensor to NumPy for QuTiP\n",
    "    psi_np = psi.detach().numpy()\n",
    "\n",
    "    rho_np = np.outer(psi_np, psi_np.conj())\n",
    "    rho_qobj = Qobj(rho_np, dims=[[2] * N, [2] * N])\n",
    "\n",
    "    rho_A = ptrace(rho_qobj, list(range(N // 2)))\n",
    "\n",
    "    # Compute von Neumann entropy\n",
    "    entropy = entropy_vn(rho_A, base=2)  # Compute in log base 2\n",
    "\n",
    "    # Convert back to PyTorch tensor to allow gradient flow\n",
    "    return torch.tensor(entropy, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Define the linear combination function - numpy\n",
    "def linear_combination_np(coeffs, psis):\n",
    "    # Ensure psis are numpy tensors\n",
    "    psi_np = [np.array(psi) for psi in psis]\n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi = sum(c * psi for c, psi in zip(coeffs, psis))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "# Define the linear combination function - torch\n",
    "def linear_combination(coeffs, psis):\n",
    "    # Ensure psis are PyTorch tensors\n",
    "    psis_torch = [torch.tensor(psi, dtype=torch.complex64) if not isinstance(psi, torch.Tensor) else psi for psi in psis]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi_torch = sum(c * psi for c, psi in zip(coeffs, psis_torch))\n",
    "    \n",
    "    return psi_torch\n",
    "\n",
    "# Define the linear combination function - torch but after computing the ptrace of outer products of scars\n",
    "def linear_combination_outer(coeffs, outs):\n",
    "    # Ensure outs are PyTorch tensors\n",
    "    outs_torch = [torch.tensor(out, dtype=torch.complex64) if not isinstance(out, torch.Tensor) else out for out in outs]\n",
    "    torch_coeffs = torch.tensor(coeffs, dtype=torch.complex64)\n",
    "\n",
    "    # Compute the PyTorch tensor of out_coeffs which is the product of all possible combinations of c_i^* times c_j\n",
    "    out_coeffs = torch.zeros((len(torch_coeffs), len(torch_coeffs)), dtype=torch.complex64)\n",
    "    for i in range(len(torch_coeffs)):\n",
    "        for j in range(len(torch_coeffs)):\n",
    "            out_coeffs[i, j] = torch.conj(torch_coeffs[i]) * torch_coeffs[j]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    lin_torch = sum(out_coeffs[i, j] * outs_torch[i] for i in range(len(coeffs)) for j in range(len(coeffs)))\n",
    "    \n",
    "    return lin_torch\n",
    "\n",
    "######################################################\n",
    "\n",
    "# chebyshev\n",
    "\n",
    "def jackson_weights(m):\n",
    "    \"\"\"\n",
    "    Jackson damping coefficients for k = 0..m.\n",
    "    (You can replace this with your own implementation if you already have one.)\n",
    "    \"\"\"\n",
    "    k = np.arange(m+1, dtype=float)\n",
    "    N = m + 1.0\n",
    "    # Standard Jackson kernel for Chebyshev series\n",
    "    # g_k = [(N - k + 1) * cos(pi*k/(N+1)) + sin(pi*k/(N+1)) / tan(pi/(N+1))] / (N+1)\n",
    "    gk = ((N - k + 1) * np.cos(np.pi * k / (N + 1.0)) +\n",
    "          np.sin(np.pi * k / (N + 1.0)) / np.tan(np.pi / (N + 1.0))) / (N + 1.0)\n",
    "    return gk\n",
    "\n",
    "def chebyshev_filter_numpy(H, Emin, Emax, target_E0, m,\n",
    "                           pad=0.05, use_jackson=True, rng=None):\n",
    "    \"\"\"\n",
    "    Chebyshev cosine kernel filter, pure NumPy/SciPy version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse_matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping.\n",
    "    rng : np.random.Generator, optional\n",
    "        Random generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filt : ndarray, shape (n,)\n",
    "        Normalized filtered vector.\n",
    "    approx_E : float\n",
    "        Rayleigh quotient <filt|H|filt>.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: matvec with Htilde = (H - c I)/d\n",
    "    def Htilde_dot(v):\n",
    "        Hv = H @ v   # works for dense or sparse\n",
    "        return (Hv - c * v) / d\n",
    "\n",
    "    # 3) Random start vector\n",
    "    n = H.shape[0]\n",
    "    v0 = rng.standard_normal(n)\n",
    "    v0 /= norm(v0)\n",
    "\n",
    "    # 4) Chebyshev recursion\n",
    "    t0 = v0\n",
    "    t1 = Htilde_dot(v0)\n",
    "\n",
    "    filt = alpha[0] * t0 + alpha[1] * t1\n",
    "\n",
    "    tkm1 = t0\n",
    "    tk   = t1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        tkp1 = 2.0 * Htilde_dot(tk) - tkm1\n",
    "        filt = filt + alpha[k] * tkp1\n",
    "        tkm1, tk = tk, tkp1\n",
    "\n",
    "    # 5) Normalize and Rayleigh quotient\n",
    "    filt_norm = norm(filt)\n",
    "    if filt_norm == 0:\n",
    "        raise RuntimeError(\"Filtered vector became zero; try different parameters.\")\n",
    "    filt /= filt_norm\n",
    "\n",
    "    Hv = H @ filt\n",
    "    approx_E = np.vdot(filt, Hv).real / np.vdot(filt, filt).real\n",
    "\n",
    "    return filt, approx_E\n",
    "\n",
    "def chebyshev_filter_numpy_v0(H, v0, Emin, Emax, target_E0, m,\n",
    "                           pad=0.05, use_jackson=True, rng=None):\n",
    "    \"\"\"\n",
    "    Chebyshev cosine kernel filter, pure NumPy/SciPy version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse_matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    v0 : (n,) array_like\n",
    "        Initial vector to start the Chebyshev recursion.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping.\n",
    "    rng : np.random.Generator, optional\n",
    "        Random generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filt : ndarray, shape (n,)\n",
    "        Normalized filtered vector.\n",
    "    approx_E : float\n",
    "        Rayleigh quotient <filt|H|filt>.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: matvec with Htilde = (H - c I)/d\n",
    "    def Htilde_dot(v):\n",
    "        Hv = H @ v   # works for dense or sparse\n",
    "        return (Hv - c * v) / d\n",
    "\n",
    "    # 3) Normalize random start vector if not already normalized\n",
    "    v0 /= norm(v0)\n",
    "\n",
    "    # 4) Chebyshev recursion\n",
    "    t0 = v0\n",
    "    t1 = Htilde_dot(v0)\n",
    "\n",
    "    filt = alpha[0] * t0 + alpha[1] * t1\n",
    "\n",
    "    tkm1 = t0\n",
    "    tk   = t1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        tkp1 = 2.0 * Htilde_dot(tk) - tkm1\n",
    "        filt = filt + alpha[k] * tkp1\n",
    "        tkm1, tk = tk, tkp1\n",
    "\n",
    "    # 5) Normalize and Rayleigh quotient\n",
    "    filt_norm = norm(filt)\n",
    "    if filt_norm == 0:\n",
    "        raise RuntimeError(\"Filtered vector became zero; try different parameters.\")\n",
    "    filt /= filt_norm\n",
    "\n",
    "    Hv = H @ filt\n",
    "    approx_E = np.vdot(filt, Hv).real / np.vdot(filt, filt).real\n",
    "\n",
    "    return filt, approx_E "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fec2cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12  # Number of spins\n",
    "J = 1.0  # Interaction strength\n",
    "h = 3.0  # Transverse field strength # this is the value in the paper. maybe try  other values too, including the critical value one (h=J=1)\n",
    "\n",
    "#keep_qubits = [0, 4, 5]\n",
    "#keep_qubits = [0, 4, 5, 11] # 4 spins rdm full rank\n",
    "#keep_qubits = [0, 4, 5, 9]  # 4 spins - 2 adjacent triangular plaquettes - this is when i observe exactly 5 degenerate scars\n",
    "#keep_qubits = [0, 4, 5, 9, 11]  # 5 spins - 3 adjacent triangular plaquettes\n",
    "keep_qubits = [2, 4, 5, 8, 9] # 5 spins - pentagon around 0\n",
    "\n",
    "trace_qubits = [i for i in range(N) if i not in keep_qubits]\n",
    "\n",
    "\n",
    "# Assuming transverse_field_ising is defined and returns a sparse Hermitian matrix\n",
    "H = transverse_field_ising_icosahedral(N, J, h)\n",
    "\n",
    "#print(f\"Hamiltonian shape: {H.shape}\")\n",
    "#print(f\"Non-zero elements in H: {H.nnz}\")\n",
    "\n",
    "# Define the C5 permutation mapping for your case - around axis through vert 9 and 10\n",
    "perm = {\n",
    "    0: 2,\n",
    "    2: 7,\n",
    "    7: 11,\n",
    "    11: 5,\n",
    "    5: 0,\n",
    "    1: 3,\n",
    "    3: 4,\n",
    "    4: 8,\n",
    "    8: 6,\n",
    "    6: 1,\n",
    "    9: 9,   # Fixed\n",
    "    10: 10  # Fixed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a08e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = eigh(H.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a82fd514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max err of U v0 - omega^r v0: 1.175570504584946\n"
     ]
    }
   ],
   "source": [
    "# build a single vector in irrep r (project a single computational basis state)\n",
    "def make_irrep_from_basis(basis_idx, r, perm_arr, N):\n",
    "    n = 2**N\n",
    "    e = np.zeros(n, dtype=np.complex128)\n",
    "    e[basis_idx] = 1.0\n",
    "    omega = np.exp(2j * np.pi / 5)\n",
    "    v = np.zeros_like(e)\n",
    "    for t in range(5):\n",
    "        v += (omega**(-r * t)) * apply_perm_power(e, perm_arr, t)\n",
    "    v /= np.linalg.norm(v)\n",
    "    return v\n",
    "\n",
    "# choose irrep label r in {0,1,2,3,4} and a single computational basis index\n",
    "r = 4        # pick the irrep you want\n",
    "basis_idx = 0  # pick one basis state (change if you prefer another starting config)\n",
    "\n",
    "v0 = make_irrep_from_basis(basis_idx, r, perm_arr, N)\n",
    "\n",
    "# quick check: applying permutation should multiply by omega**r (within numerical tol)\n",
    "omega = np.exp(2j * np.pi / 5)\n",
    "uv = apply_perm_once(v0, perm_arr)\n",
    "print(\"max err of U v0 - omega^r v0:\", np.max(np.abs(uv - (omega**r) * v0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f01483b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.99898001934579 2048\n",
      "-35.99793883668962 2048\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[123]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m vc1, Ec1 = chebyshev_filter_numpy_v0(H, vc, Emin=-\u001b[32m37.9456425\u001b[39m, Emax=\u001b[32m41.28675302\u001b[39m, target_E0=target_E0, m=\u001b[32m10000\u001b[39m, pad=\u001b[32m0.05\u001b[39m, use_jackson=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(Ec1, np.count_nonzero(np.abs(vc1) > \u001b[32m1e-10\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m vc2, Ec2 = chebyshev_filter_numpy_v0(H, vc1, Emin=-\u001b[32m37.9456425\u001b[39m, Emax=\u001b[32m41.28675302\u001b[39m, target_E0=target_E0, m=\u001b[32m10000\u001b[39m, pad=\u001b[32m0.05\u001b[39m, use_jackson=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(Ec2, np.count_nonzero(np.abs(vc2) > \u001b[32m1e-10\u001b[39m))\n\u001b[32m      9\u001b[39m vc3, Ec3 = chebyshev_filter_numpy_v0(H, vc2, Emin=-\u001b[32m37.9456425\u001b[39m, Emax=\u001b[32m41.28675302\u001b[39m, target_E0=target_E0, m=\u001b[32m10000\u001b[39m, pad=\u001b[32m0.05\u001b[39m, use_jackson=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 727\u001b[39m, in \u001b[36mchebyshev_filter_numpy_v0\u001b[39m\u001b[34m(H, v0, Emin, Emax, target_E0, m, pad, use_jackson, rng)\u001b[39m\n\u001b[32m    724\u001b[39m tk   = t1\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, m+\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m727\u001b[39m     tkp1 = \u001b[32m2.0\u001b[39m * Htilde_dot(tk) - tkm1\n\u001b[32m    728\u001b[39m     filt = filt + alpha[k] * tkp1\n\u001b[32m    729\u001b[39m     tkm1, tk = tk, tkp1\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 711\u001b[39m, in \u001b[36mchebyshev_filter_numpy_v0.<locals>.Htilde_dot\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mHtilde_dot\u001b[39m(v):\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     Hv = H @ v   \u001b[38;5;66;03m# works for dense or sparse\u001b[39;00m\n\u001b[32m    712\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (Hv - c * v) / d\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:732\u001b[39m, in \u001b[36m_spbase.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[32m    730\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mScalar operands are not allowed, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    731\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33muse \u001b[39m\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._matmul_dispatch(other)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:617\u001b[39m, in \u001b[36m_spbase._matmul_dispatch\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m other.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m np.ndarray:\n\u001b[32m    615\u001b[39m     \u001b[38;5;66;03m# Fast path for the most common case\u001b[39;00m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m other.shape == (N,):\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._matmul_vector(other)\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m other.shape == (N, \u001b[32m1\u001b[39m):\n\u001b[32m    619\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._matmul_vector(other.ravel())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:526\u001b[39m, in \u001b[36m_cs_matrix._matmul_vector\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;66;03m# csr_matvec or csc_matvec\u001b[39;00m\n\u001b[32m    525\u001b[39m fn = \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m.format + \u001b[33m'\u001b[39m\u001b[33m_matvec\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m fn(M, N, \u001b[38;5;28mself\u001b[39m.indptr, \u001b[38;5;28mself\u001b[39m.indices, \u001b[38;5;28mself\u001b[39m.data, other, result)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#v0 = np.random.randn(H.shape[0])\n",
    "target_E0 = -6.0\n",
    "vc, Ec = chebyshev_filter_numpy_v0(H, v0, Emin=-37.9456425, Emax=41.28675302, target_E0=target_E0, m=10000, pad=0.05, use_jackson=True)\n",
    "print(Ec, np.count_nonzero(np.abs(vc) > 1e-10))\n",
    "vc1, Ec1 = chebyshev_filter_numpy_v0(H, vc, Emin=-37.9456425, Emax=41.28675302, target_E0=target_E0, m=10000, pad=0.05, use_jackson=True)\n",
    "print(Ec1, np.count_nonzero(np.abs(vc1) > 1e-10))\n",
    "vc2, Ec2 = chebyshev_filter_numpy_v0(H, vc1, Emin=-37.9456425, Emax=41.28675302, target_E0=target_E0, m=10000, pad=0.05, use_jackson=True)\n",
    "print(Ec2, np.count_nonzero(np.abs(vc2) > 1e-10))\n",
    "vc3, Ec3 = chebyshev_filter_numpy_v0(H, vc2, Emin=-37.9456425, Emax=41.28675302, target_E0=target_E0, m=10000, pad=0.05, use_jackson=True)\n",
    "print(Ec3, np.count_nonzero(np.abs(vc3) > 1e-10))\n",
    "vc4, Ec4 = chebyshev_filter_numpy_v0(H, vc3, Emin=-37.9456425, Emax=41.28675302, target_E0=target_E0, m=10000, pad=0.05, use_jackson=True)\n",
    "print(Ec4, np.count_nonzero(np.abs(vc4) > 1e-10))\n",
    "vc5, Ec5 = chebyshev_filter_numpy_v0(H, vc4, Emin=-37.9456425, Emax=41.28675302, target_E0=target_E0, m=10000, pad=0.05, use_jackson=True)\n",
    "print(Ec5, np.count_nonzero(np.abs(vc5) > 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e34b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "Et = eigenvalues[1527]\n",
    "vt = eigenvectors[:,1527]\n",
    "print(Et, np.count_nonzero(np.abs(vt) > 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3efd97c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print((np.abs(np.dot(vt.conj(), vc4)))**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
