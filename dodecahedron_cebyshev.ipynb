{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574efd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from numpy.linalg import norm\n",
    "import os\n",
    "from scipy.linalg import eigh, qr, null_space, norm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from scipy.sparse import eye, kron, identity, csr_matrix, csc_matrix, lil_matrix, dok_matrix, issparse, coo_matrix\n",
    "from scipy.sparse.linalg import eigsh, eigs, lobpcg, LinearOperator, ArpackNoConvergence\n",
    "from scipy.optimize import curve_fit\n",
    "from qutip import Qobj, ptrace, entropy_vn, qeye, tensor\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import sympy as sp\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f949390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauli_x():\n",
    "    \"\"\"Pauli X matrix.\"\"\"\n",
    "    return np.array([[0, 1], [1, 0]])\n",
    "\n",
    "def pauli_z():\n",
    "    \"\"\"Pauli Z matrix.\"\"\"\n",
    "    return np.array([[1, 0], [0, -1]])\n",
    "\n",
    "def dodecahedral_bonds(): #20 vertices\n",
    "    \"\"\"\n",
    "    Defines the connectivity of a true 20-vertex dodecahedral molecular structure.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple (i, j) represents a bond between spin i and spin j.\n",
    "    \"\"\"\n",
    "    bonds = [(0, 13), (0, 14), (0, 15), (1, 4), (1, 5), (1, 12),\n",
    "    (2, 6), (2, 13), (2, 18), (3, 7), (3, 14), (3, 19),\n",
    "    (4, 10), (4, 18), (5, 11), (5, 19), (6, 10), (6, 15),\n",
    "    (7, 11), (7, 15), (8, 9), (8, 13), (8, 16), (9, 14), (9, 17),\n",
    "    (10, 11), (12, 16), (12, 17), (16, 18), (17, 19)]\n",
    "\n",
    "    return bonds\n",
    "\n",
    "\n",
    "def transverse_field_ising_dodecahedral(N, J, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an dodecahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the dodecahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 20:\n",
    "        raise ValueError(\"Dodecahedral molecules typically have N = 20 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get dodecahedral bonds\n",
    "    bonds = dodecahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for dodecahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def ising_dodecahedron(N, J):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on a dodecahedral molecular structure without transverse field.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the dodecahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        \"\"\"\n",
    "    if N != 20:\n",
    "        raise ValueError(\"Dodecahedral molecules typically have N = 20 sites.\")\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get dodecahedral bonds\n",
    "    bonds = dodecahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for dodecahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def transverse_field_dodecahedral(N, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on a dodecahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the dodecahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 20:\n",
    "        raise ValueError(\"Dodecahedral molecules typically have N = 20 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get dodecahedral bonds\n",
    "    bonds = dodecahedral_bonds()\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "'''\n",
    "def partial_trace_qubit(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits.\"\"\"\n",
    "    keep_dims = np.prod([dims[i] for i in keep])\n",
    "    trace_dims = np.prod([dims[i] for i in range(len(dims)) if i not in keep])\n",
    "    rho = rho.reshape([keep_dims, trace_dims, keep_dims, trace_dims])\n",
    "    return np.trace(rho, axis1=1, axis2=3).reshape([keep_dims, keep_dims])\n",
    "\n",
    "def partial_trace_qubit_torch(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits using PyTorch.\"\"\"\n",
    "    keep_dims = torch.prod(torch.tensor([dims[i] for i in keep]))\n",
    "    trace_dims = torch.prod(torch.tensor([dims[i] for i in range(len(dims)) if i not in keep]))\n",
    "    rho = rho.view(keep_dims, trace_dims, keep_dims, trace_dims)\n",
    "    # Compute the partial trace\n",
    "    traced_rho = torch.zeros((keep_dims, keep_dims), dtype=rho.dtype)\n",
    "    for i in range(trace_dims):\n",
    "        traced_rho += rho[:, i, :, i]\n",
    "    #return traced_rho.view(keep_dims, keep_dims)\n",
    "    return traced_rho'''\n",
    "\n",
    "def isket_numpy(arr):\n",
    "    \"\"\"\n",
    "    Check if a NumPy array is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: np.ndarray, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(\"Input must be a NumPy array\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_numpy(Q, sel, dims): # numpy function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using NumPy.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: numpy object, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - numpy object, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = np.asarray(dims[0], dtype=np.int32).ravel()\n",
    "    nd = len(rd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = np.array([sel])\n",
    "    else:\n",
    "        sel = np.asarray(sel)\n",
    "    sel = list(np.sort(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = (rd[sel]).tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(np.arange(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = (rd[qtrace]).tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = list(rd)\n",
    "    if isket_numpy(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        vmat = (Q\n",
    "                .reshape(rd)\n",
    "                .transpose(sel + qtrace)\n",
    "                .reshape([np.prod(dkeep), np.prod(dtrace)]))\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat.dot(vmat.conj().T)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        rhomat = np.trace(Q\n",
    "                          .reshape(rd + rd)\n",
    "                          .transpose(qtrace + [nd + q for q in qtrace] +\n",
    "                                     sel + [nd + q for q in sel])\n",
    "                          .reshape([np.prod(dtrace),\n",
    "                                    np.prod(dtrace),\n",
    "                                    np.prod(dkeep),\n",
    "                                    np.prod(dkeep)]))\n",
    "    return rhomat\n",
    "\n",
    "\n",
    "def ptrace_sparse(psi_sparse, keep, dims):\n",
    "    \"\"\"\n",
    "    Compute the partial trace over arbitrary subsystems using sparse matrix operations.\n",
    "\n",
    "    Args:\n",
    "        psi_sparse (scipy.sparse matrix): Full density matrix of shape (D, D), where D = product(dims)\n",
    "        keep (list of int): Subsystems to keep (indices, 0-indexed)\n",
    "        dims (list of int): List of subsystem dimensions, e.g., [2]*n for n qubits\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: Reduced density matrix over kept subsystems\n",
    "    \"\"\"\n",
    "    if not issparse(psi_sparse):\n",
    "        raise ValueError(\"psi_sparse must be a scipy.sparse matrix\")\n",
    "    n = len(dims)\n",
    "    D = np.prod(dims)\n",
    "    if psi_sparse.shape != (D, D):\n",
    "        raise ValueError(\"Density matrix shape does not match dims\")\n",
    "    trace = [i for i in range(n) if i not in keep]\n",
    "    d_keep = np.prod([dims[i] for i in keep])\n",
    "    # Prepare output\n",
    "    data = []\n",
    "    row_idx = []\n",
    "    col_idx = []\n",
    "\n",
    "    # Precompute bit masks\n",
    "    def idx_to_bits(idx):\n",
    "        return np.array(list(np.binary_repr(idx, width=n))).astype(int)\n",
    "    \n",
    "\n",
    "    psi_sparse = psi_sparse.tocoo()\n",
    "    for i, j, val in zip(psi_sparse.row, psi_sparse.col, psi_sparse.data):\n",
    "        bi = idx_to_bits(i)\n",
    "        bj = idx_to_bits(j)\n",
    "\n",
    "\n",
    "        # Only sum terms where traced-out subsystems agree\n",
    "        if np.all(bi[trace] == bj[trace]):\n",
    "            # Extract kept bits and convert to reduced indices\n",
    "            #print('condition met for i, j:', i, j)\n",
    "            i_red_bits = bi[keep]\n",
    "            j_red_bits = bj[keep]\n",
    "            i_red = int(\"\".join(i_red_bits.astype(str)), 2)\n",
    "            j_red = int(\"\".join(j_red_bits.astype(str)), 2)\n",
    "\n",
    "\n",
    "            data.append(val)\n",
    "            row_idx.append(i_red)\n",
    "            col_idx.append(j_red)\n",
    "    \n",
    "    return coo_matrix((data, (row_idx, col_idx)), shape=(d_keep, d_keep)).tocsr()\n",
    "\n",
    "\n",
    "def isket_torch(arr):\n",
    "    \"\"\"\n",
    "    Check if a PyTorch tensor is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: torch.Tensor, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, torch.Tensor):\n",
    "        raise ValueError(\"Input must be a PyTorch tensor\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_torch(Q, sel, dims): # torch function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: torch.Tensor, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = torch.tensor(dims[0], dtype=torch.int32).flatten()\n",
    "    nd = len(rd)\n",
    "    #print(\"rd\", rd)\n",
    "    #print(\"nd\", nd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = torch.tensor([sel])\n",
    "    else:\n",
    "        sel = torch.tensor(sel)\n",
    "    sel = torch.sort(sel).values.tolist()\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = rd[sel].tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(range(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = rd[qtrace].tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = rd.tolist()\n",
    "    if isket_torch(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        reshaped_Q = Q.reshape(rd)\n",
    "        #print(reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(sel + qtrace)\n",
    "        #print(transposed_Q.shape)\n",
    "        vmat = transposed_Q.reshape([torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dtrace))])\n",
    "        #print(vmat.shape)\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat @ vmat.conj().T\n",
    "        #print(rhomat.shape)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        reshaped_Q = Q.reshape(rd + rd)\n",
    "        #print(\"reshaped_Q\", reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(qtrace + [nd + q for q in qtrace] + sel + [nd + q for q in sel])\n",
    "        #print(\"transposed_Q\", transposed_Q.shape)\n",
    "        reshaped_transposed_Q = transposed_Q.reshape([torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))])\n",
    "        #print(\"reshaped_transposed_Q\", reshaped_transposed_Q.shape)\n",
    "        #rhomat = torch.trace(reshaped_transposed_Q)\n",
    "        rhomat = torch.einsum('iikl->kl', reshaped_transposed_Q)\n",
    "        # Trace out the first two dimensions\n",
    "        #rhomat = torch.zeros((torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))), dtype=Q.dtype)\n",
    "        #for i in range(reshaped_transposed_Q.shape[0]):\n",
    "        #    for j in range(reshaped_transposed_Q.shape[1]):\n",
    "        #        rhomat += reshaped_transposed_Q[i, j, :, :]\n",
    "        #print(\"rhomat\", rhomat.shape)\n",
    "    return rhomat\n",
    "\n",
    "def entanglement_entropy(psi, subsystem, total_size):\n",
    "\n",
    "    '''Computes the bipartite entanglement entropy of a pure state.\n",
    "    \n",
    "    Parameters:\n",
    "    psi : np.array\n",
    "        The wavefunction (state vector) of the full system.\n",
    "    subsystem_size : int\n",
    "        The number of qubits in subsystem A.\n",
    "    total_size : int\n",
    "        The total number of qubits in the system.\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        The von Neumann entanglement entropy S_A.'''\n",
    "    \n",
    "    psi_matrix =  np.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_numpy(psi_matrix, subsystem, [[2]*total_size, [2]*total_size])  # Partial trace over B\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rho_A)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch(psi, subsystem, total_size):\n",
    "    \"\"\"\n",
    "    Computes the bipartite entanglement entropy of a pure state using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), the wavefunction (state vector) of the full system.\n",
    "    - subsystem_size: int, the number of qubits in subsystem A.\n",
    "    - total_size: int, the total number of qubits in the system.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), the von Neumann entanglement entropy S_A.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(psi, torch.Tensor):\n",
    "        psi = torch.tensor(psi, dtype=torch.complex64)\n",
    "    \n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Compute the density matrix |psi><psi|\n",
    "    psi_matrix = torch.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_torch(psi_matrix, subsystem, [[2] * total_size, [2] * total_size])  # Partial trace over B\n",
    "\n",
    "    #rho_A = rho_A.to(dtype=torch.float64)\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigvals = torch.linalg.eigvalsh(rho_A)\n",
    "\n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "\n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_qutip(psi, subsystem, total_size):\n",
    "    \n",
    "    # Convert the wavefunction to a QuTiP Qobj\n",
    "    density_matrix = np.outer(psi, psi.conj())\n",
    "    density_matrix_qobj = Qobj(density_matrix, dims=[[2]*total_size, [2]*total_size])\n",
    "\n",
    "    rho_A = ptrace(density_matrix_qobj, subsystem)\n",
    "    # Compute the von Neumann entropy S_A\n",
    "    entropy = entropy_vn(rho_A, base=2)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_np_ptrace(rdm):\n",
    "    # rdm already computed and converted to numpy\n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rdm)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch_ptrace(rdm):\n",
    "\n",
    "    eigvals = torch.linalg.eigvalsh(rdm)\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entanglement_entropy_qutip_torch(psi, N):\n",
    "    \"\"\"\n",
    "    Compute the von Neumann entanglement entropy using qutip.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), state vector of a quantum system.\n",
    "    - N: int, total number of qubits.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), von Neumann entropy.\n",
    "    \"\"\"\n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Convert PyTorch tensor to NumPy for QuTiP\n",
    "    psi_np = psi.detach().numpy()\n",
    "\n",
    "    rho_np = np.outer(psi_np, psi_np.conj())\n",
    "    rho_qobj = Qobj(rho_np, dims=[[2] * N, [2] * N])\n",
    "\n",
    "    rho_A = ptrace(rho_qobj, list(range(N // 2)))\n",
    "\n",
    "    # Compute von Neumann entropy\n",
    "    entropy = entropy_vn(rho_A, base=2)  # Compute in log base 2\n",
    "\n",
    "    # Convert back to PyTorch tensor to allow gradient flow\n",
    "    return torch.tensor(entropy, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Define the linear combination function - numpy\n",
    "def linear_combination_np(coeffs, psis):\n",
    "    # Ensure psis are numpy tensors\n",
    "    psi_np = [np.array(psi) for psi in psis]\n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi = sum(c * psi for c, psi in zip(coeffs, psis))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "# Define the linear combination function - torch\n",
    "def linear_combination(coeffs, psis):\n",
    "    # Ensure psis are PyTorch tensors\n",
    "    psis_torch = [torch.tensor(psi, dtype=torch.complex64) if not isinstance(psi, torch.Tensor) else psi for psi in psis]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi_torch = sum(c * psi for c, psi in zip(coeffs, psis_torch))\n",
    "    \n",
    "    return psi_torch\n",
    "\n",
    "# Define the linear combination function - torch but after computing the ptrace of outer products of scars\n",
    "def linear_combination_outer(coeffs, outs):\n",
    "    # Ensure outs are PyTorch tensors\n",
    "    outs_torch = [torch.tensor(out, dtype=torch.complex64) if not isinstance(out, torch.Tensor) else out for out in outs]\n",
    "    torch_coeffs = torch.tensor(coeffs, dtype=torch.complex64)\n",
    "\n",
    "    # Compute the PyTorch tensor of out_coeffs which is the product of all possible combinations of c_i^* times c_j\n",
    "    out_coeffs = torch.zeros((len(torch_coeffs), len(torch_coeffs)), dtype=torch.complex64)\n",
    "    for i in range(len(torch_coeffs)):\n",
    "        for j in range(len(torch_coeffs)):\n",
    "            out_coeffs[i, j] = torch.conj(torch_coeffs[i]) * torch_coeffs[j]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    lin_torch = sum(out_coeffs[i, j] * outs_torch[i] for i in range(len(coeffs)) for j in range(len(coeffs)))\n",
    "    \n",
    "    return lin_torch\n",
    "\n",
    "######################################################\n",
    "\n",
    "# chebyshev\n",
    "\n",
    "def jackson_weights(m):\n",
    "    \"\"\"\n",
    "    Jackson damping coefficients for k = 0..m.\n",
    "    (You can replace this with your own implementation if you already have one.)\n",
    "    \"\"\"\n",
    "    k = np.arange(m+1, dtype=float)\n",
    "    N = m + 1.0\n",
    "    # Standard Jackson kernel for Chebyshev series\n",
    "    # g_k = [(N - k + 1) * cos(pi*k/(N+1)) + sin(pi*k/(N+1)) / tan(pi/(N+1))] / (N+1)\n",
    "    gk = ((N - k + 1) * np.cos(np.pi * k / (N + 1.0)) +\n",
    "          np.sin(np.pi * k / (N + 1.0)) / np.tan(np.pi / (N + 1.0))) / (N + 1.0)\n",
    "    return gk\n",
    "\n",
    "def chebyshev_filter_numpy(H, Emin, Emax, target_E0, m,\n",
    "                           pad=0.05, use_jackson=True, rng=None):\n",
    "    \"\"\"\n",
    "    Chebyshev cosine kernel filter, pure NumPy/SciPy version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse_matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping.\n",
    "    rng : np.random.Generator, optional\n",
    "        Random generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filt : ndarray, shape (n,)\n",
    "        Normalized filtered vector.\n",
    "    approx_E : float\n",
    "        Rayleigh quotient <filt|H|filt>.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: matvec with Htilde = (H - c I)/d\n",
    "    def Htilde_dot(v):\n",
    "        Hv = H @ v   # works for dense or sparse\n",
    "        return (Hv - c * v) / d\n",
    "\n",
    "    # 3) Random start vector\n",
    "    n = H.shape[0]\n",
    "    v0 = rng.standard_normal(n)\n",
    "    v0 /= norm(v0)\n",
    "\n",
    "    # 4) Chebyshev recursion\n",
    "    t0 = v0\n",
    "    t1 = Htilde_dot(v0)\n",
    "\n",
    "    filt = alpha[0] * t0 + alpha[1] * t1\n",
    "\n",
    "    tkm1 = t0\n",
    "    tk   = t1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        tkp1 = 2.0 * Htilde_dot(tk) - tkm1\n",
    "        filt = filt + alpha[k] * tkp1\n",
    "        tkm1, tk = tk, tkp1\n",
    "\n",
    "    # 5) Normalize and Rayleigh quotient\n",
    "    filt_norm = norm(filt)\n",
    "    if filt_norm == 0:\n",
    "        raise RuntimeError(\"Filtered vector became zero; try different parameters.\")\n",
    "    filt /= filt_norm\n",
    "\n",
    "    Hv = H @ filt\n",
    "    approx_E = np.vdot(filt, Hv).real / np.vdot(filt, filt).real\n",
    "\n",
    "    return filt, approx_E\n",
    "\n",
    "def chebyshev_filter_v0_numpy(H, v0, Emin, Emax, target_E0, m,\n",
    "                           pad=0.05, use_jackson=True, rng=None):\n",
    "    \"\"\"\n",
    "    Chebyshev cosine kernel filter, pure NumPy/SciPy version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse_matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    v0 : (n,) array_like\n",
    "        Initial vector to start the Chebyshev recursion.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping.\n",
    "    rng : np.random.Generator, optional\n",
    "        Random generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filt : ndarray, shape (n,)\n",
    "        Normalized filtered vector.\n",
    "    approx_E : float\n",
    "        Rayleigh quotient <filt|H|filt>.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: matvec with Htilde = (H - c I)/d\n",
    "    def Htilde_dot(v):\n",
    "        Hv = H @ v   # works for dense or sparse\n",
    "        return (Hv - c * v) / d\n",
    "\n",
    "    # 3) Normalize random start vector if not already normalized\n",
    "    v0 /= norm(v0)\n",
    "\n",
    "    # 4) Chebyshev recursion\n",
    "    t0 = v0\n",
    "    t1 = Htilde_dot(v0)\n",
    "\n",
    "    filt = alpha[0] * t0 + alpha[1] * t1\n",
    "\n",
    "    tkm1 = t0\n",
    "    tk   = t1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        tkp1 = 2.0 * Htilde_dot(tk) - tkm1\n",
    "        filt = filt + alpha[k] * tkp1\n",
    "        tkm1, tk = tk, tkp1\n",
    "\n",
    "    # 5) Normalize and Rayleigh quotient\n",
    "    filt_norm = norm(filt)\n",
    "    if filt_norm == 0:\n",
    "        raise RuntimeError(\"Filtered vector became zero; try different parameters.\")\n",
    "    filt /= filt_norm\n",
    "\n",
    "    Hv = H @ filt\n",
    "    approx_E = np.vdot(filt, Hv).real / np.vdot(filt, filt).real\n",
    "\n",
    "    return filt, approx_E\n",
    "\n",
    "def chebyshev_filter_block_numpy(H, V0, Emin, Emax, target_E0, m,\n",
    "                                 pad=0.05, use_jackson=True):\n",
    "    \"\"\"\n",
    "    Block Chebyshev cosine kernel filter (pure NumPy/SciPy version).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    V0 : (n, p) array_like\n",
    "        Initial block of p vectors (columns) to start the Chebyshev recursion.\n",
    "        Columns should be linearly independent; they need not be orthonormal.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping to the Chebyshev coefficients.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Phi : ndarray, shape (n, p)\n",
    "        Approximate eigenvectors (columns) near target_E0.\n",
    "    evals : ndarray, shape (p,)\n",
    "        Corresponding Ritz eigenvalues.\n",
    "    \"\"\"\n",
    "\n",
    "    V0 = np.array(V0, dtype=np.complex128, copy=True)\n",
    "    n, p = V0.shape\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)   # assumed defined elsewhere\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: Htilde = (H - c I)/d acting on a block\n",
    "    def Htilde_dot_block(V):\n",
    "        HV = H @ V              # works for dense or sparse\n",
    "        return (HV - c * V) / d\n",
    "\n",
    "    # 3) Orthonormalize starting block: V0 -> Q0\n",
    "    #    (this gives us an orthonormal basis of the initial subspace)\n",
    "    Q0, _ = np.linalg.qr(V0)    # (n, p), orthonormal columns\n",
    "\n",
    "    # 4) Block Chebyshev recursion\n",
    "    T0 = Q0                     # (n, p)\n",
    "    T1 = Htilde_dot_block(Q0)   # (n, p)\n",
    "\n",
    "    filt = alpha[0] * T0 + alpha[1] * T1\n",
    "\n",
    "    Tkm1 = T0\n",
    "    Tk   = T1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        Tkp1 = 2.0 * Htilde_dot_block(Tk) - Tkm1\n",
    "        filt = filt + alpha[k] * Tkp1\n",
    "        Tkm1, Tk = Tk, Tkp1\n",
    "\n",
    "    # 5) Orthonormalize the filtered block\n",
    "    Q, _ = np.linalg.qr(filt)   # (n, p), orthonormal columns spanning filtered subspace\n",
    "\n",
    "    # 6) Rayleigh–Ritz in the filtered subspace\n",
    "    # H_sub is the projected matrix H in basis Q\n",
    "    H_sub = Q.conj().T @ (H @ Q)    # (p, p)\n",
    "    evals, U = np.linalg.eigh(H_sub)\n",
    "\n",
    "    # 7) Lift Ritz eigenvectors back to full space\n",
    "    Phi = Q @ U    # (n, p)\n",
    "\n",
    "    return Phi, evals\n",
    "\n",
    "### symmetry sectors -- Ih later\n",
    "\n",
    "def check_magnetization_sector(vec, N, tol=1e-6): ### total magnetization is not conserved --- it only applies to scars\n",
    "    \"\"\"Check average magnetization of a state vector.\"\"\"\n",
    "    D = 1 << N\n",
    "    mag_avg = 0.0\n",
    "    for b in range(D):\n",
    "        mag_avg += magnetization(b, N) * np.abs(vec[b])**2\n",
    "    return mag_avg\n",
    "\n",
    "def check_parity_sector(vec, N, tol=1e-6):\n",
    "    \"\"\"Check if vector is in even/odd parity sector.\"\"\"\n",
    "    D = 1 << N\n",
    "    weight_even = sum(np.abs(vec[b])**2 for b in range(D) if parity(b, N) == 1)\n",
    "    weight_odd = sum(np.abs(vec[b])**2 for b in range(D) if parity(b, N) == -1)\n",
    "    if weight_even > 1.0 - tol:\n",
    "        return \"even\"\n",
    "    elif weight_odd > 1.0 - tol:\n",
    "        return \"odd\"\n",
    "    else:\n",
    "        return f\"mixed (even={weight_even:.4f}, odd={weight_odd:.4f})\"\n",
    "\n",
    "def build_parity_operator(N):\n",
    "    \"\"\"\n",
    "    Build the parity operator as a matrix.\n",
    "    Parity operator P|b> = (-1)^(number of 1s) |b>\n",
    "    \n",
    "    Parameters:\n",
    "    - N: int, number of qubits\n",
    "    \n",
    "    Returns:\n",
    "    - P_op: sparse matrix, parity operator (diagonal)\n",
    "    \"\"\"\n",
    "    D = 1 << N\n",
    "    # build diagonal entries as a small-memory 1D array\n",
    "    diag = np.fromiter((1 if bin(b).count('1') % 2 == 0 else -1 for b in range(D)),\n",
    "                       dtype=np.int8, count=D)\n",
    "    # construct sparse diagonal directly (COO -> CSR) without making a dense (D,D) array\n",
    "    rows = np.arange(D, dtype=np.int64)\n",
    "    P_op = csr_matrix((diag.astype(np.int8), (rows, rows)), shape=(D, D))\n",
    "    return P_op\n",
    "\n",
    "def commutator_norm(A, B):\n",
    "    \"\"\"\n",
    "    Compute the Frobenius norm of the commutator [A, B] = AB - BA.\n",
    "    For sparse matrices, use sparse operations.\n",
    "    \n",
    "    Parameters:\n",
    "    - A, B: matrices (dense or sparse)\n",
    "    \n",
    "    Returns:\n",
    "    - float, ||[A, B]||_F\n",
    "    \"\"\"\n",
    "    comm = A @ B - B @ A\n",
    "    \n",
    "    if issparse(comm):\n",
    "        # For sparse matrices, compute Frobenius norm\n",
    "        return np.sqrt(comm.multiply(comm.conj()).sum())\n",
    "    else:\n",
    "        # For dense matrices\n",
    "        return np.linalg.norm(comm, 'fro')\n",
    "\n",
    "def magnetization(bitstring, N):\n",
    "    # Suppose spin up = 1, spin down = 0\n",
    "    # Or adjust convention as needed\n",
    "    n_up = bitstring.bit_count()\n",
    "    n_down = N - n_up\n",
    "    return n_up - n_down  # proportional to total Sz\n",
    "\n",
    "def parity(bitstring, N):\n",
    "    \"\"\"\n",
    "    Compute parity of a bitstring.\n",
    "    Returns +1 for even number of up spins, -1 for odd.\n",
    "    \"\"\"\n",
    "    n_up = bitstring.bit_count()\n",
    "    return 1 if (n_up % 2 == 0) else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec2cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamiltonian shape: (1048576, 1048576)\n",
      "Non-zero elements in H: 32321100\n"
     ]
    }
   ],
   "source": [
    "N = 20  # Number of spins\n",
    "J = 1.0  # Interaction strength\n",
    "h = 3.0  # Transverse field strength # this is the value in the paper. maybe try  other values too, including the critical value one (h=J=1)\n",
    "\n",
    "# Assuming transverse_field_ising is defined and returns a sparse Hermitian matrix\n",
    "H = transverse_field_ising_dodecahedral(N, J, h)\n",
    "Hi = ising_dodecahedron(N, J)\n",
    "Htf = transverse_field_dodecahedral(N, h)\n",
    "\n",
    "print(f\"Hamiltonian shape: {H.shape}\")\n",
    "print(f\"Non-zero elements in H: {H.nnz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9fbbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if H commutes with symmetry operators:\n",
      "\n",
      "Parity:\n",
      "  ||[H, P]||_F = 0.000000e+00\n",
      "  ||H||_F = 1.483917e+04\n",
      "  Relative error: 0.000000e+00\n",
      "  Commutes: YES\n",
      "\n",
      "Operator properties:\n",
      "  ||P^2 - I||_F = 0.000000e+00+0.000000e+00j\n",
      "  P is involutory: YES\n"
     ]
    }
   ],
   "source": [
    "# Build symmetry operators\n",
    "P_op = build_parity_operator(N)\n",
    "\n",
    "# compute Frobenius norm of H (works for sparse or dense)\n",
    "if issparse(H):\n",
    "    H_norm = np.sqrt((H.multiply(H.conj())).sum())\n",
    "else:\n",
    "    H_norm = np.linalg.norm(H, 'fro')\n",
    "print(\"Checking if H commutes with symmetry operators:\\n\")\n",
    "\n",
    "# Check [H, P] = 0 (parity symmetry)\n",
    "comm_parity = commutator_norm(H, P_op)\n",
    "print(f\"Parity:\")\n",
    "print(f\"  ||[H, P]||_F = {comm_parity:.6e}\")\n",
    "print(f\"  ||H||_F = {H_norm:.6e}\")\n",
    "print(f\"  Relative error: {comm_parity / H_norm:.6e}\")\n",
    "print(f\"  Commutes: {'YES' if comm_parity / H_norm < 1e-10 else 'NO'}\\n\")\n",
    "\n",
    "# Additional check: verify P^2 = Identity\n",
    "P_squared = P_op @ P_op\n",
    "Id_op = eye(1 << N, dtype=np.complex128, format='csr')   # <-- use eye(), don't shadow identity()\n",
    "\n",
    "# FIX: subtract the matrix Id_op (not the identity function) and handle sparse/dense norm\n",
    "diff = P_squared - Id_op\n",
    "if issparse(diff):\n",
    "    P_identity_error = np.sqrt((diff.multiply(diff.conj())).sum())\n",
    "else:\n",
    "    P_identity_error = np.linalg.norm(diff, 'fro')\n",
    "# ...existing code...\n",
    "print(f\"Operator properties:\")\n",
    "print(f\"  ||P^2 - I||_F = {P_identity_error:.6e}\")\n",
    "print(f\"  P is involutory: {'YES' if P_identity_error < 1e-10 else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a987b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bonds: 30\n",
      "Loaded 120 I_h permutations on 20 sites.\n",
      "Number of automorphisms wrt your bonds: 120\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Dodecahedron bonds (current labelling)\n",
    "# ============================================================\n",
    "\n",
    "bonds = [(0, 13), (0, 14), (0, 15), (1, 4), (1, 5), (1, 12),\n",
    "    (2, 6), (2, 13), (2, 18), (3, 7), (3, 14), (3, 19),\n",
    "    (4, 10), (4, 18), (5, 11), (5, 19), (6, 10), (6, 15),\n",
    "    (7, 11), (7, 15), (8, 9), (8, 13), (8, 16), (9, 14), (9, 17),\n",
    "    (10, 11), (12, 16), (12, 17), (16, 18), (17, 19)]\n",
    "\n",
    "bonds_set = {tuple(sorted(e)) for e in bonds}\n",
    "print(\"Number of bonds:\", len(bonds_set))\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load Ih permutations from file\n",
    "# ============================================================\n",
    "\n",
    "def load_ih_permutations(path=\"ih_dodeca_permutations_0based.txt\"):\n",
    "    \"\"\"\n",
    "    Each line in ih_dodeca_permutations_0based.txt represents a permutation on vertices 0..19.\n",
    "    \"\"\"\n",
    "    perms = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            nums = line.strip('[]').split(',')\n",
    "            perms.append(np.array([int(x) for x in nums], dtype=int))\n",
    "    return perms\n",
    "\n",
    "perms = load_ih_permutations(\"ih_dodeca_permutations_0based.txt\")\n",
    "N_sites = len(perms[0])\n",
    "print(f\"Loaded {len(perms)} I_h permutations on {N_sites} sites.\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Graph automorphism checker (sanity)\n",
    "# ============================================================\n",
    "\n",
    "def is_automorphism(perm, bonds_set):\n",
    "    \"\"\"\n",
    "    Check if 'perm' is a graph automorphism of the icosahedron\n",
    "    defined by bonds_set, i.e. maps edges to edges.\n",
    "    \"\"\"\n",
    "    for i, j in bonds_set:\n",
    "        ii, jj = perm[i], perm[j]\n",
    "        if tuple(sorted((ii, jj))) not in bonds_set:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "num_auto = sum(is_automorphism(p, bonds_set) for p in perms)\n",
    "print(\"Number of automorphisms wrt your bonds:\", num_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "587d6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bonds: 30\n",
      "Loaded 120 I_h permutations on 20 sites.\n",
      "Number of automorphisms wrt your bonds: 120\n",
      "Found 10 conjugacy classes in new labelling.\n",
      "class 0: size=12, order=10\n",
      "class 1: size=15, order= 2\n",
      "class 2: size=20, order= 6\n",
      "class 3: size=20, order= 3\n",
      "class 4: size=12, order= 5\n",
      "class 5: size=15, order= 2\n",
      "class 6: size=12, order=10\n",
      "class 7: size=12, order= 5\n",
      "class 8: size= 1, order= 2\n",
      "class 9: size= 1, order= 1\n",
      "\n",
      "Checking a few U_g for unitarity and permutation structure...\n",
      "Number of nonzeros in Ug†Ug - I: 0\n",
      "All tests passed for this Ug.\n",
      "Number of nonzeros in Ug†Ug - I: 0\n",
      "All tests passed for this Ug.\n",
      "Number of nonzeros in Ug†Ug - I: 0\n",
      "All tests passed for this Ug.\n",
      "\n",
      "Number of distinct trace values: 6\n",
      "Distinct values: [4, 16, 256, 1024, 4096, 1048576]\n",
      "Counts per trace:\n",
      "  trace=4: 24\n",
      "  trace=16: 44\n",
      "  trace=256: 20\n",
      "  trace=1024: 16\n",
      "  trace=4096: 15\n",
      "  trace=1048576: 1\n",
      "\n",
      "Raw class summary (index, size, order, chi):\n",
      "{'idx': 0, 'size': 12, 'order': 10, 'chi': 4.0}\n",
      "{'idx': 1, 'size': 15, 'order': 2, 'chi': 1024.0}\n",
      "{'idx': 2, 'size': 20, 'order': 6, 'chi': 16.0}\n",
      "{'idx': 3, 'size': 20, 'order': 3, 'chi': 256.0}\n",
      "{'idx': 4, 'size': 12, 'order': 5, 'chi': 16.0}\n",
      "{'idx': 5, 'size': 15, 'order': 2, 'chi': 4096.0}\n",
      "{'idx': 6, 'size': 12, 'order': 10, 'chi': 4.0}\n",
      "{'idx': 7, 'size': 12, 'order': 5, 'chi': 16.0}\n",
      "{'idx': 8, 'size': 1, 'order': 2, 'chi': 1024.0}\n",
      "{'idx': 9, 'size': 1, 'order': 1, 'chi': 1048576.0}\n",
      "\n",
      "By (size, order):\n",
      "  (12, 10): indices [0, 6]\n",
      "  (15, 2): indices [1, 5]\n",
      "  (20, 6): indices [2]\n",
      "  (20, 3): indices [3]\n",
      "  (12, 5): indices [4, 7]\n",
      "  (1, 2): indices [8]\n",
      "  (1, 1): indices [9]\n",
      "\n",
      "Automatic identification:\n",
      " E:   9\n",
      " i:   8\n",
      " C5:  [4, 7]\n",
      " S10: [0, 6]\n",
      " C3:  3\n",
      " S6:  2\n",
      " 15-classes (C2, σ) candidates: [1, 5]\n",
      "\n",
      "Distinguishing C2 vs σ by trace:\n",
      "  Class 1: χ_red = 1024.0\n",
      "  Class 5: χ_red = 4096.0\n",
      "  → Class 5 is σ (trace=4096, 12 cycles)\n",
      "  → Class 1 is C2 (trace=1024, 10 cycles)\n",
      "\n",
      "12C5 classes (same trace, check consistency):\n",
      "  Class 4: χ_red = 16.0\n",
      "  Class 7: χ_red = 16.0\n",
      "\n",
      "12S10 classes (same trace, check consistency):\n",
      "  Class 0: χ_red = 4.0\n",
      "  Class 6: χ_red = 4.0\n",
      "\n",
      "============================================================\n",
      "Trying assignment:\n",
      "  C2 -> class 1 (trace=1024.0)\n",
      "  σ  -> class 5 (trace=4096.0)\n",
      "  12C5 -> class 4\n",
      "  12C5² -> class 7\n",
      "  12S10 -> class 0\n",
      "  12(S10)³ -> class 6\n",
      "Class sizes: [ 1 12 12 20 15  1 12 12 20 15]\n",
      "chi_red: [1.048576e+06 1.600000e+01 1.600000e+01 2.560000e+02 1.024000e+03\n",
      " 1.024000e+03 4.000000e+00 4.000000e+00 1.600000e+01 4.096000e+03]\n",
      "Raw multiplicities: [ 9436. 25602. 25602. 35028. 44328.  8388. 26574. 26574. 34956. 43224.]\n",
      "Rounded multiplicities: [ 9436 25602 25602 35028 44328  8388 26574 26574 34956 43224]\n",
      "Max deviation from integer: 0.0\n",
      "∑ n_Γ d_Γ = 1048576 (expect 2^N = 1048576 )\n",
      "=> This assignment is CONSISTENT ✓\n",
      "\n",
      "============================================================\n",
      "Trying assignment:\n",
      "  C2 -> class 1 (trace=1024.0)\n",
      "  σ  -> class 5 (trace=4096.0)\n",
      "  12C5 -> class 4\n",
      "  12C5² -> class 7\n",
      "  12S10 -> class 6\n",
      "  12(S10)³ -> class 0\n",
      "Class sizes: [ 1 12 12 20 15  1 12 12 20 15]\n",
      "chi_red: [1.048576e+06 1.600000e+01 1.600000e+01 2.560000e+02 1.024000e+03\n",
      " 1.024000e+03 4.000000e+00 4.000000e+00 1.600000e+01 4.096000e+03]\n",
      "Raw multiplicities: [ 9436. 25602. 25602. 35028. 44328.  8388. 26574. 26574. 34956. 43224.]\n",
      "Rounded multiplicities: [ 9436 25602 25602 35028 44328  8388 26574 26574 34956 43224]\n",
      "Max deviation from integer: 0.0\n",
      "∑ n_Γ d_Γ = 1048576 (expect 2^N = 1048576 )\n",
      "=> This assignment is CONSISTENT ✓\n",
      "\n",
      "============================================================\n",
      "Trying assignment:\n",
      "  C2 -> class 1 (trace=1024.0)\n",
      "  σ  -> class 5 (trace=4096.0)\n",
      "  12C5 -> class 7\n",
      "  12C5² -> class 4\n",
      "  12S10 -> class 0\n",
      "  12(S10)³ -> class 6\n",
      "Class sizes: [ 1 12 12 20 15  1 12 12 20 15]\n",
      "chi_red: [1.048576e+06 1.600000e+01 1.600000e+01 2.560000e+02 1.024000e+03\n",
      " 1.024000e+03 4.000000e+00 4.000000e+00 1.600000e+01 4.096000e+03]\n",
      "Raw multiplicities: [ 9436. 25602. 25602. 35028. 44328.  8388. 26574. 26574. 34956. 43224.]\n",
      "Rounded multiplicities: [ 9436 25602 25602 35028 44328  8388 26574 26574 34956 43224]\n",
      "Max deviation from integer: 0.0\n",
      "∑ n_Γ d_Γ = 1048576 (expect 2^N = 1048576 )\n",
      "=> This assignment is CONSISTENT ✓\n",
      "\n",
      "============================================================\n",
      "Trying assignment:\n",
      "  C2 -> class 1 (trace=1024.0)\n",
      "  σ  -> class 5 (trace=4096.0)\n",
      "  12C5 -> class 7\n",
      "  12C5² -> class 4\n",
      "  12S10 -> class 6\n",
      "  12(S10)³ -> class 0\n",
      "Class sizes: [ 1 12 12 20 15  1 12 12 20 15]\n",
      "chi_red: [1.048576e+06 1.600000e+01 1.600000e+01 2.560000e+02 1.024000e+03\n",
      " 1.024000e+03 4.000000e+00 4.000000e+00 1.600000e+01 4.096000e+03]\n",
      "Raw multiplicities: [ 9436. 25602. 25602. 35028. 44328.  8388. 26574. 26574. 34956. 43224.]\n",
      "Rounded multiplicities: [ 9436 25602 25602 35028 44328  8388 26574 26574 34956 43224]\n",
      "Max deviation from integer: 0.0\n",
      "∑ n_Γ d_Γ = 1048576 (expect 2^N = 1048576 )\n",
      "=> This assignment is CONSISTENT ✓\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Dodecahedron bonds (current labelling)\n",
    "# ============================================================\n",
    "\n",
    "bonds = [(0, 13), (0, 14), (0, 15), (1, 4), (1, 5), (1, 12),\n",
    "    (2, 6), (2, 13), (2, 18), (3, 7), (3, 14), (3, 19),\n",
    "    (4, 10), (4, 18), (5, 11), (5, 19), (6, 10), (6, 15),\n",
    "    (7, 11), (7, 15), (8, 9), (8, 13), (8, 16), (9, 14), (9, 17),\n",
    "    (10, 11), (12, 16), (12, 17), (16, 18), (17, 19)]\n",
    "\n",
    "bonds_set = {tuple(sorted(e)) for e in bonds}\n",
    "print(\"Number of bonds:\", len(bonds_set))\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load Ih permutations from file\n",
    "# ============================================================\n",
    "\n",
    "def load_ih_permutations(path=\"ih_dodeca_permutations_0based.txt\"):\n",
    "    \"\"\"\n",
    "    Each line in ih_dodeca_permutations_0based.txt represents a permutation on vertices 0..19.\n",
    "    \"\"\"\n",
    "    perms = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            nums = line.strip('[]').split(',')\n",
    "            perms.append(np.array([int(x) for x in nums], dtype=int))\n",
    "    return perms\n",
    "\n",
    "perms = load_ih_permutations(\"ih_dodeca_permutations_0based.txt\")\n",
    "N_sites = len(perms[0])\n",
    "print(f\"Loaded {len(perms)} I_h permutations on {N_sites} sites.\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Graph automorphism checker (sanity)\n",
    "# ============================================================\n",
    "\n",
    "def is_automorphism(perm, bonds_set):\n",
    "    \"\"\"\n",
    "    Check if 'perm' is a graph automorphism of the dodecahedron\n",
    "    defined by bonds_set, i.e. maps edges to edges.\n",
    "    \"\"\"\n",
    "    for i, j in bonds_set:\n",
    "        ii, jj = perm[i], perm[j]\n",
    "        if tuple(sorted((ii, jj))) not in bonds_set:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "num_auto = sum(is_automorphism(p, bonds_set) for p in perms)\n",
    "print(\"Number of automorphisms wrt your bonds:\", num_auto)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Permutation utilities & conjugacy classes of I_h\n",
    "# ============================================================\n",
    "\n",
    "def perm_compose(p, q):\n",
    "    \"\"\"\n",
    "    Composition p ∘ q acting on indices [0..N-1]:\n",
    "    result r satisfies r[i] = p[q[i]].\n",
    "    \"\"\"\n",
    "    return p[q]\n",
    "\n",
    "def perm_inverse(p):\n",
    "    \"\"\"Inverse permutation p^{-1}.\"\"\"\n",
    "    inv = np.empty_like(p)\n",
    "    inv[p] = np.arange(len(p))\n",
    "    return inv\n",
    "\n",
    "def perm_order(p, max_iter=300):\n",
    "    \"\"\"Order of permutation p: smallest k>0 with p^k = identity.\"\"\"\n",
    "    n = len(p)\n",
    "    e = np.arange(n)\n",
    "    x = p.copy()\n",
    "    k = 1\n",
    "    while not np.array_equal(x, e):\n",
    "        x = perm_compose(x, p)\n",
    "        k += 1\n",
    "        if k > max_iter:\n",
    "            raise RuntimeError(\"Permutation order too large?\")\n",
    "    return k\n",
    "\n",
    "def compute_conjugacy_classes(perms):\n",
    "    \"\"\"\n",
    "    Compute conjugacy classes of the group represented by 'perms'\n",
    "    via g -> h g h^{-1}.\n",
    "    \"\"\"\n",
    "    perms_tuples = [tuple(p.tolist()) for p in perms]\n",
    "    perm_dict = {pt: p for pt, p in zip(perms_tuples, perms)}\n",
    "\n",
    "    unseen = set(perms_tuples)\n",
    "    classes = []\n",
    "\n",
    "    while unseen:\n",
    "        rep_t = unseen.pop()\n",
    "        rep = perm_dict[rep_t]\n",
    "        current = set()\n",
    "\n",
    "        for h_t, h in perm_dict.items():\n",
    "            h_inv = perm_inverse(h)\n",
    "            conj = perm_compose(h, perm_compose(rep, h_inv))\n",
    "            conj_t = tuple(conj.tolist())\n",
    "            if conj_t in perm_dict:\n",
    "                current.add(conj_t)\n",
    "\n",
    "        for ct in current:\n",
    "            unseen.discard(ct)\n",
    "\n",
    "        class_perms = [perm_dict[ct] for ct in current]\n",
    "        classes.append(class_perms)\n",
    "\n",
    "    return classes\n",
    "\n",
    "classes = compute_conjugacy_classes(perms)\n",
    "print(f\"Found {len(classes)} conjugacy classes in new labelling.\")\n",
    "for i, cls in enumerate(classes):\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    print(f\"class {i}: size={size:2d}, order={order:2d}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Build Hilbert-space operator U_g for a permutation g\n",
    "#    (big-endian convention, site 0 = most significant bit)\n",
    "# ============================================================\n",
    "\n",
    "def build_symmetry_operator(N_spins, perm):\n",
    "    \"\"\"\n",
    "    U |s_0 ... s_{N-1}> = |s_{perm(0)} ... s_{perm(N-1)}|\n",
    "    with site 0 as the left-most tensor factor (MSB).\n",
    "    \"\"\"\n",
    "    D = 1 << N_spins\n",
    "    rows = np.empty(D, dtype=np.int64)\n",
    "    cols = np.arange(D, dtype=np.int64)\n",
    "\n",
    "    for b in range(D):\n",
    "        # decode: big-endian, site 0 = most significant bit\n",
    "        bits = [(b >> (N_spins - 1 - i)) & 1 for i in range(N_spins)]\n",
    "\n",
    "        # permute sites\n",
    "        permuted_bits = [bits[perm[i]] for i in range(N_spins)]\n",
    "\n",
    "        # re-encode in the same big-endian convention\n",
    "        b_prime = 0\n",
    "        for i in range(N_spins):\n",
    "            b_prime |= permuted_bits[i] << (N_spins - 1 - i)\n",
    "\n",
    "        rows[b] = b_prime\n",
    "\n",
    "    data = np.ones(D, dtype=np.int8)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(D, D))\n",
    "\n",
    "def check_Ug(N_spins, Ug):\n",
    "    \"\"\"\n",
    "    Sanity checks: shape, permutation structure, and unitarity Ug† Ug = I.\n",
    "    \"\"\"\n",
    "    dim = 1 << N_spins\n",
    "\n",
    "    # 1. Size\n",
    "    assert Ug.shape == (dim, dim), f\"Ug has wrong shape: {Ug.shape}\"\n",
    "\n",
    "    # 2. Permutation structure: exactly one nonzero per row and column\n",
    "    nnz_per_row = Ug.getnnz(axis=1)\n",
    "    nnz_per_col = Ug.getnnz(axis=0)\n",
    "    assert np.all(nnz_per_row == 1), \"Some rows do not have exactly one '1'\"\n",
    "    assert np.all(nnz_per_col == 1), \"Some columns do not have exactly one '1'\"\n",
    "\n",
    "    # 3. Unitarity: Ug† Ug = I\n",
    "    Id = eye(dim, dtype=np.complex128, format='csr')\n",
    "    diff = (Ug.conj().T @ Ug) - Id\n",
    "    print(\"Number of nonzeros in Ug†Ug - I:\", diff.nnz)\n",
    "    if diff.nnz != 0:\n",
    "        raise ValueError(\"Ug is not unitary: Ug†Ug - I has nonzero entries\")\n",
    "\n",
    "    print(\"All tests passed for this Ug.\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. Build all Ugs, check a few, and collect traces\n",
    "# ============================================================\n",
    "\n",
    "N_spins = N_sites  # 12 for icosahedron\n",
    "dim = 1 << N_spins\n",
    "\n",
    "Ugs = [build_symmetry_operator(N_spins, perm) for perm in perms]\n",
    "\n",
    "traces = []\n",
    "print(\"\\nChecking a few U_g for unitarity and permutation structure...\")\n",
    "for i, Ug in enumerate(Ugs):\n",
    "    if i < 3:\n",
    "        check_Ug(N_spins, Ug)\n",
    "    tr = Ug.diagonal().sum()\n",
    "    traces.append(int(round(float(np.real(tr)))))\n",
    "\n",
    "unique_traces = sorted(set(traces))\n",
    "print(f\"\\nNumber of distinct trace values: {len(unique_traces)}\")\n",
    "print(f\"Distinct values: {unique_traces}\")\n",
    "\n",
    "counts = Counter(traces)\n",
    "print(\"Counts per trace:\")\n",
    "for val in unique_traces:\n",
    "    print(f\"  trace={val}: {counts[val]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. Build class operators C_k = sum_{g in class_k} U_g\n",
    "# ============================================================\n",
    "\n",
    "def build_class_operators(N_spins, classes):\n",
    "    \"\"\"\n",
    "    Build class operators C_k = sum_{g in class_k} U_g.\n",
    "    Returns a list of sparse CSR matrices.\n",
    "    \"\"\"\n",
    "    class_ops = []\n",
    "    for class_perms in classes:\n",
    "        U_sum = None\n",
    "        for perm in class_perms:\n",
    "            U_g = build_symmetry_operator(N_spins, perm)\n",
    "            if U_sum is None:\n",
    "                U_sum = U_g.astype(np.complex128, copy=True).tocsr()\n",
    "            else:\n",
    "                U_sum = U_sum + U_g.tocsr()\n",
    "        class_ops.append(U_sum.tocsr())\n",
    "    return class_ops\n",
    "\n",
    "# ============================================================\n",
    "# 7. Optional: commutator norm checks with H, Hi, Htf\n",
    "# ============================================================\n",
    "\n",
    "def comm_norm(A, B):\n",
    "    \"\"\"Sparse Frobenius norm of commutator [A,B].\"\"\"\n",
    "    C = A @ B - B @ A\n",
    "    return np.sqrt((C.multiply(C.conj())).sum())\n",
    "\n",
    "# ============================================================\n",
    "# 8. Compute class data: size, order, χ_red for each conjugacy class\n",
    "# ============================================================\n",
    "\n",
    "def trace_from_perm(perm):\n",
    "    Ug = build_symmetry_operator(N_spins, perm)\n",
    "    return float(Ug.diagonal().sum())\n",
    "\n",
    "class_data = []\n",
    "for idx, cls in enumerate(classes):\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    chi = trace_from_perm(cls[0])\n",
    "    class_data.append({\n",
    "        \"idx\": idx,\n",
    "        \"size\": size,\n",
    "        \"order\": order,\n",
    "        \"chi\": chi,\n",
    "    })\n",
    "\n",
    "print(\"\\nRaw class summary (index, size, order, chi):\")\n",
    "for cd in class_data:\n",
    "    print(cd)\n",
    "\n",
    "def find_by(size=None, order=None):\n",
    "    return [cd[\"idx\"] for cd in class_data\n",
    "            if (size is None or cd[\"size\"] == size)\n",
    "            and (order is None or cd[\"order\"] == order)]\n",
    "\n",
    "print(\"\\nBy (size, order):\")\n",
    "sizes_orders = {}\n",
    "for cd in class_data:\n",
    "    key = (cd[\"size\"], cd[\"order\"])\n",
    "    sizes_orders.setdefault(key, []).append(cd[\"idx\"])\n",
    "for k, v in sizes_orders.items():\n",
    "    print(f\"  {k}: indices {v}\")\n",
    "\n",
    "# ============================================================\n",
    "# 9. Automatically build Ih standard order from class_data\n",
    "#    Standard order: (E, 12C5, 12C5^2, 20C3, 15C2, i, 12S10, 12(S10)^3, 20S6, 15σ)\n",
    "# ============================================================\n",
    "\n",
    "idx_E_list   = find_by(size=1,  order=1)\n",
    "idx_i_list   = find_by(size=1,  order=2)\n",
    "idx_C5_list  = find_by(size=12, order=5)\n",
    "idx_S10_list = find_by(size=12, order=10)\n",
    "idx_C3_list  = find_by(size=20, order=3)\n",
    "idx_S6_list  = find_by(size=20, order=6)\n",
    "idx_15_list  = find_by(size=15, order=2)\n",
    "\n",
    "assert len(idx_E_list)   == 1, \"Expected 1 identity class\"\n",
    "assert len(idx_i_list)   == 1, \"Expected 1 inversion class\"\n",
    "assert len(idx_C5_list)  == 2, \"Expected two 5-fold rotation classes\"\n",
    "assert len(idx_S10_list) == 2, \"Expected two S10 classes\"\n",
    "assert len(idx_C3_list)  == 1, \"Expected one 20C3 class\"\n",
    "assert len(idx_S6_list)  == 1, \"Expected one 20S6 class\"\n",
    "assert len(idx_15_list)  == 2, \"Expected two 15-element classes\"\n",
    "\n",
    "idx_E  = idx_E_list[0]\n",
    "idx_i  = idx_i_list[0]\n",
    "idx_C3 = idx_C3_list[0]\n",
    "idx_S6 = idx_S6_list[0]\n",
    "idx_C5_a, idx_C5_b     = idx_C5_list\n",
    "idx_S10_a, idx_S10_b   = idx_S10_list\n",
    "idx_15_a, idx_15_b     = idx_15_list\n",
    "\n",
    "print(\"\\nAutomatic identification:\")\n",
    "print(\" E:  \", idx_E)\n",
    "print(\" i:  \", idx_i)\n",
    "print(\" C5: \", idx_C5_list)\n",
    "print(\" S10:\", idx_S10_list)\n",
    "print(\" C3: \", idx_C3)\n",
    "print(\" S6: \", idx_S6)\n",
    "print(\" 15-classes (C2, σ) candidates:\", idx_15_list)\n",
    "\n",
    "# ============================================================\n",
    "# 10. Character table of Ih (in standard column order)\n",
    "# ============================================================\n",
    "\n",
    "w  = 2.0 * np.pi / 5.0\n",
    "c2 = np.cos(2*w)   # cos(4π/5)\n",
    "c1 = np.cos(1*w)   # cos(2π/5)\n",
    "\n",
    "chi_irreps = np.array([\n",
    "    # E,   12C5,     12C5^2,   20C3,  15C2,  i,    12S10,    12(S10)^3, 20S6,  15σ\n",
    "    [1,    1,        1,        1,     1,     1,    1,        1,        1,     1],       # Ag\n",
    "    [3,   -2*c2,    -2*c1,     0,    -1,     3,   -2*c1,    -2*c2,     0,    -1],       # T1g\n",
    "    [3,   -2*c1,    -2*c2,     0,    -1,     3,   -2*c2,    -2*c1,     0,    -1],       # T2g\n",
    "    [4,   -1,       -1,        1,     0,     4,   -1,       -1,        1,     0],       # Gg\n",
    "    [5,    0,        0,       -1,     1,     5,    0,        0,       -1,     1],       # Hg\n",
    "    [1,    1,        1,        1,     1,    -1,   -1,       -1,       -1,    -1],       # Au\n",
    "    [3,   -2*c2,    -2*c1,     0,    -1,    -3,    2*c1,     2*c2,     0,     1],       # T1u\n",
    "    [3,   -2*c1,    -2*c2,     0,    -1,    -3,    2*c2,     2*c1,     0,     1],       # T2u\n",
    "    [4,   -1,       -1,        1,     0,    -4,    1,        1,       -1,     0],       # Gu\n",
    "    [5,    0,        0,       -1,     1,    -5,    0,        0,        1,    -1],       # Hu\n",
    "], dtype=float)\n",
    "\n",
    "irrep_labels = [\"Ag\", \"T1g\", \"T2g\", \"Gg\", \"Hg\",\n",
    "                \"Au\", \"T1u\", \"T2u\", \"Gu\", \"Hu\"]\n",
    "\n",
    "G_order = 120\n",
    "\n",
    "# ============================================================\n",
    "# 11. Distinguish C2 vs σ by trace, then try all combinations\n",
    "#     for C5/C5² and S10/(S10)³\n",
    "# ============================================================\n",
    "\n",
    "# Distinguish C2 vs σ by trace:\n",
    "# - σ (reflection) has 8 cycles → trace = 2^12 = 4096\n",
    "# - C2 (rotation) has 6 cycles → trace = 2^10 = 1024\n",
    "\n",
    "chi_15_a = trace_from_perm(classes[idx_15_a][0])\n",
    "chi_15_b = trace_from_perm(classes[idx_15_b][0])\n",
    "\n",
    "print(f\"\\nDistinguishing C2 vs σ by trace:\")\n",
    "print(f\"  Class {idx_15_a}: χ_red = {chi_15_a}\")\n",
    "print(f\"  Class {idx_15_b}: χ_red = {chi_15_b}\")\n",
    "\n",
    "if abs(chi_15_a - 4096) < 1e-6:\n",
    "    idx_sigma = idx_15_a\n",
    "    idx_C2 = idx_15_b\n",
    "    print(f\"  → Class {idx_15_a} is σ (trace=4096, 12 cycles)\")\n",
    "    print(f\"  → Class {idx_15_b} is C2 (trace=1024, 10 cycles)\")\n",
    "elif abs(chi_15_b - 4096) < 1e-6:\n",
    "    idx_sigma = idx_15_b\n",
    "    idx_C2 = idx_15_a\n",
    "    print(f\"  → Class {idx_15_b} is σ (trace=4096, 12 cycles)\")\n",
    "    print(f\"  → Class {idx_15_a} is C2 (trace=1024, 10 cycles)\")\n",
    "else:\n",
    "    raise ValueError(\"Cannot identify σ by trace=4096\")\n",
    "\n",
    "# C5/C5² and S10/(S10)³ have same trace, so check consistency\n",
    "chi_C5_a = trace_from_perm(classes[idx_C5_a][0])\n",
    "chi_C5_b = trace_from_perm(classes[idx_C5_b][0])\n",
    "print(f\"\\n12C5 classes (same trace, check consistency):\")\n",
    "print(f\"  Class {idx_C5_a}: χ_red = {chi_C5_a}\")\n",
    "print(f\"  Class {idx_C5_b}: χ_red = {chi_C5_b}\")\n",
    "\n",
    "chi_S10_a = trace_from_perm(classes[idx_S10_a][0])\n",
    "chi_S10_b = trace_from_perm(classes[idx_S10_b][0])\n",
    "print(f\"\\n12S10 classes (same trace, check consistency):\")\n",
    "print(f\"  Class {idx_S10_a}: χ_red = {chi_S10_a}\")\n",
    "print(f\"  Class {idx_S10_b}: χ_red = {chi_S10_b}\")\n",
    "\n",
    "def compute_multiplicities(class_sizes, chi_red):\n",
    "    \"\"\"Compute irrep multiplicities using character orthogonality.\"\"\"\n",
    "    multiplicities = []\n",
    "    for i in range(len(irrep_labels)):\n",
    "        chi_Gamma = chi_irreps[i]\n",
    "        n_Gamma = (class_sizes * chi_red * chi_Gamma).sum() / G_order\n",
    "        multiplicities.append(n_Gamma)\n",
    "    return np.array(multiplicities, dtype=float)\n",
    "\n",
    "# Try all possible assignments for C5/C5² and S10/(S10)³\n",
    "solutions = []\n",
    "\n",
    "for (idx_C5_1, idx_C5_2) in [(idx_C5_a, idx_C5_b), (idx_C5_b, idx_C5_a)]:\n",
    "    for (idx_S10_1, idx_S10_2) in [(idx_S10_a, idx_S10_b), (idx_S10_b, idx_S10_a)]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Trying assignment:\")\n",
    "        print(f\"  C2 -> class {idx_C2} (trace={chi_15_a if idx_C2==idx_15_a else chi_15_b})\")\n",
    "        print(f\"  σ  -> class {idx_sigma} (trace={chi_15_a if idx_sigma==idx_15_a else chi_15_b})\")\n",
    "        print(f\"  12C5 -> class {idx_C5_1}\")\n",
    "        print(f\"  12C5² -> class {idx_C5_2}\")\n",
    "        print(f\"  12S10 -> class {idx_S10_1}\")\n",
    "        print(f\"  12(S10)³ -> class {idx_S10_2}\")\n",
    "        \n",
    "        ordered_indices = [\n",
    "            idx_E,\n",
    "            idx_C5_1,\n",
    "            idx_C5_2,\n",
    "            idx_C3,\n",
    "            idx_C2,\n",
    "            idx_i,\n",
    "            idx_S10_1,\n",
    "            idx_S10_2,\n",
    "            idx_S6,\n",
    "            idx_sigma,\n",
    "        ]\n",
    "        \n",
    "        class_sizes = np.zeros(10, dtype=int)\n",
    "        chi_red = np.zeros(10, dtype=float)\n",
    "        for k, class_idx in enumerate(ordered_indices):\n",
    "            cls = classes[class_idx]\n",
    "            class_sizes[k] = len(cls)\n",
    "            rep_perm = cls[0]\n",
    "            chi_red[k] = trace_from_perm(rep_perm)\n",
    "        \n",
    "        print(\"Class sizes:\", class_sizes)\n",
    "        print(\"chi_red:\", chi_red)\n",
    "\n",
    "        mult = compute_multiplicities(class_sizes, chi_red)\n",
    "        mult_rounded = np.round(mult).astype(int)\n",
    "        max_dev = np.max(np.abs(mult - mult_rounded))\n",
    "        \n",
    "        print(\"Raw multiplicities:\", mult)\n",
    "        print(\"Rounded multiplicities:\", mult_rounded)\n",
    "        print(\"Max deviation from integer:\", max_dev)\n",
    "\n",
    "        dims_irreps = np.array([1, 3, 3, 4, 5, 1, 3, 3, 4, 5], dtype=int)\n",
    "        dim_check = (mult_rounded * dims_irreps).sum()\n",
    "        print(\"∑ n_Γ d_Γ =\", dim_check, \"(expect 2^N =\", 1 << N_spins, \")\")\n",
    "\n",
    "        ok = (max_dev < 1e-6) and (dim_check == (1 << N_spins)) and np.all(mult_rounded >= 0)\n",
    "        if ok:\n",
    "            print(\"=> This assignment is CONSISTENT ✓\")\n",
    "            solutions.append({\n",
    "                \"idx_C2\": idx_C2,\n",
    "                \"idx_sigma\": idx_sigma,\n",
    "                \"idx_C5_1\": idx_C5_1,\n",
    "                \"idx_C5_2\": idx_C5_2,\n",
    "                \"idx_S10_1\": idx_S10_1,\n",
    "                \"idx_S10_2\": idx_S10_2,\n",
    "                \"ordered_indices\": ordered_indices,\n",
    "                \"class_sizes\": class_sizes,\n",
    "                \"chi_red\": chi_red,\n",
    "                \"multiplicities\": mult_rounded,\n",
    "            })\n",
    "        else:\n",
    "            print(\"=> This assignment is NOT consistent ✗\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244f6f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 consistent assignment(s)\n",
      "\n",
      "=== Final assignment (C2/σ by trace, C5/S10 by consistency) ===\n",
      "C2  class index: 1\n",
      "sigma class index: 5\n",
      "12C5 class index: 7\n",
      "12C5² class index: 4\n",
      "12S10 class index: 0\n",
      "12(S10)³ class index: 6\n",
      "Class sizes (Ih order): [ 1 12 12 20 15  1 12 12 20 15]\n",
      "chi_red (Ih order): [1.048576e+06 1.600000e+01 1.600000e+01 2.560000e+02 1.024000e+03\n",
      " 1.024000e+03 4.000000e+00 4.000000e+00 1.600000e+01 4.096000e+03]\n",
      "\n",
      "Irrep multiplicities:\n",
      "  Ag: n = 9436\n",
      "  T1g: n = 25602\n",
      "  T2g: n = 25602\n",
      "  Gg: n = 35028\n",
      "  Hg: n = 44328\n",
      "  Au: n = 8388\n",
      "  T1u: n = 26574\n",
      "  T2u: n = 26574\n",
      "  Gu: n = 34956\n",
      "  Hu: n = 43224\n",
      "\n",
      "Check ∑ n_Γ d_Γ = 1048576   (should be 2^N = 1048576 )\n",
      "\n",
      "=== Full Ih character table (χ_Γ(C)) in our ordering ===\n",
      "irrep \\ class          E       12C5     12C5^2       20C3       15C2          i      12S10  12(S10)^3       20S6        15σ\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "Ag             1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000\n",
      "T1g            3.0000     1.6180    -0.6180     0.0000    -1.0000     3.0000    -0.6180     1.6180     0.0000    -1.0000\n",
      "T2g            3.0000    -0.6180     1.6180     0.0000    -1.0000     3.0000     1.6180    -0.6180     0.0000    -1.0000\n",
      "Gg             4.0000    -1.0000    -1.0000     1.0000     0.0000     4.0000    -1.0000    -1.0000     1.0000     0.0000\n",
      "Hg             5.0000     0.0000     0.0000    -1.0000     1.0000     5.0000     0.0000     0.0000    -1.0000     1.0000\n",
      "Au             1.0000     1.0000     1.0000     1.0000     1.0000    -1.0000    -1.0000    -1.0000    -1.0000    -1.0000\n",
      "T1u            3.0000     1.6180    -0.6180     0.0000    -1.0000    -3.0000     0.6180    -1.6180     0.0000     1.0000\n",
      "T2u            3.0000    -0.6180     1.6180     0.0000    -1.0000    -3.0000    -1.6180     0.6180     0.0000     1.0000\n",
      "Gu             4.0000    -1.0000    -1.0000     1.0000     0.0000    -4.0000     1.0000     1.0000    -1.0000     0.0000\n",
      "Hu             5.0000     0.0000     0.0000    -1.0000     1.0000    -5.0000     0.0000     0.0000     1.0000    -1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(solutions)} consistent assignment(s)\")\n",
    "\n",
    "if not solutions:\n",
    "    raise RuntimeError(\"No consistent assignment found.\")\n",
    "else:\n",
    "    sol = solutions[2]  # solutions[1] is also valid\n",
    "\n",
    "    print(\"\\n=== Final assignment (C2/σ by trace, C5/S10 by consistency) ===\")\n",
    "    print(f\"C2  class index: {sol['idx_C2']}\")\n",
    "    print(f\"sigma class index: {sol['idx_sigma']}\")\n",
    "    print(f\"12C5 class index: {sol['idx_C5_1']}\")\n",
    "    print(f\"12C5² class index: {sol['idx_C5_2']}\")\n",
    "    print(f\"12S10 class index: {sol['idx_S10_1']}\")\n",
    "    print(f\"12(S10)³ class index: {sol['idx_S10_2']}\")\n",
    "    print(\"Class sizes (Ih order):\", sol[\"class_sizes\"])\n",
    "    print(\"chi_red (Ih order):\", sol[\"chi_red\"])\n",
    "    print(\"\\nIrrep multiplicities:\")\n",
    "    for label, n in zip(irrep_labels, sol[\"multiplicities\"]):\n",
    "        print(f\"  {label}: n = {n}\")\n",
    "\n",
    "    dims_irreps = np.array([1, 3, 3, 4, 5, 1, 3, 3, 4, 5], dtype=int)\n",
    "    print(\"\\nCheck ∑ n_Γ d_Γ =\",\n",
    "          (sol[\"multiplicities\"] * dims_irreps).sum(),\n",
    "          \"  (should be 2^N =\", 1 << N_spins, \")\")\n",
    "\n",
    "# ============================================================\n",
    "# 12. Character table in our ordering\n",
    "# ============================================================\n",
    "\n",
    "class_labels = [\n",
    "    \"E\", \"12C5\", \"12C5^2\", \"20C3\", \"15C2\",\n",
    "    \"i\", \"12S10\", \"12(S10)^3\", \"20S6\", \"15σ\",\n",
    "]\n",
    "\n",
    "print(\"\\n=== Full Ih character table (χ_Γ(C)) in our ordering ===\")\n",
    "header = \"irrep \\\\ class\".ljust(10) + \"  \" + \"  \".join(f\"{c:>9}\" for c in class_labels)\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for i, label in enumerate(irrep_labels):\n",
    "    row = [label.ljust(10)]\n",
    "    for j in range(10):\n",
    "        row.append(f\"{chi_irreps[i, j]:9.4f}\")\n",
    "    print(\"  \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f07cca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7, 4, 3, 1, 8, 0, 6, 2, 5]\n",
      "Ih conjugacy classes (final assignment):\n",
      "E            size= 1  order= 1  chi=1048576 (2^20)\n",
      "12C5         size=12  order= 5  chi=16 (2^4)\n",
      "12C5^2       size=12  order= 5  chi=16 (2^4)\n",
      "20C3         size=20  order= 3  chi=256 (2^8)\n",
      "15C2         size=15  order= 2  chi=1024 (2^10)\n",
      "i            size= 1  order= 2  chi=1024 (2^10)\n",
      "12S10        size=12  order=10  chi=4 (2^2)\n",
      "12(S10)^3    size=12  order=10  chi=4 (2^2)\n",
      "20S6         size=20  order= 6  chi=16 (2^4)\n",
      "15σ          size=15  order= 2  chi=4096 (2^12)\n"
     ]
    }
   ],
   "source": [
    "# Reprint Ih conjugacy classes using the final assignment from `sol` (no raw indices)\n",
    "\n",
    "if 'sol' not in globals():\n",
    "    raise RuntimeError(\"Missing `sol` (run the previous assignment cell first).\")\n",
    "if 'classes' not in globals() or 'perm_order' not in globals() or 'trace_from_perm' not in globals():\n",
    "    raise RuntimeError(\"Missing prerequisites (`classes`, `perm_order`, `trace_from_perm`).\")\n",
    "\n",
    "# Canonical Ih column order (must match how `sol['ordered_indices']` was built)\n",
    "if 'class_labels_Ih' not in globals():\n",
    "    class_labels_Ih = [\"E\",\"12C5\",\"12C5^2\",\"20C3\",\"15C2\",\"i\",\"12S10\",\"12(S10)^3\",\"20S6\",\"15σ\"]\n",
    "\n",
    "ordered_indices = sol[\"ordered_indices\"]\n",
    "print(ordered_indices)\n",
    "\n",
    "canonical_classes = []\n",
    "for lbl, raw_idx in zip(class_labels_Ih, ordered_indices):\n",
    "    cls = classes[raw_idx]\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    chi = int(round(float(trace_from_perm(cls[0]))))\n",
    "    canonical_classes.append({\"label\": lbl, \"size\": size, \"order\": order, \"chi\": chi})\n",
    "\n",
    "print(\"Ih conjugacy classes (final assignment):\")\n",
    "for c in canonical_classes:\n",
    "    # pretty power-of-two print if applicable\n",
    "    exp = None\n",
    "    if c[\"chi\"] > 0:\n",
    "        from math import log2\n",
    "        e = log2(c[\"chi\"])\n",
    "        if abs(e - round(e)) < 1e-12:\n",
    "            exp = int(round(e))\n",
    "    if exp is not None:\n",
    "        print(f\"{c['label']:12s} size={c['size']:2d}  order={c['order']:2d}  chi={c['chi']} (2^{exp})\")\n",
    "    else:\n",
    "        print(f\"{c['label']:12s} size={c['size']:2d}  order={c['order']:2d}  chi={c['chi']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7583a904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H Frobenius norm (sparse): 1.483917e+04\n",
      "Checked 120 U_g operators\n",
      "Number with relative commutator > 1.000000e-10: 0\n",
      "\n",
      "Top offenders (index, ||[H,Ug]||_F, relative):\n",
      "     0  0.000000e+00  rel=0.000e+00\n",
      "     1  0.000000e+00  rel=0.000e+00\n",
      "     2  0.000000e+00  rel=0.000e+00\n",
      "     3  0.000000e+00  rel=0.000e+00\n",
      "     4  0.000000e+00  rel=0.000e+00\n",
      "     5  0.000000e+00  rel=0.000e+00\n",
      "     6  0.000000e+00  rel=0.000e+00\n",
      "     7  0.000000e+00  rel=0.000e+00\n",
      "     8  0.000000e+00  rel=0.000e+00\n",
      "     9  0.000000e+00  rel=0.000e+00\n",
      "    10  0.000000e+00  rel=0.000e+00\n",
      "    11  0.000000e+00  rel=0.000e+00\n",
      "    12  0.000000e+00  rel=0.000e+00\n",
      "    13  0.000000e+00  rel=0.000e+00\n",
      "    14  0.000000e+00  rel=0.000e+00\n",
      "    15  0.000000e+00  rel=0.000e+00\n",
      "    16  0.000000e+00  rel=0.000e+00\n",
      "    17  0.000000e+00  rel=0.000e+00\n",
      "    18  0.000000e+00  rel=0.000e+00\n",
      "    19  0.000000e+00  rel=0.000e+00\n",
      "\n",
      "All U_g commute with H within tolerance.\n"
     ]
    }
   ],
   "source": [
    "# Sparse-only check: verify [H, U_g] = 0 for all Ugs\n",
    "tol_rel = 1e-10  # relative tolerance\n",
    "if not issparse(H):\n",
    "    raise RuntimeError(\"H must be sparse for the sparse-only check\")\n",
    "\n",
    "# Frobenius norm of H (sparse)\n",
    "H_norm = float(np.sqrt(np.real((H.multiply(H.conj())).sum())))\n",
    "if H_norm == 0:\n",
    "    H_norm = 1.0\n",
    "\n",
    "bad = []\n",
    "rel_values = []\n",
    "for i, Ug in enumerate(Ugs):\n",
    "    # sparse commutator\n",
    "    C = H @ Ug - Ug @ H\n",
    "    # Frobenius norm via sparse elementwise multiply and sum\n",
    "    s = (C.multiply(C.conj())).sum()\n",
    "    nrm = float(np.sqrt(np.real(s)))\n",
    "    rel = nrm / H_norm\n",
    "    rel_values.append((i, nrm, rel))\n",
    "    if rel > tol_rel:\n",
    "        bad.append((i, nrm, rel))\n",
    "\n",
    "# summary\n",
    "rel_values_sorted = sorted(rel_values, key=lambda x: x[2], reverse=True)\n",
    "print(f\"H Frobenius norm (sparse): {H_norm:.6e}\")\n",
    "print(f\"Checked {len(Ugs)} U_g operators\")\n",
    "print(f\"Number with relative commutator > {tol_rel:e}: {len(bad)}\")\n",
    "\n",
    "# show top offenders (up to 20)\n",
    "print(\"\\nTop offenders (index, ||[H,Ug]||_F, relative):\")\n",
    "for idx, nrm, rel in rel_values_sorted[:20]:\n",
    "    tag = \"!!\" if rel > tol_rel else \"  \"\n",
    "    print(f\"{tag} {idx:3d}  {nrm:12.6e}  rel={rel:.3e}\")\n",
    "\n",
    "# if any noncommuting found, raise or print details\n",
    "if bad:\n",
    "    print(\"\\nNon-commuting U_g indices (rel > tol):\")\n",
    "    for i, nrm, rel in sorted(bad, key=lambda x: x[2], reverse=True):\n",
    "        print(f\"  index={i:3d}, ||[H,Ug]||_F = {nrm:.6e}, rel = {rel:.3e}\")\n",
    "else:\n",
    "    print(\"\\nAll U_g commute with H within tolerance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2335bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity index: 0\n",
      "involution indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "inversion index: 71\n",
      "inversion perm: [1, 0, 19, 18, 14, 13, 17, 16, 11, 10, 9, 8, 15, 5, 4, 12, 7, 6, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "def compose(p, q): return p[q]\n",
    "\n",
    "# find identity index\n",
    "identity_idx = next(i for i, p in enumerate(perms) if np.array_equal(p, np.arange(len(p))))\n",
    "identity = perms[identity_idx]\n",
    "\n",
    "# find all involution indices (order 2, excluding identity)\n",
    "involution_indices = [i for i, p in enumerate(perms) if i != identity_idx and np.array_equal(compose(p, p), identity)]\n",
    "\n",
    "# find the unique central involution (spatial inversion)\n",
    "inversion_idx = None\n",
    "for i in involution_indices:\n",
    "    p = perms[i]\n",
    "    if all(np.array_equal(compose(p, g), compose(g, p)) for g in perms):\n",
    "        inversion_idx = i\n",
    "        break\n",
    "    \n",
    "print(\"identity index:\", identity_idx)\n",
    "print(\"involution indices:\", involution_indices)\n",
    "print(\"inversion index:\", inversion_idx)\n",
    "if inversion_idx is not None:\n",
    "    print(\"inversion perm:\", perms[inversion_idx].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0c0b8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjugacy classes (canonical label <- raw_index):\n",
      "           E  <- raw   9    size=  1, order= 1\n",
      "        12C5  <- raw   7    size= 12, order= 5\n",
      "      12C5^2  <- raw   4    size= 12, order= 5\n",
      "        20C3  <- raw   3    size= 20, order= 3\n",
      "        15C2  <- raw   1    size= 15, order= 2\n",
      "           i  <- raw   8    size=  1, order= 2\n",
      "       12S10  <- raw   0    size= 12, order=10\n",
      "   12(S10)^3  <- raw   6    size= 12, order=10\n",
      "        20S6  <- raw   2    size= 20, order= 6\n",
      "         15σ  <- raw   5    size= 15, order= 2\n",
      "\n",
      "Raw class summary (raw_idx, size, order, chi_red):\n",
      "       12S10  raw_idx=  0  size= 12  order=10  chi_red=   4.0\n",
      "        15C2  raw_idx=  1  size= 15  order= 2  chi_red=1024.0\n",
      "        20S6  raw_idx=  2  size= 20  order= 6  chi_red=  16.0\n",
      "        20C3  raw_idx=  3  size= 20  order= 3  chi_red= 256.0\n",
      "      12C5^2  raw_idx=  4  size= 12  order= 5  chi_red=  16.0\n",
      "         15σ  raw_idx=  5  size= 15  order= 2  chi_red=4096.0\n",
      "   12(S10)^3  raw_idx=  6  size= 12  order=10  chi_red=   4.0\n",
      "        12C5  raw_idx=  7  size= 12  order= 5  chi_red=  16.0\n",
      "           i  raw_idx=  8  size=  1  order= 2  chi_red=1024.0\n",
      "           E  raw_idx=  9  size=  1  order= 1  chi_red=1048576.0\n",
      "Building projector for irrep 'Ag' (dim=1)\n",
      "  Adding class 'E' contribution with chi=1.0\n",
      "  Adding class '12C5' contribution with chi=1.0\n",
      "  Adding class '12C5^2' contribution with chi=1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=1.0\n",
      "  Adding class 'i' contribution with chi=1.0\n",
      "  Adding class '12S10' contribution with chi=1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=1.0\n",
      "  Adding class '20S6' contribution with chi=1.0\n",
      "  Adding class '15σ' contribution with chi=1.0\n",
      "Building projector for irrep 'T1g' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=1.6180339887498947\n",
      "  Adding class '12C5^2' contribution with chi=-0.6180339887498949\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=3.0\n",
      "  Adding class '12S10' contribution with chi=-0.6180339887498949\n",
      "  Adding class '12(S10)^3' contribution with chi=1.6180339887498947\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15σ' contribution with chi=-1.0\n",
      "Building projector for irrep 'T2g' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=-0.6180339887498949\n",
      "  Adding class '12C5^2' contribution with chi=1.6180339887498947\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=3.0\n",
      "  Adding class '12S10' contribution with chi=1.6180339887498947\n",
      "  Adding class '12(S10)^3' contribution with chi=-0.6180339887498949\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15σ' contribution with chi=-1.0\n",
      "Building projector for irrep 'Gg' (dim=4)\n",
      "  Adding class 'E' contribution with chi=4.0\n",
      "  Adding class '12C5' contribution with chi=-1.0\n",
      "  Adding class '12C5^2' contribution with chi=-1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=0.0\n",
      "  Adding class 'i' contribution with chi=4.0\n",
      "  Adding class '12S10' contribution with chi=-1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=-1.0\n",
      "  Adding class '20S6' contribution with chi=1.0\n",
      "  Adding class '15σ' contribution with chi=0.0\n",
      "Building projector for irrep 'Hg' (dim=5)\n",
      "  Adding class 'E' contribution with chi=5.0\n",
      "  Adding class '12C5' contribution with chi=0.0\n",
      "  Adding class '12C5^2' contribution with chi=0.0\n",
      "  Adding class '20C3' contribution with chi=-1.0\n",
      "  Adding class '15C2' contribution with chi=1.0\n",
      "  Adding class 'i' contribution with chi=5.0\n",
      "  Adding class '12S10' contribution with chi=0.0\n",
      "  Adding class '12(S10)^3' contribution with chi=0.0\n",
      "  Adding class '20S6' contribution with chi=-1.0\n",
      "  Adding class '15σ' contribution with chi=1.0\n",
      "Building projector for irrep 'Au' (dim=1)\n",
      "  Adding class 'E' contribution with chi=1.0\n",
      "  Adding class '12C5' contribution with chi=1.0\n",
      "  Adding class '12C5^2' contribution with chi=1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=1.0\n",
      "  Adding class 'i' contribution with chi=-1.0\n",
      "  Adding class '12S10' contribution with chi=-1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=-1.0\n",
      "  Adding class '20S6' contribution with chi=-1.0\n",
      "  Adding class '15σ' contribution with chi=-1.0\n",
      "Building projector for irrep 'T1u' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=1.6180339887498947\n",
      "  Adding class '12C5^2' contribution with chi=-0.6180339887498949\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=-3.0\n",
      "  Adding class '12S10' contribution with chi=0.6180339887498949\n",
      "  Adding class '12(S10)^3' contribution with chi=-1.6180339887498947\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15σ' contribution with chi=1.0\n",
      "Building projector for irrep 'T2u' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=-0.6180339887498949\n",
      "  Adding class '12C5^2' contribution with chi=1.6180339887498947\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=-3.0\n",
      "  Adding class '12S10' contribution with chi=-1.6180339887498947\n",
      "  Adding class '12(S10)^3' contribution with chi=0.6180339887498949\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15σ' contribution with chi=1.0\n",
      "Building projector for irrep 'Gu' (dim=4)\n",
      "  Adding class 'E' contribution with chi=4.0\n",
      "  Adding class '12C5' contribution with chi=-1.0\n",
      "  Adding class '12C5^2' contribution with chi=-1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=0.0\n",
      "  Adding class 'i' contribution with chi=-4.0\n",
      "  Adding class '12S10' contribution with chi=1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=1.0\n",
      "  Adding class '20S6' contribution with chi=-1.0\n",
      "  Adding class '15σ' contribution with chi=0.0\n",
      "Building projector for irrep 'Hu' (dim=5)\n",
      "  Adding class 'E' contribution with chi=5.0\n",
      "  Adding class '12C5' contribution with chi=0.0\n",
      "  Adding class '12C5^2' contribution with chi=0.0\n",
      "  Adding class '20C3' contribution with chi=-1.0\n",
      "  Adding class '15C2' contribution with chi=1.0\n",
      "  Adding class 'i' contribution with chi=-5.0\n",
      "  Adding class '12S10' contribution with chi=0.0\n",
      "  Adding class '12(S10)^3' contribution with chi=0.0\n",
      "  Adding class '20S6' contribution with chi=1.0\n",
      "  Adding class '15σ' contribution with chi=-1.0\n",
      "\n",
      "Built 10 projectors for irreps: ['Ag', 'T1g', 'T2g', 'Gg', 'Hg', 'Au', 'T1u', 'T2u', 'Gu', 'Hu']\n",
      "\n",
      "Projector 'Ag':\n",
      "  trace = 9436.000000\n",
      "  Idempotent: YES (err=2.067e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'T1g':\n",
      "  trace = 76806.000000\n",
      "  Idempotent: YES (err=1.180e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'T2g':\n",
      "  trace = 76806.000000\n",
      "  Idempotent: YES (err=1.180e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'Gg':\n",
      "  trace = 140112.000000\n",
      "  Idempotent: YES (err=3.090e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'Hg':\n",
      "  trace = 221640.000000\n",
      "  Idempotent: YES (err=3.979e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'Au':\n",
      "  trace = 8388.000000\n",
      "  Idempotent: YES (err=2.066e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'T1u':\n",
      "  trace = 79722.000000\n",
      "  Idempotent: YES (err=1.172e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'T2u':\n",
      "  trace = 79722.000000\n",
      "  Idempotent: YES (err=1.171e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'Gu':\n",
      "  trace = 139824.000000\n",
      "  Idempotent: YES (err=3.090e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n",
      "\n",
      "Projector 'Hu':\n",
      "  trace = 216120.000000\n",
      "  Idempotent: YES (err=3.964e-13+0.000e+00j, thresh=1.0e-08)\n",
      "  Hermitian : YES (err=0.000e+00+0.000e+00j, thresh=1.0e-08)\n",
      "  Projector valid (idempotent & hermitian): YES\n"
     ]
    }
   ],
   "source": [
    "ordered_indices = sol[\"ordered_indices\"]\n",
    "\n",
    "# Canonical Ih column order\n",
    "class_labels_Ih = [\n",
    "    \"E\", \"12C5\", \"12C5^2\", \"20C3\", \"15C2\",\n",
    "    \"i\", \"12S10\", \"12(S10)^3\", \"20S6\", \"15σ\",\n",
    "]\n",
    "\n",
    "# map raw class index -> canonical Ih label\n",
    "raw_to_label = {raw: lbl for raw, lbl in zip(ordered_indices, class_labels_Ih)}\n",
    "\n",
    "print(\"Conjugacy classes (canonical label <- raw_index):\")\n",
    "for k, lbl in enumerate(class_labels_Ih):\n",
    "    raw_idx = ordered_indices[k]\n",
    "    cls = classes[raw_idx]\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    print(f\"  {lbl:>10}  <- raw {raw_idx:3d}    size={size:3d}, order={order:2d}\")\n",
    "\n",
    "print(\"\\nRaw class summary (raw_idx, size, order, chi_red):\")\n",
    "for cd in class_data:\n",
    "    label = raw_to_label.get(cd[\"idx\"], f\"raw_{cd['idx']}\")\n",
    "    print(f\"  {label:>10}  raw_idx={cd['idx']:3d}  size={cd['size']:3d}  order={cd['order']:2d}  chi_red={cd['chi']:6.1f}\")\n",
    "\n",
    "# Build class operators in Ih order\n",
    "def build_class_operators_in_Ih_order(N_spins, classes, ordered_indices):\n",
    "    class_ops = []\n",
    "    for class_idx in ordered_indices:\n",
    "        class_perms = classes[class_idx]\n",
    "        U_sum = None\n",
    "        for perm in class_perms:\n",
    "            U_g = build_symmetry_operator(N_spins, perm)\n",
    "            if U_sum is None:\n",
    "                U_sum = U_g.astype(np.complex128, copy=True).tocsr()\n",
    "            else:\n",
    "                U_sum = U_sum + U_g\n",
    "        class_ops.append(U_sum.tocsr())\n",
    "    return class_ops\n",
    "\n",
    "def build_projectors(class_ops, chi_irreps, dims_irreps, class_sizes, G_order=120):\n",
    "    \"\"\"\n",
    "    Build orthogonal projectors P_Gamma for each irrep Gamma of group G using sparse ops only.\n",
    "    Returns a list of sparse matrices (same sparse format as used during accumulation).\n",
    "    \"\"\"\n",
    "    projectors = []\n",
    "    n_irreps, n_classes = chi_irreps.shape\n",
    "\n",
    "    # assume at least one class_op present and use its shape\n",
    "    if len(class_ops) == 0:\n",
    "        return projectors\n",
    "    dim = class_ops[0].shape[0]\n",
    "\n",
    "    for i in range(n_irreps):\n",
    "        d_Gamma = dims_irreps[i]\n",
    "        chi_Gamma = chi_irreps[i]\n",
    "        label = irrep_labels[i] if i < len(irrep_labels) else f\"irrep_{i}\"\n",
    "        print(f\"Building projector for irrep '{label}' (dim={d_Gamma})\")\n",
    "\n",
    "        # start from a sparse zero matrix (CSR) with complex dtype and accumulate sparsely\n",
    "        P = csr_matrix((dim, dim), dtype=np.complex128)\n",
    "        for k, C_k in enumerate(class_ops):\n",
    "            class_lbl = class_labels_Ih[k] if k < len(class_labels_Ih) else f\"class_{k}\"\n",
    "            coef = complex((d_Gamma / G_order) * np.conj(chi_Gamma[k]))\n",
    "            print(f\"  Adding class '{class_lbl}' contribution with chi={chi_Gamma[k]}\")\n",
    "            # sparse scalar multiplication + sparse addition keeps result sparse\n",
    "            P = P + coef * C_k\n",
    "\n",
    "        projectors.append(P)   # already sparse; do not convert to dense/force .tocsr()\n",
    "\n",
    "    return projectors\n",
    "\n",
    "# Input data (must all use the same class order!)\n",
    "G_order = 120\n",
    "class_sizes_Ih = np.array([1,12,12,20,15,1,12,12,20,15])\n",
    "dims_irreps = np.array([1,3,3,4,5,1,3,3,4,5])\n",
    "\n",
    "# Build classes\n",
    "classop = build_class_operators_in_Ih_order(N_spins, classes, ordered_indices)\n",
    "\n",
    "# Build projectors\n",
    "projectors = build_projectors(classop, chi_irreps, dims_irreps, class_sizes_Ih, G_order)\n",
    "\n",
    "print(f\"\\nBuilt {len(projectors)} projectors for irreps:\", irrep_labels)\n",
    "\n",
    "# Quick sanity checks: idempotency (P^2 = P), Hermiticity (P† = P) and trace\n",
    "err_thresh = 1e-8  # threshold below which we declare the property satisfied\n",
    "for i, P in enumerate(projectors):\n",
    "    label = irrep_labels[i] if i < len(irrep_labels) else f\"irrep_{i}\"\n",
    "    # P may be sparse CSR\n",
    "    P2 = P @ P\n",
    "    diff_idem = P2 - P\n",
    "    # idempotency error (Frobenius)\n",
    "    if issparse(diff_idem):\n",
    "        idem_err = np.sqrt((diff_idem.multiply(diff_idem.conj())).sum())\n",
    "    else:\n",
    "        idem_err = np.linalg.norm(diff_idem, ord='fro')\n",
    "    # Hermiticity error\n",
    "    diff_herm = P - P.conj().T\n",
    "    if issparse(diff_herm):\n",
    "        herm_err = np.sqrt((diff_herm.multiply(diff_herm.conj())).sum())\n",
    "    else:\n",
    "        herm_err = np.linalg.norm(diff_herm, ord='fro')\n",
    "    # trace (should equal dimension of the irrep subspace: n_Gamma * d_Gamma)\n",
    "    try:\n",
    "        tr = np.real(P.diagonal().sum())\n",
    "    except Exception:\n",
    "        tr = float(np.real(np.trace(P.toarray())))\n",
    "\n",
    "    idem_ok = idem_err < err_thresh\n",
    "    herm_ok = herm_err < err_thresh\n",
    "    ok = idem_ok and herm_ok\n",
    "\n",
    "    print(f\"\\nProjector '{label}':\")\n",
    "    print(f\"  trace = {tr:.6f}\")\n",
    "    print(f\"  Idempotent: {'YES' if idem_ok else 'NO'} (err={idem_err:.3e}, thresh={err_thresh:.1e})\")\n",
    "    print(f\"  Hermitian : {'YES' if herm_ok else 'NO'} (err={herm_err:.3e}, thresh={err_thresh:.1e})\")\n",
    "    print(f\"  Projector valid (idempotent & hermitian): {'YES' if ok else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b92e731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of projector traces = 1048576.000000  (expected 1048576)\n",
      "|| sum(P) - I ||_F = 2.325e-13, max_abs_entry = 6.661e-16\n",
      "Sum is identity: YES\n"
     ]
    }
   ],
   "source": [
    "# Check that sum of projectors = Identity\n",
    "dim = projectors[0].shape[0]\n",
    "Id = eye(dim, dtype=np.complex128, format='csr')\n",
    "\n",
    "# sum projectors (sparse)\n",
    "S = None\n",
    "for P in projectors:\n",
    "    S = P.copy() if S is None else S + P\n",
    "\n",
    "diff = (S - Id).tocsr()\n",
    "\n",
    "# Frobenius norm of the deviation\n",
    "if issparse(diff):\n",
    "    s = (diff.multiply(diff.conj())).sum()\n",
    "    frob = float(np.sqrt(np.real(s)))  # take real part to avoid ComplexWarning\n",
    "    max_abs = float(np.max(np.abs(diff.data))) if diff.nnz > 0 else 0.0\n",
    "else:\n",
    "    frob = float(np.linalg.norm(diff, ord='fro'))\n",
    "    max_abs = float(np.max(np.abs(diff)))\n",
    "\n",
    "# Total trace should equal dim\n",
    "# (trace is linear, so either sum individual traces or trace of S)\n",
    "total_trace = float(np.real(S.diagonal().sum()))\n",
    "\n",
    "print(f\"Sum of projector traces = {total_trace:.6f}  (expected {dim})\")\n",
    "print(f\"|| sum(P) - I ||_F = {frob:.3e}, max_abs_entry = {max_abs:.3e}\")\n",
    "print(\"Sum is identity:\" , \"YES\" if frob < 1e-8 and abs(total_trace - dim) < 1e-6 else \"NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23e0e6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest 5 eigenvalues of H: [-62.51489576 -58.59394385 -58.59394385 -58.59394385 -58.25359416]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = eigsh(H, k=5, which='SA')  # smallest algebraic\n",
    "print(\"Lowest 5 eigenvalues of H:\", eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40899fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_eigenvectors(eigvecs, projectors, irrep_labels, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Optimized version that pre-normalizes eigenvectors.\n",
    "    \"\"\"\n",
    "    dim, nvecs = eigvecs.shape\n",
    "    results = []\n",
    "\n",
    "    for n in tqdm(range(nvecs)):\n",
    "        psi = eigvecs[:, n]\n",
    "        # Normalize once (eigenvectors from eigsh should already be normalized)\n",
    "        psi_norm = np.sqrt(np.vdot(psi, psi).real)\n",
    "        if psi_norm > 0:\n",
    "            psi = psi / psi_norm\n",
    "        \n",
    "        weights = {}\n",
    "        for P, label in zip(projectors, irrep_labels):\n",
    "            psi_G = P @ psi  # Sparse @ dense = dense\n",
    "            w = np.vdot(psi_G, psi_G).real  # No division needed since psi is normalized\n",
    "            \n",
    "            if abs(w) < tol:\n",
    "                w = 0.0\n",
    "            weights[label] = w\n",
    "        results.append(weights)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c04f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvector 0:\n",
      "  Ag: 1.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 0.000000, Gu: 0.000000, Hu: 0.000000\n",
      "Eigenvector 1:\n",
      "  Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 1.000000, Gu: 0.000000, Hu: 0.000000\n",
      "Eigenvector 2:\n",
      "  Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 1.000000, Gu: 0.000000, Hu: 0.000000\n",
      "Eigenvector 3:\n",
      "  Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 1.000000, Gu: 0.000000, Hu: 0.000000\n",
      "Eigenvector 4:\n",
      "  Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 1.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 0.000000, Gu: 0.000000, Hu: 0.000000\n"
     ]
    }
   ],
   "source": [
    "results = classify_eigenvectors(eigenvectors, projectors, irrep_labels, tol=1e-4)\n",
    "for idx, weights in enumerate(results):\n",
    "    # print index on its own line\n",
    "    print(f\"Eigenvector {idx}:\")\n",
    "    # print irreps decomposition on separate line (preserve canonical irrep order)\n",
    "    print(\"  \" + \", \".join(f\"{lbl}: {weights[lbl]:.6f}\" for lbl in irrep_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8daa97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors checked: 5\n",
      "\n",
      "Counts per irrep (assigned by largest weight):\n",
      "    Ag:     1\n",
      "   T1g:     0\n",
      "   T2g:     0\n",
      "    Gg:     1\n",
      "    Hg:     0\n",
      "    Au:     0\n",
      "   T1u:     0\n",
      "   T2u:     3\n",
      "    Gu:     0\n",
      "    Hu:     0\n",
      "\n",
      "No vectors have >1 significant irrep contribution (within tolerance).\n",
      "\n",
      "All vectors: sum(weights) ≈ 1 (within tol_sum).\n",
      "\n",
      "All vectors have primary weight ≳ 1 - 1e-06 (appear pure): 5\n",
      "\n",
      "Per-vector irrep weight coefficients (rounded to 6 decimals):\n",
      "  Vec    0: Ag: 1.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 0.000000, Gu: 0.000000, Hu: 0.000000\n",
      "  Vec    1: Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 1.000000, Gu: 0.000000, Hu: 0.000000\n",
      "  Vec    2: Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 1.000000, Gu: 0.000000, Hu: 0.000000\n",
      "  Vec    3: Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 0.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 1.000000, Gu: 0.000000, Hu: 0.000000\n",
      "  Vec    4: Ag: 0.000000, T1g: 0.000000, T2g: 0.000000, Gg: 1.000000, Hg: 0.000000, Au: 0.000000, T1u: 0.000000, T2u: 0.000000, Gu: 0.000000, Hu: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# tolerance for treating a weight as nonzero / significant\n",
    "tol_multi = 1e-4\n",
    "tol_sum = 1e-8       # tolerance for sum of weights = 1\n",
    "tol_pure = 1e-6      # tolerance for testing primary weight ~= 1\n",
    "\n",
    "# `results` is expected to be the list returned by classify_eigenvectors\n",
    "# where each entry is a dict {irrep_label: weight}\n",
    "nvec = len(results)\n",
    "counts = Counter()\n",
    "multi_members = []    # list of (vec_index, [(label, weight), ...]) for vectors with >1 significant weights\n",
    "\n",
    "# per-vector formatted weights\n",
    "per_vector_weights = []\n",
    "\n",
    "# diagnostics\n",
    "bad_sum = []\n",
    "not_pure = []\n",
    "pure_vectors = []\n",
    "\n",
    "for idx, wdict in enumerate(results):\n",
    "    # ensure numeric values\n",
    "    wvals = np.array([float(wdict[l]) for l in irrep_labels])\n",
    "    sum_w = wvals.sum()\n",
    "\n",
    "    # assign by argmax (primary irrep)\n",
    "    primary = max(wdict.items(), key=lambda kv: kv[1])[0]\n",
    "    max_w = wdict[primary]\n",
    "    counts[primary] += 1\n",
    "\n",
    "    # collect significant contributions\n",
    "    significant = [(lbl, wt) for lbl, wt in wdict.items() if wt > tol_multi]\n",
    "    if len(significant) > 1:\n",
    "        multi_members.append((idx, sorted(significant, key=lambda x: -x[1])))\n",
    "\n",
    "    # record per-vector weights (rounded) for printing\n",
    "    per_vector_weights.append((idx, {lbl: float(f\"{wt:.6f}\") for lbl, wt in wdict.items()}))\n",
    "\n",
    "    # diagnostics: sum check\n",
    "    if abs(sum_w - 1.0) > tol_sum:\n",
    "        bad_sum.append((idx, float(sum_w)))\n",
    "\n",
    "    # diagnostics: purity check (is the vector purely in one irrep?)\n",
    "    if max_w < 1.0 - tol_pure:\n",
    "        not_pure.append((idx, primary, float(max_w)))\n",
    "    else:\n",
    "        # record pure vectors where primary weight ≈ 1\n",
    "        pure_vectors.append((idx, primary, float(max_w)))\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total vectors checked: {nvec}\\n\")\n",
    "print(\"Counts per irrep (assigned by largest weight):\")\n",
    "for lbl in irrep_labels:\n",
    "    print(f\"  {lbl:>4}: {counts[lbl]:5d}\")\n",
    "print()\n",
    "\n",
    "if multi_members:\n",
    "    print(f\"Vectors with >1 significant irrep contribution (tol = {tol_multi}): {len(multi_members)}\")\n",
    "    for idx, sig in multi_members:\n",
    "        sig_str = \", \".join(f\"{lbl}({wt:.6f})\" for lbl, wt in sig)\n",
    "        print(f\"  Vector {idx}: {sig_str}\")\n",
    "else:\n",
    "    print(\"No vectors have >1 significant irrep contribution (within tolerance).\")\n",
    "\n",
    "# diagnostics output\n",
    "if bad_sum:\n",
    "    print(\"\\nWARNING: Vectors whose irrep-weight sums deviate from 1:\")\n",
    "    for idx, s in bad_sum:\n",
    "        print(f\"  Vec {idx:4d}: sum(weights) = {s:.8f}\")\n",
    "else:\n",
    "    print(\"\\nAll vectors: sum(weights) ≈ 1 (within tol_sum).\")\n",
    "\n",
    "if not_pure:\n",
    "    print(f\"\\nVectors whose primary weight < 1 - {tol_pure} (mixed across irreps): {len(not_pure)}\")\n",
    "    for idx, prim, mw in not_pure:\n",
    "        print(f\"  Vec {idx:4d}: primary={prim}, max_weight={mw:.6f}\")\n",
    "else:\n",
    "    print(f\"\\nAll vectors have primary weight ≳ 1 - {tol_pure} (appear pure): {len(pure_vectors)}\")\n",
    "\n",
    "print(\"\\nPer-vector irrep weight coefficients (rounded to 6 decimals):\")\n",
    "for idx, wdict in per_vector_weights:\n",
    "    wstr = \", \".join(f\"{lbl}: {wdict[lbl]:.6f}\" for lbl in irrep_labels)\n",
    "    print(f\"  Vec {idx:4d}: {wstr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4cf96c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvector index: 0, Eigenvalue: -62.514896\n",
      "  Magnetization: -19.162816\n",
      "  Parity: even\n",
      "\n",
      "Eigenvector index: 1, Eigenvalue: -58.593944\n",
      "  Magnetization: -17.239547\n",
      "  Parity: odd\n",
      "\n",
      "Eigenvector index: 2, Eigenvalue: -58.593944\n",
      "  Magnetization: -17.239547\n",
      "  Parity: odd\n",
      "\n",
      "Eigenvector index: 3, Eigenvalue: -58.593944\n",
      "  Magnetization: -17.239547\n",
      "  Parity: odd\n",
      "\n",
      "Eigenvector index: 4, Eigenvalue: -58.253594\n",
      "  Magnetization: -17.279693\n",
      "  Parity: odd\n"
     ]
    }
   ],
   "source": [
    "for idx in range(eigenvectors.shape[1]):\n",
    "    v = eigenvectors[:, idx]\n",
    "    E = eigenvalues[idx]\n",
    "    print(f\"\\nEigenvector index: {idx}, Eigenvalue: {E:.6f}\")\n",
    "    \n",
    "    # Check symmetry properties\n",
    "    mag_avg = check_magnetization_sector(v, N)\n",
    "    parity_sector = check_parity_sector(v, N)\n",
    "    \n",
    "    print(f\"  Magnetization: {mag_avg:.6f}\")\n",
    "    print(f\"  Parity: {parity_sector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d4c151e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Ug index 71 to the 6 Lanczos eigenvectors\n",
      "\n",
      "vec     0: lambda = +1.000000, resid = 1.35e-14 -> +1\n",
      "vec     1: lambda = -1.000000, resid = 4.90e-13 -> -1\n",
      "vec     2: lambda = -1.000000, resid = 6.36e-14 -> -1\n",
      "vec     3: lambda = -1.000000, resid = 4.53e-14 -> -1\n",
      "vec     4: lambda = +1.000000, resid = 6.28e-14 -> +1\n"
     ]
    }
   ],
   "source": [
    "idx_Ug = 71 # 0 if you want to apply identity\n",
    "Ug = Ugs[idx_Ug]          # sparse CSR permutation operator\n",
    "Ug_matvec = lambda v: Ug @ v\n",
    "\n",
    "print(f\"Applying Ug index {idx_Ug} to the 6 Lanczos eigenvectors\\n\")\n",
    "\n",
    "for si in range(eigenvectors.shape[1]):\n",
    "    v = eigenvectors[:, si]\n",
    "    w = Ug_matvec(v)\n",
    "    lam = np.vdot(v, w) / np.vdot(v, v)        # Rayleigh estimate of eigenvalue\n",
    "    resid = np.linalg.norm(w - lam * v)       # how close w == lam*v\n",
    "    sign_check = None\n",
    "    if np.allclose(lam, 1.0, atol=1e-6):\n",
    "        sign_check = \"+1\"\n",
    "    elif np.allclose(lam, -1.0, atol=1e-6):\n",
    "        sign_check = \"-1\"\n",
    "    else:\n",
    "        sign_check = \"not ±1\"\n",
    "\n",
    "    # avoid formatting a string with float format spec -> build imag part separately\n",
    "    imag_part = \"\" if abs(lam.imag) < 1e-12 else f\"{lam.imag:+.6f}j\"\n",
    "    print(f\"vec {si:5d}: lambda = {lam.real:+.6f}{imag_part}, resid = {resid:.2e} -> {sign_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f6c77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CSR helpers for sparse column vectors (shape (D,1)) ---\n",
    "def _csr_rand_vec_in_indices(D, idx_sector, rng):\n",
    "    rows = np.asarray(idx_sector, dtype=np.int64)\n",
    "    K = rows.size\n",
    "    cols = np.zeros(K, dtype=np.int64)\n",
    "    data = rng.normal(size=K) + 1j * rng.normal(size=K)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(D, 1), dtype=np.complex128)\n",
    "\n",
    "def _csr_basis_vec(D, b):\n",
    "    return csr_matrix(([1.0 + 0.0j], ([int(b)], [0])), shape=(D, 1), dtype=np.complex128)\n",
    "\n",
    "def _csr_norm(v):\n",
    "    if v.nnz == 0:\n",
    "        return 0.0\n",
    "    return float(np.sqrt(np.sum(np.abs(v.data) ** 2)))\n",
    "\n",
    "def _csr_normalize(v):\n",
    "    nrm = _csr_norm(v)\n",
    "    if nrm > 0:\n",
    "        v = v.copy()\n",
    "        v.data /= nrm\n",
    "    return v, nrm\n",
    "\n",
    "def _csr_residual(Ug, v):\n",
    "    r = Ug @ v - v\n",
    "    return _csr_norm(r)\n",
    "\n",
    "def _csr_parity_label(v, N, tol=1e-6):\n",
    "    # compute weights on even/odd parity using nonzeros only\n",
    "    coo = v.tocoo()\n",
    "    rows = coo.row\n",
    "    data = coo.data\n",
    "    w_even = 0.0\n",
    "    w_odd = 0.0\n",
    "    for idx, amp in zip(rows, data):\n",
    "        if parity(int(idx), N) == 1:\n",
    "            w_even += float((amp.conjugate() * amp).real)\n",
    "        else:\n",
    "            w_odd += float((amp.conjugate() * amp).real)\n",
    "    if w_even > 1.0 - tol:\n",
    "        return \"even\"\n",
    "    if w_odd > 1.0 - tol:\n",
    "        return \"odd\"\n",
    "    return f\"mixed (even={w_even:.4f}, odd={w_odd:.4f})\"\n",
    "\n",
    "def _csr_magnetization_avg(v, N):\n",
    "    coo = v.tocoo()\n",
    "    rows = coo.row\n",
    "    data = coo.data\n",
    "    m = 0.0\n",
    "    for idx, amp in zip(rows, data):\n",
    "        m += magnetization(int(idx), N) * float((amp.conjugate() * amp).real)\n",
    "    return m\n",
    "\n",
    "def make_vc0_parity_Ih_irrep(N, projectors, par, irrep_labels, target_irrep,\n",
    "                                 rng=None, max_attempts=200):\n",
    "    \"\"\"\n",
    "    Build a single normalized vector v with:\n",
    "      - even/odd parity,\n",
    "      - in the chosen Ih irrep subspace (e.g. \"Ag\" or \"Gg\").\n",
    "    Sparse (CSR) internally. Returns dense 1D vector.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    if par == \"even\":\n",
    "        idx_sector = [b for b in range(D) if parity(b, N) == 1]\n",
    "    else:\n",
    "        idx_sector = [b for b in range(D) if parity(b, N) == -1]\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(f\"No {par}-parity basis states\")\n",
    "\n",
    "    try:\n",
    "        i_target = irrep_labels.index(str(target_irrep))\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"target_irrep '{target_irrep}' not found in irrep_labels\")\n",
    "    P_target = projectors[i_target].astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        v = _csr_rand_vec_in_indices(D, idx_sector, rng)\n",
    "\n",
    "        v = P_target @ v\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            w = _csr_norm(P_target @ v) ** 2\n",
    "            par = _csr_parity_label(v, N)\n",
    "            if w > 1e-8:\n",
    "                return v.toarray().ravel()\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    # fallback\n",
    "    for b in idx_sector:\n",
    "        v = _csr_basis_vec(D, b)\n",
    "        v = P_target @ v\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    raise RuntimeError(f\"Failed to build vector in irrep '{target_irrep}' after {max_attempts} attempts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d0d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 0.9999999999999999\n",
      "magnetization (expected 0): -0.02268714409004229\n",
      "parity sector (expected 'odd'): odd\n",
      "support size: 524240\n"
     ]
    }
   ],
   "source": [
    "# build a vector in a chosen Ih irrep (no Ug invariance enforced)\n",
    "vc0 = make_vc0_parity_Ih_irrep(N, projectors, par=\"odd\", irrep_labels=irrep_labels, target_irrep=\"Gg\", rng=None)\n",
    "\n",
    "# quick checks for vc0\n",
    "tol = 1e-8\n",
    "\n",
    "print(\"norm:\", np.vdot(vc0, vc0).real)\n",
    "\n",
    "mag = check_magnetization_sector(vc0, N)\n",
    "pari = check_parity_sector(vc0, N)\n",
    "print(\"magnetization (expected 0):\", mag)\n",
    "print(\"parity sector (expected 'odd'):\", pari)\n",
    "\n",
    "support = np.nonzero(np.abs(vc0) > 1e-10)[0]\n",
    "print(\"support size:\", support.size)\n",
    "\n",
    "# compute membership weights in each Ih irrep: w_Gamma = || P_Gamma |v> ||^2\n",
    "weights = {}\n",
    "for P, lbl in zip(projectors, irrep_labels):\n",
    "    psi_G = P @ vc0\n",
    "    w = np.vdot(psi_G, psi_G).real\n",
    "    weights[lbl] = float(w)\n",
    "\n",
    "# summary: sorted by weight\n",
    "sorted_weights = sorted(weights.items(), key=lambda kv: -kv[1])\n",
    "print(\"\\nIrrep weights (descending):\")\n",
    "for lbl, w in sorted_weights:\n",
    "    print(f\"  {lbl:>4}: {w:.6e}\")\n",
    "\n",
    "total_weight = sum(weights.values())\n",
    "print(f\"\\nSum of irrep-weights = {total_weight:.12f} (should be ≈ 1.0)\")\n",
    "\n",
    "# optional: overlap with Ug (diagnostic only, not required)\n",
    "if 'Ug' in globals():\n",
    "    resid = np.linalg.norm(Ug @ vc0 - vc0)\n",
    "    ov = (np.vdot(vc0, Ug @ vc0) / np.vdot(vc0, vc0)).real\n",
    "    print(f\"\\nDiagnostic Ug overlap: ||Ug v - v|| = {resid:.2e}, <v|Ug|v> = {ov:.6f}\")\n",
    "\n",
    "# sanity checks (raise only if major failures)\n",
    "if pari.startswith(\"odd\"):\n",
    "    print(\"Vector is in odd-parity sector as expected.\")\n",
    "else:\n",
    "    print(\"Vector is in even-parity sector as expected.\")\n",
    "\n",
    "if abs(total_weight - 1.0) > 1e-6:\n",
    "    print(\"WARNING: sum of irrep weights deviates from 1 by\", total_weight - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16da7722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target eigenvalue for filtering: -58.25359416\n",
      "Target support: 523806\n",
      "Running 50 iterations with m=1000, pad=0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, n_steps + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m         Phi, evals = \u001b[43mchebyshev_filter_v0_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mtarget_E0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_jackson\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_jackson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m         \u001b[38;5;66;03m# basic sanity checks\u001b[39;00m\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(evals):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 724\u001b[39m, in \u001b[36mchebyshev_filter_v0_numpy\u001b[39m\u001b[34m(H, v0, Emin, Emax, target_E0, m, pad, use_jackson, rng)\u001b[39m\n\u001b[32m    721\u001b[39m tk   = t1\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, m+\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     tkp1 = \u001b[32m2.0\u001b[39m * \u001b[43mHtilde_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtk\u001b[49m\u001b[43m)\u001b[49m - tkm1\n\u001b[32m    725\u001b[39m     filt = filt + alpha[k] * tkp1\n\u001b[32m    726\u001b[39m     tkm1, tk = tk, tkp1\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 708\u001b[39m, in \u001b[36mchebyshev_filter_v0_numpy.<locals>.Htilde_dot\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mHtilde_dot\u001b[39m(v):\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     Hv = \u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m   \u001b[38;5;66;03m# works for dense or sparse\u001b[39;00m\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (Hv - c * v) / d\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camip\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\sparse\\_base.py:732\u001b[39m, in \u001b[36m_spbase.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[32m    730\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mScalar operands are not allowed, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    731\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33muse \u001b[39m\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camip\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\sparse\\_base.py:617\u001b[39m, in \u001b[36m_spbase._matmul_dispatch\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m other.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m np.ndarray:\n\u001b[32m    615\u001b[39m     \u001b[38;5;66;03m# Fast path for the most common case\u001b[39;00m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m other.shape == (N,):\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matmul_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m other.shape == (N, \u001b[32m1\u001b[39m):\n\u001b[32m    619\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._matmul_vector(other.ravel())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camip\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:526\u001b[39m, in \u001b[36m_cs_matrix._matmul_vector\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;66;03m# csr_matvec or csc_matvec\u001b[39;00m\n\u001b[32m    525\u001b[39m fn = \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m.format + \u001b[33m'\u001b[39m\u001b[33m_matvec\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# run many short Chebyshev filters (m=500) repeatedly instead of one huge m\n",
    "m = 1000\n",
    "n_steps = 50\n",
    "pad = 0.05\n",
    "use_jackson = True\n",
    "\n",
    "start_vec = vc0\n",
    "current = start_vec\n",
    "Emin = -62.51489576\n",
    "Emax = 62.60812227\n",
    "target = eigenvalues[4]  # 5th lowest eigenvalue from earlier Lanczos run\n",
    "print(f\"Target eigenvalue for filtering: {target:.8f}\")\n",
    "print(f\"Target support: {np.count_nonzero(np.abs(eigenvectors[:,4]) > 1e-10)}\")\n",
    "\n",
    "print(f\"Running {n_steps} iterations with m={m}, pad={pad}\")\n",
    "\n",
    "last_eval = None\n",
    "try:\n",
    "    for i in range(1, n_steps + 1):\n",
    "        Phi, evals = chebyshev_filter_v0_numpy(H, current, Emin=Emin, Emax=Emax,\n",
    "                                               target_E0=target, m=m, pad=pad, use_jackson=use_jackson)\n",
    "        # basic sanity checks\n",
    "        if not np.isfinite(evals):\n",
    "            print(f\"Stopped at step {i}: non-finite eval {evals}\")\n",
    "            break\n",
    "        if not np.all(np.isfinite(Phi)):\n",
    "            print(f\"Stopped at step {i}: non-finite entries in Phi\")\n",
    "            break\n",
    "\n",
    "        current = Phi\n",
    "        last_eval = evals\n",
    "\n",
    "        # print every ~10% of total steps (works for n_steps=10 too)\n",
    "        if (i % max(1, n_steps // 10) ) == 0 or i == 1 or i == n_steps:\n",
    "            support = np.count_nonzero(np.abs(current) > 1e-10)\n",
    "            print(f\"step {i:4d}: approx E = {last_eval:.8f}, support = {support}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(\"RuntimeError during filtering:\", e)\n",
    "\n",
    "# final result in `current`, last Rayleigh estimate in `last_eval`\n",
    "Phi_final = current\n",
    "E_final = last_eval\n",
    "print(\"Done. Final approx E:\", E_final)\n",
    "print(\"Final support size:\", np.count_nonzero(np.abs(Phi_final) > 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7f448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 iterations with m=500, pad=0.05\n",
      "step    1: approx E = -17.99504766, support = 524288\n",
      "step    5: approx E = -18.02212267, support = 524288\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, n_steps + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         Phi, evals = \u001b[43mchebyshev_filter_v0_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                                               \u001b[49m\u001b[43mtarget_E0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_jackson\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_jackson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m         \u001b[38;5;66;03m# basic sanity checks\u001b[39;00m\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(evals):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 726\u001b[39m, in \u001b[36mchebyshev_filter_v0_numpy\u001b[39m\u001b[34m(H, v0, Emin, Emax, target_E0, m, pad, use_jackson, rng)\u001b[39m\n\u001b[32m    724\u001b[39m     tkp1 = \u001b[32m2.0\u001b[39m * Htilde_dot(tk) - tkm1\n\u001b[32m    725\u001b[39m     filt = filt + alpha[k] * tkp1\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     tkm1, tk = tk, tkp1\n\u001b[32m    728\u001b[39m \u001b[38;5;66;03m# 5) Normalize and Rayleigh quotient\u001b[39;00m\n\u001b[32m    729\u001b[39m filt_norm = norm(filt)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# run many short Chebyshev filters (m=1000) repeatedly instead of one huge m\n",
    "m = 1000\n",
    "n_steps = 50\n",
    "pad = 0.05\n",
    "use_jackson = True\n",
    "\n",
    "start_vec = vc0\n",
    "current = start_vec\n",
    "Emin = -62.51489576\n",
    "Emax = 62.60812227\n",
    "target = -18.0\n",
    "\n",
    "print(f\"Running {n_steps} iterations with m={m}, pad={pad}\")\n",
    "\n",
    "last_eval = None\n",
    "try:\n",
    "    for i in range(1, n_steps + 1):\n",
    "        Phi, evals = chebyshev_filter_v0_numpy(H, current, Emin=Emin, Emax=Emax,\n",
    "                                               target_E0=target, m=m, pad=pad, use_jackson=use_jackson)\n",
    "        # basic sanity checks\n",
    "        if not np.isfinite(evals):\n",
    "            print(f\"Stopped at step {i}: non-finite eval {evals}\")\n",
    "            break\n",
    "        if not np.all(np.isfinite(Phi)):\n",
    "            print(f\"Stopped at step {i}: non-finite entries in Phi\")\n",
    "            break\n",
    "\n",
    "        current = Phi\n",
    "        last_eval = evals\n",
    "\n",
    "        # print every ~10% of total steps (works for n_steps=10 too)\n",
    "        if (i % max(1, n_steps // 10) ) == 0 or i == 1 or i == n_steps:\n",
    "            support = np.count_nonzero(np.abs(current) > 1e-10)\n",
    "            print(f\"step {i:4d}: approx E = {last_eval:.8f}, support = {support}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(\"RuntimeError during filtering:\", e)\n",
    "\n",
    "# final result in `current`, last Rayleigh estimate in `last_eval`\n",
    "Phi_final = current\n",
    "E_final = last_eval\n",
    "print(\"Done. Final approx E:\", E_final)\n",
    "print(\"Final support size:\", np.count_nonzero(np.abs(Phi_final) > 1e-10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
