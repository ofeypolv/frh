{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574efd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from numpy.linalg import norm\n",
    "import os\n",
    "from scipy.linalg import eigh, qr, null_space, norm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from scipy.sparse import eye, kron, identity, csr_matrix, csc_matrix, lil_matrix, dok_matrix, issparse, coo_matrix\n",
    "from scipy.sparse.linalg import eigsh, eigs, lobpcg, LinearOperator, ArpackNoConvergence\n",
    "from scipy.optimize import curve_fit\n",
    "from qutip import Qobj, ptrace, entropy_vn, qeye, tensor\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import sympy as sp\n",
    "from collections import Counter\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f949390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauli_x():\n",
    "    \"\"\"Pauli X matrix.\"\"\"\n",
    "    return np.array([[0, 1], [1, 0]])\n",
    "\n",
    "def pauli_z():\n",
    "    \"\"\"Pauli Z matrix.\"\"\"\n",
    "    return np.array([[1, 0], [0, -1]])\n",
    "\n",
    "def dodecahedral_bonds(): #20 vertices\n",
    "    \"\"\"\n",
    "    Defines the connectivity of a true 20-vertex dodecahedral molecular structure.\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: Each tuple (i, j) represents a bond between spin i and spin j.\n",
    "    \"\"\"\n",
    "    bonds = [(0, 13), (0, 14), (0, 15), (1, 4), (1, 5), (1, 12),\n",
    "    (2, 6), (2, 13), (2, 18), (3, 7), (3, 14), (3, 19),\n",
    "    (4, 10), (4, 18), (5, 11), (5, 19), (6, 10), (6, 15),\n",
    "    (7, 11), (7, 15), (8, 9), (8, 13), (8, 16), (9, 14), (9, 17),\n",
    "    (10, 11), (12, 16), (12, 17), (16, 18), (17, 19)]\n",
    "\n",
    "    return bonds\n",
    "\n",
    "\n",
    "def transverse_field_ising_dodecahedral(N, J, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an dodecahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the dodecahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 20:\n",
    "        raise ValueError(\"Dodecahedral molecules typically have N = 20 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get dodecahedral bonds\n",
    "    bonds = dodecahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for dodecahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def ising_dodecahedron(N, J):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on a dodecahedral molecular structure without transverse field.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the dodecahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        \"\"\"\n",
    "    if N != 20:\n",
    "        raise ValueError(\"Dodecahedral molecules typically have N = 20 sites.\")\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get dodecahedral bonds\n",
    "    bonds = dodecahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for dodecahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def transverse_field_dodecahedral(N, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on a dodecahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the dodecahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 20:\n",
    "        raise ValueError(\"Dodecahedral molecules typically have N = 20 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get dodecahedral bonds\n",
    "    bonds = dodecahedral_bonds()\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "'''\n",
    "def partial_trace_qubit(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits.\"\"\"\n",
    "    keep_dims = np.prod([dims[i] for i in keep])\n",
    "    trace_dims = np.prod([dims[i] for i in range(len(dims)) if i not in keep])\n",
    "    rho = rho.reshape([keep_dims, trace_dims, keep_dims, trace_dims])\n",
    "    return np.trace(rho, axis1=1, axis2=3).reshape([keep_dims, keep_dims])\n",
    "\n",
    "def partial_trace_qubit_torch(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits using PyTorch.\"\"\"\n",
    "    keep_dims = torch.prod(torch.tensor([dims[i] for i in keep]))\n",
    "    trace_dims = torch.prod(torch.tensor([dims[i] for i in range(len(dims)) if i not in keep]))\n",
    "    rho = rho.view(keep_dims, trace_dims, keep_dims, trace_dims)\n",
    "    # Compute the partial trace\n",
    "    traced_rho = torch.zeros((keep_dims, keep_dims), dtype=rho.dtype)\n",
    "    for i in range(trace_dims):\n",
    "        traced_rho += rho[:, i, :, i]\n",
    "    #return traced_rho.view(keep_dims, keep_dims)\n",
    "    return traced_rho'''\n",
    "\n",
    "def isket_numpy(arr):\n",
    "    \"\"\"\n",
    "    Check if a NumPy array is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: np.ndarray, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(\"Input must be a NumPy array\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_numpy(Q, sel, dims): # numpy function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using NumPy.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: numpy object, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - numpy object, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = np.asarray(dims[0], dtype=np.int32).ravel()\n",
    "    nd = len(rd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = np.array([sel])\n",
    "    else:\n",
    "        sel = np.asarray(sel)\n",
    "    sel = list(np.sort(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = (rd[sel]).tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(np.arange(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = (rd[qtrace]).tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = list(rd)\n",
    "    if isket_numpy(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        vmat = (Q\n",
    "                .reshape(rd)\n",
    "                .transpose(sel + qtrace)\n",
    "                .reshape([np.prod(dkeep), np.prod(dtrace)]))\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat.dot(vmat.conj().T)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        rhomat = np.trace(Q\n",
    "                          .reshape(rd + rd)\n",
    "                          .transpose(qtrace + [nd + q for q in qtrace] +\n",
    "                                     sel + [nd + q for q in sel])\n",
    "                          .reshape([np.prod(dtrace),\n",
    "                                    np.prod(dtrace),\n",
    "                                    np.prod(dkeep),\n",
    "                                    np.prod(dkeep)]))\n",
    "    return rhomat\n",
    "\n",
    "\n",
    "def ptrace_sparse(psi_sparse, keep, dims):\n",
    "    \"\"\"\n",
    "    Compute the partial trace over arbitrary subsystems using sparse matrix operations.\n",
    "\n",
    "    Args:\n",
    "        psi_sparse (scipy.sparse matrix): Full density matrix of shape (D, D), where D = product(dims)\n",
    "        keep (list of int): Subsystems to keep (indices, 0-indexed)\n",
    "        dims (list of int): List of subsystem dimensions, e.g., [2]*n for n qubits\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: Reduced density matrix over kept subsystems\n",
    "    \"\"\"\n",
    "    if not issparse(psi_sparse):\n",
    "        raise ValueError(\"psi_sparse must be a scipy.sparse matrix\")\n",
    "    n = len(dims)\n",
    "    D = np.prod(dims)\n",
    "    if psi_sparse.shape != (D, D):\n",
    "        raise ValueError(\"Density matrix shape does not match dims\")\n",
    "    trace = [i for i in range(n) if i not in keep]\n",
    "    d_keep = np.prod([dims[i] for i in keep])\n",
    "    # Prepare output\n",
    "    data = []\n",
    "    row_idx = []\n",
    "    col_idx = []\n",
    "\n",
    "    # Precompute bit masks\n",
    "    def idx_to_bits(idx):\n",
    "        return np.array(list(np.binary_repr(idx, width=n))).astype(int)\n",
    "    \n",
    "\n",
    "    psi_sparse = psi_sparse.tocoo()\n",
    "    for i, j, val in zip(psi_sparse.row, psi_sparse.col, psi_sparse.data):\n",
    "        bi = idx_to_bits(i)\n",
    "        bj = idx_to_bits(j)\n",
    "\n",
    "\n",
    "        # Only sum terms where traced-out subsystems agree\n",
    "        if np.all(bi[trace] == bj[trace]):\n",
    "            # Extract kept bits and convert to reduced indices\n",
    "            #print('condition met for i, j:', i, j)\n",
    "            i_red_bits = bi[keep]\n",
    "            j_red_bits = bj[keep]\n",
    "            i_red = int(\"\".join(i_red_bits.astype(str)), 2)\n",
    "            j_red = int(\"\".join(j_red_bits.astype(str)), 2)\n",
    "\n",
    "\n",
    "            data.append(val)\n",
    "            row_idx.append(i_red)\n",
    "            col_idx.append(j_red)\n",
    "    \n",
    "    return coo_matrix((data, (row_idx, col_idx)), shape=(d_keep, d_keep)).tocsr()\n",
    "\n",
    "\n",
    "def isket_torch(arr):\n",
    "    \"\"\"\n",
    "    Check if a PyTorch tensor is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: torch.Tensor, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, torch.Tensor):\n",
    "        raise ValueError(\"Input must be a PyTorch tensor\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_torch(Q, sel, dims): # torch function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: torch.Tensor, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = torch.tensor(dims[0], dtype=torch.int32).flatten()\n",
    "    nd = len(rd)\n",
    "    #print(\"rd\", rd)\n",
    "    #print(\"nd\", nd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = torch.tensor([sel])\n",
    "    else:\n",
    "        sel = torch.tensor(sel)\n",
    "    sel = torch.sort(sel).values.tolist()\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = rd[sel].tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(range(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = rd[qtrace].tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = rd.tolist()\n",
    "    if isket_torch(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        reshaped_Q = Q.reshape(rd)\n",
    "        #print(reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(sel + qtrace)\n",
    "        #print(transposed_Q.shape)\n",
    "        vmat = transposed_Q.reshape([torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dtrace))])\n",
    "        #print(vmat.shape)\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat @ vmat.conj().T\n",
    "        #print(rhomat.shape)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        reshaped_Q = Q.reshape(rd + rd)\n",
    "        #print(\"reshaped_Q\", reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(qtrace + [nd + q for q in qtrace] + sel + [nd + q for q in sel])\n",
    "        #print(\"transposed_Q\", transposed_Q.shape)\n",
    "        reshaped_transposed_Q = transposed_Q.reshape([torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))])\n",
    "        #print(\"reshaped_transposed_Q\", reshaped_transposed_Q.shape)\n",
    "        #rhomat = torch.trace(reshaped_transposed_Q)\n",
    "        rhomat = torch.einsum('iikl->kl', reshaped_transposed_Q)\n",
    "        # Trace out the first two dimensions\n",
    "        #rhomat = torch.zeros((torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))), dtype=Q.dtype)\n",
    "        #for i in range(reshaped_transposed_Q.shape[0]):\n",
    "        #    for j in range(reshaped_transposed_Q.shape[1]):\n",
    "        #        rhomat += reshaped_transposed_Q[i, j, :, :]\n",
    "        #print(\"rhomat\", rhomat.shape)\n",
    "    return rhomat\n",
    "\n",
    "def entanglement_entropy(psi, subsystem, total_size):\n",
    "\n",
    "    '''Computes the bipartite entanglement entropy of a pure state.\n",
    "    \n",
    "    Parameters:\n",
    "    psi : np.array\n",
    "        The wavefunction (state vector) of the full system.\n",
    "    subsystem_size : int\n",
    "        The number of qubits in subsystem A.\n",
    "    total_size : int\n",
    "        The total number of qubits in the system.\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        The von Neumann entanglement entropy S_A.'''\n",
    "    \n",
    "    psi_matrix =  np.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_numpy(psi_matrix, subsystem, [[2]*total_size, [2]*total_size])  # Partial trace over B\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rho_A)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch(psi, subsystem, total_size):\n",
    "    \"\"\"\n",
    "    Computes the bipartite entanglement entropy of a pure state using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), the wavefunction (state vector) of the full system.\n",
    "    - subsystem_size: int, the number of qubits in subsystem A.\n",
    "    - total_size: int, the total number of qubits in the system.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), the von Neumann entanglement entropy S_A.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(psi, torch.Tensor):\n",
    "        psi = torch.tensor(psi, dtype=torch.complex64)\n",
    "    \n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Compute the density matrix |psi><psi|\n",
    "    psi_matrix = torch.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_torch(psi_matrix, subsystem, [[2] * total_size, [2] * total_size])  # Partial trace over B\n",
    "\n",
    "    #rho_A = rho_A.to(dtype=torch.float64)\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigvals = torch.linalg.eigvalsh(rho_A)\n",
    "\n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "\n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_qutip(psi, subsystem, total_size):\n",
    "    \n",
    "    # Convert the wavefunction to a QuTiP Qobj\n",
    "    density_matrix = np.outer(psi, psi.conj())\n",
    "    density_matrix_qobj = Qobj(density_matrix, dims=[[2]*total_size, [2]*total_size])\n",
    "\n",
    "    rho_A = ptrace(density_matrix_qobj, subsystem)\n",
    "    # Compute the von Neumann entropy S_A\n",
    "    entropy = entropy_vn(rho_A, base=2)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_np_ptrace(rdm):\n",
    "    # rdm already computed and converted to numpy\n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rdm)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch_ptrace(rdm):\n",
    "\n",
    "    eigvals = torch.linalg.eigvalsh(rdm)\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entanglement_entropy_qutip_torch(psi, N):\n",
    "    \"\"\"\n",
    "    Compute the von Neumann entanglement entropy using qutip.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), state vector of a quantum system.\n",
    "    - N: int, total number of qubits.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), von Neumann entropy.\n",
    "    \"\"\"\n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Convert PyTorch tensor to NumPy for QuTiP\n",
    "    psi_np = psi.detach().numpy()\n",
    "\n",
    "    rho_np = np.outer(psi_np, psi_np.conj())\n",
    "    rho_qobj = Qobj(rho_np, dims=[[2] * N, [2] * N])\n",
    "\n",
    "    rho_A = ptrace(rho_qobj, list(range(N // 2)))\n",
    "\n",
    "    # Compute von Neumann entropy\n",
    "    entropy = entropy_vn(rho_A, base=2)  # Compute in log base 2\n",
    "\n",
    "    # Convert back to PyTorch tensor to allow gradient flow\n",
    "    return torch.tensor(entropy, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Define the linear combination function - numpy\n",
    "def linear_combination_np(coeffs, psis):\n",
    "    # Ensure psis are numpy tensors\n",
    "    psi_np = [np.array(psi) for psi in psis]\n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi = sum(c * psi for c, psi in zip(coeffs, psis))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "# Define the linear combination function - torch\n",
    "def linear_combination(coeffs, psis):\n",
    "    # Ensure psis are PyTorch tensors\n",
    "    psis_torch = [torch.tensor(psi, dtype=torch.complex64) if not isinstance(psi, torch.Tensor) else psi for psi in psis]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi_torch = sum(c * psi for c, psi in zip(coeffs, psis_torch))\n",
    "    \n",
    "    return psi_torch\n",
    "\n",
    "# Define the linear combination function - torch but after computing the ptrace of outer products of scars\n",
    "def linear_combination_outer(coeffs, outs):\n",
    "    # Ensure outs are PyTorch tensors\n",
    "    outs_torch = [torch.tensor(out, dtype=torch.complex64) if not isinstance(out, torch.Tensor) else out for out in outs]\n",
    "    torch_coeffs = torch.tensor(coeffs, dtype=torch.complex64)\n",
    "\n",
    "    # Compute the PyTorch tensor of out_coeffs which is the product of all possible combinations of c_i^* times c_j\n",
    "    out_coeffs = torch.zeros((len(torch_coeffs), len(torch_coeffs)), dtype=torch.complex64)\n",
    "    for i in range(len(torch_coeffs)):\n",
    "        for j in range(len(torch_coeffs)):\n",
    "            out_coeffs[i, j] = torch.conj(torch_coeffs[i]) * torch_coeffs[j]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    lin_torch = sum(out_coeffs[i, j] * outs_torch[i] for i in range(len(coeffs)) for j in range(len(coeffs)))\n",
    "    \n",
    "    return lin_torch\n",
    "\n",
    "######################################################\n",
    "\n",
    "# chebyshev\n",
    "\n",
    "def jackson_weights(m):\n",
    "    \"\"\"\n",
    "    Jackson damping coefficients for k = 0..m.\n",
    "    (You can replace this with your own implementation if you already have one.)\n",
    "    \"\"\"\n",
    "    k = np.arange(m+1, dtype=float)\n",
    "    N = m + 1.0\n",
    "    # Standard Jackson kernel for Chebyshev series\n",
    "    # g_k = [(N - k + 1) * cos(pi*k/(N+1)) + sin(pi*k/(N+1)) / tan(pi/(N+1))] / (N+1)\n",
    "    gk = ((N - k + 1) * np.cos(np.pi * k / (N + 1.0)) +\n",
    "          np.sin(np.pi * k / (N + 1.0)) / np.tan(np.pi / (N + 1.0))) / (N + 1.0)\n",
    "    return gk\n",
    "\n",
    "def chebyshev_filter_numpy(H, Emin, Emax, target_E0, m,\n",
    "                           pad=0.05, use_jackson=True, rng=None):\n",
    "    \"\"\"\n",
    "    Chebyshev cosine kernel filter, pure NumPy/SciPy version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse_matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping.\n",
    "    rng : np.random.Generator, optional\n",
    "        Random generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filt : ndarray, shape (n,)\n",
    "        Normalized filtered vector.\n",
    "    approx_E : float\n",
    "        Rayleigh quotient <filt|H|filt>.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: matvec with Htilde = (H - c I)/d\n",
    "    def Htilde_dot(v):\n",
    "        Hv = H @ v   # works for dense or sparse\n",
    "        return (Hv - c * v) / d\n",
    "\n",
    "    # 3) Random start vector\n",
    "    n = H.shape[0]\n",
    "    v0 = rng.standard_normal(n)\n",
    "    v0 /= norm(v0)\n",
    "\n",
    "    # 4) Chebyshev recursion\n",
    "    t0 = v0\n",
    "    t1 = Htilde_dot(v0)\n",
    "\n",
    "    filt = alpha[0] * t0 + alpha[1] * t1\n",
    "\n",
    "    tkm1 = t0\n",
    "    tk   = t1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        tkp1 = 2.0 * Htilde_dot(tk) - tkm1\n",
    "        filt = filt + alpha[k] * tkp1\n",
    "        tkm1, tk = tk, tkp1\n",
    "\n",
    "    # 5) Normalize and Rayleigh quotient\n",
    "    filt_norm = norm(filt)\n",
    "    if filt_norm == 0:\n",
    "        raise RuntimeError(\"Filtered vector became zero; try different parameters.\")\n",
    "    filt /= filt_norm\n",
    "\n",
    "    Hv = H @ filt\n",
    "    approx_E = np.vdot(filt, Hv).real / np.vdot(filt, filt).real\n",
    "\n",
    "    return filt, approx_E\n",
    "\n",
    "def chebyshev_filter_v0_numpy(H, v0, Emin, Emax, target_E0, m,\n",
    "                           pad=0.05, use_jackson=True, rng=None):\n",
    "    \"\"\"\n",
    "    Chebyshev cosine kernel filter, pure NumPy/SciPy version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse_matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    v0 : (n,) array_like\n",
    "        Initial vector to start the Chebyshev recursion.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping.\n",
    "    rng : np.random.Generator, optional\n",
    "        Random generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filt : ndarray, shape (n,)\n",
    "        Normalized filtered vector.\n",
    "    approx_E : float\n",
    "        Rayleigh quotient <filt|H|filt>.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: matvec with Htilde = (H - c I)/d\n",
    "    def Htilde_dot(v):\n",
    "        Hv = H @ v   # works for dense or sparse\n",
    "        return (Hv - c * v) / d\n",
    "\n",
    "    # 3) Normalize random start vector if not already normalized\n",
    "    v0 /= norm(v0)\n",
    "\n",
    "    # 4) Chebyshev recursion\n",
    "    t0 = v0\n",
    "    t1 = Htilde_dot(v0)\n",
    "\n",
    "    filt = alpha[0] * t0 + alpha[1] * t1\n",
    "\n",
    "    tkm1 = t0\n",
    "    tk   = t1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        tkp1 = 2.0 * Htilde_dot(tk) - tkm1\n",
    "        filt = filt + alpha[k] * tkp1\n",
    "        tkm1, tk = tk, tkp1\n",
    "\n",
    "    # 5) Normalize and Rayleigh quotient\n",
    "    filt_norm = norm(filt)\n",
    "    if filt_norm == 0:\n",
    "        raise RuntimeError(\"Filtered vector became zero; try different parameters.\")\n",
    "    filt /= filt_norm\n",
    "\n",
    "    Hv = H @ filt\n",
    "    approx_E = np.vdot(filt, Hv).real / np.vdot(filt, filt).real\n",
    "\n",
    "    return filt, approx_E\n",
    "\n",
    "def chebyshev_filter_block_numpy(H, V0, Emin, Emax, target_E0, m,\n",
    "                                 pad=0.05, use_jackson=True):\n",
    "    \"\"\"\n",
    "    Block Chebyshev cosine kernel filter (pure NumPy/SciPy version).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : (n, n) array_like or sparse matrix\n",
    "        Real symmetric / Hermitian matrix.\n",
    "    V0 : (n, p) array_like\n",
    "        Initial block of p vectors (columns) to start the Chebyshev recursion.\n",
    "        Columns should be linearly independent; they need not be orthonormal.\n",
    "    Emin, Emax : float\n",
    "        Estimated spectral bounds of H.\n",
    "    target_E0 : float\n",
    "        Target energy where we want to focus the filter.\n",
    "    m : int\n",
    "        Polynomial degree.\n",
    "    pad : float, optional\n",
    "        Padding fraction for bounds.\n",
    "    use_jackson : bool, optional\n",
    "        Apply Jackson damping to the Chebyshev coefficients.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Phi : ndarray, shape (n, p)\n",
    "        Approximate eigenvectors (columns) near target_E0.\n",
    "    evals : ndarray, shape (p,)\n",
    "        Corresponding Ritz eigenvalues.\n",
    "    \"\"\"\n",
    "\n",
    "    V0 = np.array(V0, dtype=np.complex128, copy=True)\n",
    "    n, p = V0.shape\n",
    "\n",
    "    # 1) Padded bounds and rescaling parameters\n",
    "    width  = Emax - Emin\n",
    "    Emin_p = Emin - pad * width\n",
    "    Emax_p = Emax + pad * width\n",
    "\n",
    "    c = 0.5 * (Emax_p + Emin_p)\n",
    "    d = 0.5 * (Emax_p - Emin_p)\n",
    "\n",
    "    # 2) Rescaled target x0 and Chebyshev coefficients alpha_k\n",
    "    x0 = (target_E0 - c) / d\n",
    "    x0 = float(np.clip(x0, -0.999999, 0.999999))\n",
    "    theta0 = np.arccos(x0)\n",
    "\n",
    "    alpha = np.cos(np.arange(m+1) * theta0)\n",
    "    if use_jackson:\n",
    "        g = jackson_weights(m)   # assumed defined elsewhere\n",
    "        alpha = alpha * g\n",
    "\n",
    "    # Helper: Htilde = (H - c I)/d acting on a block\n",
    "    def Htilde_dot_block(V):\n",
    "        HV = H @ V              # works for dense or sparse\n",
    "        return (HV - c * V) / d\n",
    "\n",
    "    # 3) Orthonormalize starting block: V0 -> Q0\n",
    "    #    (this gives us an orthonormal basis of the initial subspace)\n",
    "    Q0, _ = np.linalg.qr(V0)    # (n, p), orthonormal columns\n",
    "\n",
    "    # 4) Block Chebyshev recursion\n",
    "    T0 = Q0                     # (n, p)\n",
    "    T1 = Htilde_dot_block(Q0)   # (n, p)\n",
    "\n",
    "    filt = alpha[0] * T0 + alpha[1] * T1\n",
    "\n",
    "    Tkm1 = T0\n",
    "    Tk   = T1\n",
    "\n",
    "    for k in range(2, m+1):\n",
    "        Tkp1 = 2.0 * Htilde_dot_block(Tk) - Tkm1\n",
    "        filt = filt + alpha[k] * Tkp1\n",
    "        Tkm1, Tk = Tk, Tkp1\n",
    "\n",
    "    # 5) Orthonormalize the filtered block\n",
    "    Q, _ = np.linalg.qr(filt)   # (n, p), orthonormal columns spanning filtered subspace\n",
    "\n",
    "    # 6) Rayleighâ€“Ritz in the filtered subspace\n",
    "    # H_sub is the projected matrix H in basis Q\n",
    "    H_sub = Q.conj().T @ (H @ Q)    # (p, p)\n",
    "    evals, U = np.linalg.eigh(H_sub)\n",
    "\n",
    "    # 7) Lift Ritz eigenvectors back to full space\n",
    "    Phi = Q @ U    # (n, p)\n",
    "\n",
    "    return Phi, evals\n",
    "\n",
    "### symmetry sectors -- Ih NEEDS TO BE ADDED\n",
    "\n",
    "def check_magnetization_sector(vec, N, tol=1e-6): ### total magnetization is not conserved --- it only applies to scars\n",
    "    \"\"\"Check average magnetization of a state vector.\"\"\"\n",
    "    D = 1 << N\n",
    "    mag_avg = 0.0\n",
    "    for b in range(D):\n",
    "        mag_avg += magnetization(b, N) * np.abs(vec[b])**2\n",
    "    return mag_avg\n",
    "\n",
    "def check_parity_sector(vec, N, tol=1e-6):\n",
    "    \"\"\"Check if vector is in even/odd parity sector.\"\"\"\n",
    "    D = 1 << N\n",
    "    weight_even = sum(np.abs(vec[b])**2 for b in range(D) if parity(b, N) == 1)\n",
    "    weight_odd = sum(np.abs(vec[b])**2 for b in range(D) if parity(b, N) == -1)\n",
    "    if weight_even > 1.0 - tol:\n",
    "        return \"even\"\n",
    "    elif weight_odd > 1.0 - tol:\n",
    "        return \"odd\"\n",
    "    else:\n",
    "        return f\"mixed (even={weight_even:.4f}, odd={weight_odd:.4f})\"\n",
    "\n",
    "def build_parity_operator(N):\n",
    "    \"\"\"\n",
    "    Build the parity operator as a matrix.\n",
    "    Parity operator P|b> = (-1)^(number of 1s) |b>\n",
    "    \n",
    "    Parameters:\n",
    "    - N: int, number of qubits\n",
    "    \n",
    "    Returns:\n",
    "    - P_op: sparse matrix, parity operator (diagonal)\n",
    "    \"\"\"\n",
    "    D = 1 << N\n",
    "    # build diagonal entries as a small-memory 1D array\n",
    "    diag = np.fromiter((1 if bin(b).count('1') % 2 == 0 else -1 for b in range(D)),\n",
    "                       dtype=np.int8, count=D)\n",
    "    # construct sparse diagonal directly (COO -> CSR) without making a dense (D,D) array\n",
    "    rows = np.arange(D, dtype=np.int64)\n",
    "    P_op = csr_matrix((diag.astype(np.int8), (rows, rows)), shape=(D, D))\n",
    "    return P_op\n",
    "\n",
    "def commutator_norm(A, B):\n",
    "    \"\"\"\n",
    "    Compute the Frobenius norm of the commutator [A, B] = AB - BA.\n",
    "    For sparse matrices, use sparse operations.\n",
    "    \n",
    "    Parameters:\n",
    "    - A, B: matrices (dense or sparse)\n",
    "    \n",
    "    Returns:\n",
    "    - float, ||[A, B]||_F\n",
    "    \"\"\"\n",
    "    comm = A @ B - B @ A\n",
    "    \n",
    "    if issparse(comm):\n",
    "        # For sparse matrices, compute Frobenius norm\n",
    "        return np.sqrt(comm.multiply(comm.conj()).sum())\n",
    "    else:\n",
    "        # For dense matrices\n",
    "        return np.linalg.norm(comm, 'fro')\n",
    "\n",
    "def magnetization(bitstring, N):\n",
    "    # Suppose spin up = 1, spin down = 0\n",
    "    # Or adjust convention as needed\n",
    "    n_up = bitstring.bit_count()\n",
    "    n_down = N - n_up\n",
    "    return n_up - n_down  # proportional to total Sz\n",
    "\n",
    "def parity(bitstring, N):\n",
    "    \"\"\"\n",
    "    Compute parity of a bitstring.\n",
    "    Returns +1 for even number of up spins, -1 for odd.\n",
    "    \"\"\"\n",
    "    n_up = bitstring.bit_count()\n",
    "    return 1 if (n_up % 2 == 0) else -1\n",
    "\n",
    "def build_sz0_even_parity_indices(N):\n",
    "    \"\"\"\n",
    "    Build indices for states with:\n",
    "    - Zero magnetization (Sz = 0)\n",
    "    - Even parity (even number of up spins)\n",
    "    \n",
    "    Parameters:\n",
    "    - N: int, number of qubits\n",
    "    \n",
    "    Returns:\n",
    "    - idx_sector: np.array, indices satisfying all conditions\n",
    "    \"\"\"\n",
    "    D = 1 << N\n",
    "    idx_sector = []\n",
    "    \n",
    "    for b in range(D):\n",
    "        # Check magnetization = 0\n",
    "        if magnetization(b, N) != 0:\n",
    "            continue\n",
    "        \n",
    "        # Check even parity\n",
    "        if parity(b, N) != 1:\n",
    "            continue\n",
    "        \n",
    "        idx_sector.append(b)\n",
    "    \n",
    "    return np.array(idx_sector, dtype=np.int64)\n",
    "\n",
    "def random_block_in_sz0_even_parity(N, block_size=5, rng=None):\n",
    "    \"\"\"\n",
    "    Generate random block of vectors in the symmetry sector:\n",
    "    - Sz = 0\n",
    "    - Even parity\n",
    "    \n",
    "    Parameters:\n",
    "    - N: int, number of qubits\n",
    "    - block_size: int, number of vectors\n",
    "    - rng: random generator\n",
    "    \n",
    "    Returns:\n",
    "    - Q: (D, block_size) array, orthonormal columns in symmetry sector\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    idx_sector = build_sz0_even_parity_indices(N)\n",
    "    V = np.zeros((D, block_size), dtype=np.complex128)\n",
    "\n",
    "    for k in range(block_size):\n",
    "        v = np.zeros(D, dtype=np.complex128)\n",
    "        \n",
    "        # Random amplitudes in the sector\n",
    "        amplitudes = rng.normal(size=len(idx_sector)) + 1j * rng.normal(size=len(idx_sector))\n",
    "        \n",
    "        # Assign random amplitudes to basis states in the sector\n",
    "        v[idx_sector] = amplitudes\n",
    "        \n",
    "        V[:, k] = v\n",
    "\n",
    "    # Orthonormalize columns\n",
    "    Q, _ = np.linalg.qr(V)\n",
    "    return Q   # shape (D, block_size)\n",
    "\n",
    "def random_block_in_sz0_even_parity_and_Ih_g_intersection(N, projectors, irrep_labels,\n",
    "                                                         block_size=5, rng=None, max_attempts=50):\n",
    "    \"\"\"\n",
    "    Build an orthonormal block of vectors that lie simultaneously in:\n",
    "      - Sz = 0 & even parity (computational-basis subspace),\n",
    "      - Ih 'g' (gerade) sector (sum of irreps ending with 'g').\n",
    "\n",
    "    Strategy:\n",
    "      - draw random vectors supported only on the Sz0+even-parity basis indices,\n",
    "      - project each vector into the Ih g-sector using the provided projectors,\n",
    "      - keep nonzero results, renormalize and orthonormalize the collected block.\n",
    "\n",
    "    Returns\n",
    "      Q : (D, block_size) ndarray with orthonormal columns in the intersection subspace.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    # 1) build index list for Sz=0 & even parity\n",
    "    idx_sector = build_sz0_even_parity_indices(N)\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(\"No basis states found for Sz=0 & even parity\")\n",
    "\n",
    "    D = (1 << N)\n",
    "\n",
    "    # 2) build total projector onto g-sector P_g\n",
    "    g_indices = [i for i, lbl in enumerate(irrep_labels) if str(lbl).endswith('g')]\n",
    "    if len(g_indices) == 0:\n",
    "        raise ValueError(\"No 'g' irreps found in irrep_labels\")\n",
    "    P_g = None\n",
    "    for i in g_indices:\n",
    "        P = projectors[i]\n",
    "        P_g = P.copy() if P_g is None else (P_g + P)\n",
    "    P_g = P_g.astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    # 3) generate candidates: random amplitudes on idx_sector, then project into P_g\n",
    "    V = np.zeros((D, block_size), dtype=np.complex128)\n",
    "    k = 0\n",
    "    attempts = 0\n",
    "    while k < block_size and attempts < max_attempts * block_size:\n",
    "        attempts += 1\n",
    "        # random complex amplitudes only on allowed basis states\n",
    "        amps = rng.normal(size=len(idx_sector)) + 1j * rng.normal(size=len(idx_sector))\n",
    "        v = np.zeros(D, dtype=np.complex128)\n",
    "        v[idx_sector] = amps\n",
    "        # project into g-sector\n",
    "        v_proj = P_g @ v\n",
    "        vnorm = norm(v_proj)\n",
    "        if vnorm > 0:\n",
    "            V[:, k] = v_proj / vnorm\n",
    "            k += 1\n",
    "        else:\n",
    "            # retry; if too many failures, try deterministic fallback: project a basis vector\n",
    "            if attempts > max_attempts * block_size // 5:\n",
    "                for i_b in range(len(idx_sector)):\n",
    "                    e = np.zeros(D, dtype=np.complex128)\n",
    "                    e[idx_sector[i_b]] = 1.0\n",
    "                    v_proj = P_g @ e\n",
    "                    vnorm = norm(v_proj)\n",
    "                    if vnorm > 0:\n",
    "                        V[:, k] = v_proj / vnorm\n",
    "                        k += 1\n",
    "                        break\n",
    "\n",
    "    if k < block_size:\n",
    "        raise RuntimeError(f\"Could not construct {block_size} nonzero vectors in the intersection after {attempts} attempts\")\n",
    "\n",
    "    # 4) orthonormalize columns and return requested number\n",
    "    Q, _ = np.linalg.qr(V)\n",
    "    return Q[:, :block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec2cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamiltonian shape: (1048576, 1048576)\n",
      "Non-zero elements in H: 32321100\n"
     ]
    }
   ],
   "source": [
    "N = 20  # Number of spins\n",
    "J = 1.0  # Interaction strength\n",
    "h = 3.0  # Transverse field strength # this is the value in the paper. maybe try  other values too, including the critical value one (h=J=1)\n",
    "\n",
    "# Assuming transverse_field_ising is defined and returns a sparse Hermitian matrix\n",
    "H = transverse_field_ising_dodecahedral(N, J, h)\n",
    "Hi = ising_dodecahedron(N, J)\n",
    "Htf = transverse_field_dodecahedral(N, h)\n",
    "\n",
    "print(f\"Hamiltonian shape: {H.shape}\")\n",
    "print(f\"Non-zero elements in H: {H.nnz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9fbbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if H commutes with symmetry operators:\n",
      "\n",
      "Parity:\n",
      "  ||[H, P]||_F = 0.000000e+00\n",
      "  ||H||_F = 1.483917e+04\n",
      "  Relative error: 0.000000e+00\n",
      "  Commutes: YES\n",
      "\n",
      "Operator properties:\n",
      "  ||P^2 - I||_F = 0.000000e+00+0.000000e+00j\n",
      "  P is involutory: YES\n"
     ]
    }
   ],
   "source": [
    "# Build symmetry operators\n",
    "P_op = build_parity_operator(N)\n",
    "\n",
    "# compute Frobenius norm of H (works for sparse or dense)\n",
    "if issparse(H):\n",
    "    H_norm = np.sqrt((H.multiply(H.conj())).sum())\n",
    "else:\n",
    "    H_norm = np.linalg.norm(H, 'fro')\n",
    "print(\"Checking if H commutes with symmetry operators:\\n\")\n",
    "\n",
    "# Check [H, P] = 0 (parity symmetry)\n",
    "comm_parity = commutator_norm(H, P_op)\n",
    "print(f\"Parity:\")\n",
    "print(f\"  ||[H, P]||_F = {comm_parity:.6e}\")\n",
    "print(f\"  ||H||_F = {H_norm:.6e}\")\n",
    "print(f\"  Relative error: {comm_parity / H_norm:.6e}\")\n",
    "print(f\"  Commutes: {'YES' if comm_parity / H_norm < 1e-10 else 'NO'}\\n\")\n",
    "\n",
    "# Additional check: verify P^2 = Identity\n",
    "P_squared = P_op @ P_op\n",
    "Id_op = eye(1 << N, dtype=np.complex128, format='csr')   # <-- use eye(), don't shadow identity()\n",
    "\n",
    "# FIX: subtract the matrix Id_op (not the identity function) and handle sparse/dense norm\n",
    "diff = P_squared - Id_op\n",
    "if issparse(diff):\n",
    "    P_identity_error = np.sqrt((diff.multiply(diff.conj())).sum())\n",
    "else:\n",
    "    P_identity_error = np.linalg.norm(diff, 'fro')\n",
    "# ...existing code...\n",
    "print(f\"Operator properties:\")\n",
    "print(f\"  ||P^2 - I||_F = {P_identity_error:.6e}\")\n",
    "print(f\"  P is involutory: {'YES' if P_identity_error < 1e-10 else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a987b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bonds: 30\n",
      "Loaded 120 I_h permutations on 20 sites.\n",
      "Number of automorphisms wrt your bonds: 120\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Dodecahedron bonds (current labelling)\n",
    "# ============================================================\n",
    "\n",
    "bonds = [(0, 13), (0, 14), (0, 15), (1, 4), (1, 5), (1, 12),\n",
    "    (2, 6), (2, 13), (2, 18), (3, 7), (3, 14), (3, 19),\n",
    "    (4, 10), (4, 18), (5, 11), (5, 19), (6, 10), (6, 15),\n",
    "    (7, 11), (7, 15), (8, 9), (8, 13), (8, 16), (9, 14), (9, 17),\n",
    "    (10, 11), (12, 16), (12, 17), (16, 18), (17, 19)]\n",
    "\n",
    "bonds_set = {tuple(sorted(e)) for e in bonds}\n",
    "print(\"Number of bonds:\", len(bonds_set))\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load Ih permutations from file\n",
    "# ============================================================\n",
    "\n",
    "def load_ih_permutations(path=\"ih_dodeca_permutations_0based.txt\"):\n",
    "    \"\"\"\n",
    "    Each line in ih_dodeca_permutations_0based.txt represents a permutation on vertices 0..19.\n",
    "    \"\"\"\n",
    "    perms = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            nums = line.strip('[]').split(',')\n",
    "            perms.append(np.array([int(x) for x in nums], dtype=int))\n",
    "    return perms\n",
    "\n",
    "perms = load_ih_permutations(\"ih_dodeca_permutations_0based.txt\")\n",
    "N_sites = len(perms[0])\n",
    "print(f\"Loaded {len(perms)} I_h permutations on {N_sites} sites.\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Graph automorphism checker (sanity)\n",
    "# ============================================================\n",
    "\n",
    "def is_automorphism(perm, bonds_set):\n",
    "    \"\"\"\n",
    "    Check if 'perm' is a graph automorphism of the icosahedron\n",
    "    defined by bonds_set, i.e. maps edges to edges.\n",
    "    \"\"\"\n",
    "    for i, j in bonds_set:\n",
    "        ii, jj = perm[i], perm[j]\n",
    "        if tuple(sorted((ii, jj))) not in bonds_set:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "num_auto = sum(is_automorphism(p, bonds_set) for p in perms)\n",
    "print(\"Number of automorphisms wrt your bonds:\", num_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d6950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bonds: 30\n",
      "Loaded 120 I_h permutations on 20 sites.\n",
      "Number of automorphisms wrt your bonds: 120\n",
      "Found 10 conjugacy classes in new labelling.\n",
      "class 0: size=12, order=10\n",
      "class 1: size=15, order= 2\n",
      "class 2: size=20, order= 6\n",
      "class 3: size=20, order= 3\n",
      "class 4: size=12, order= 5\n",
      "class 5: size=15, order= 2\n",
      "class 6: size=12, order=10\n",
      "class 7: size=12, order= 5\n",
      "class 8: size= 1, order= 2\n",
      "class 9: size= 1, order= 1\n",
      "\n",
      "Checking a few U_g for unitarity and permutation structure...\n",
      "Number of nonzeros in Ugâ€ Ug - I: 0\n",
      "All tests passed for this Ug.\n",
      "Number of nonzeros in Ugâ€ Ug - I: 0\n",
      "All tests passed for this Ug.\n",
      "Number of nonzeros in Ugâ€ Ug - I: 0\n",
      "All tests passed for this Ug.\n",
      "\n",
      "Number of distinct trace values: 6\n",
      "Distinct values: [4, 16, 256, 1024, 4096, 1048576]\n",
      "Counts per trace:\n",
      "  trace=4: 24\n",
      "  trace=16: 44\n",
      "  trace=256: 20\n",
      "  trace=1024: 16\n",
      "  trace=4096: 15\n",
      "  trace=1048576: 1\n",
      "\n",
      "Raw class summary (index, size, order, chi):\n",
      "{'idx': 0, 'size': 12, 'order': 10, 'chi': 4.0}\n",
      "{'idx': 1, 'size': 15, 'order': 2, 'chi': 1024.0}\n",
      "{'idx': 2, 'size': 20, 'order': 6, 'chi': 16.0}\n",
      "{'idx': 3, 'size': 20, 'order': 3, 'chi': 256.0}\n",
      "{'idx': 4, 'size': 12, 'order': 5, 'chi': 16.0}\n",
      "{'idx': 5, 'size': 15, 'order': 2, 'chi': 4096.0}\n",
      "{'idx': 6, 'size': 12, 'order': 10, 'chi': 4.0}\n",
      "{'idx': 7, 'size': 12, 'order': 5, 'chi': 16.0}\n",
      "{'idx': 8, 'size': 1, 'order': 2, 'chi': 1024.0}\n",
      "{'idx': 9, 'size': 1, 'order': 1, 'chi': 1048576.0}\n",
      "\n",
      "By (size, order):\n",
      "  (12, 10): indices [0, 6]\n",
      "  (15, 2): indices [1, 5]\n",
      "  (20, 6): indices [2]\n",
      "  (20, 3): indices [3]\n",
      "  (12, 5): indices [4, 7]\n",
      "  (1, 2): indices [8]\n",
      "  (1, 1): indices [9]\n",
      "\n",
      "Automatic identification:\n",
      " E:   9\n",
      " i:   8\n",
      " C5:  [4, 7]\n",
      " S10: [0, 6]\n",
      " C3:  3\n",
      " S6:  2\n",
      " 15-classes (C2, Ïƒ) candidates: [1, 5]\n",
      "\n",
      "Distinguishing C2 vs Ïƒ by trace:\n",
      "  Class 1: Ï‡_red = 1024.0\n",
      "  Class 5: Ï‡_red = 4096.0\n",
      "  â†’ Class 5 is Ïƒ (trace=4096, 8 cycles)\n",
      "  â†’ Class 1 is C2 (trace=1024, 6 cycles)\n",
      "\n",
      "12C5 classes (same trace, check consistency):\n",
      "  Class 4: Ï‡_red = 16.0\n",
      "  Class 7: Ï‡_red = 16.0\n",
      "\n",
      "12S10 classes (same trace, check consistency):\n",
      "  Class 0: Ï‡_red = 4.0\n",
      "  Class 6: Ï‡_red = 4.0\n",
      "\n",
      "============================================================\n",
      "Trying assignment:\n",
      "  C2 -> class 1 (trace=1024.0)\n",
      "  Ïƒ  -> class 5 (trace=4096.0)\n",
      "  12C5 -> class 4\n",
      "  12C5Â² -> class 7\n",
      "  12S10 -> class 0\n",
      "  12(S10)Â³ -> class 6\n",
      "Class sizes: [ 1 12 12 20 15  1 12 12 20 15]\n",
      "chi_red: [1.048576e+06 1.600000e+01 1.600000e+01 2.560000e+02 1.024000e+03\n",
      " 1.024000e+03 4.000000e+00 4.000000e+00 1.600000e+01 4.096000e+03]\n",
      "Raw multiplicities: [ 9436. 25602. 25602. 35028. 44328.  8388. 26574. 26574. 34956. 43224.]\n",
      "Rounded multiplicities: [ 9436 25602 25602 35028 44328  8388 26574 26574 34956 43224]\n",
      "Max deviation from integer: 0.0\n",
      "âˆ‘ n_Î“ d_Î“ = 1048576 (expect 2^N = 1048576 )\n",
      "=> This assignment is CONSISTENT âœ“\n",
      "\n",
      "============================================================\n",
      "Trying assignment:\n",
      "  C2 -> class 1 (trace=1024.0)\n",
      "  Ïƒ  -> class 5 (trace=4096.0)\n",
      "  12C5 -> class 4\n",
      "  12C5Â² -> class 7\n",
      "  12S10 -> class 6\n",
      "  12(S10)Â³ -> class 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0. Dodecahedron bonds (current labelling)\n",
    "# ============================================================\n",
    "\n",
    "bonds = [(0, 13), (0, 14), (0, 15), (1, 4), (1, 5), (1, 12),\n",
    "    (2, 6), (2, 13), (2, 18), (3, 7), (3, 14), (3, 19),\n",
    "    (4, 10), (4, 18), (5, 11), (5, 19), (6, 10), (6, 15),\n",
    "    (7, 11), (7, 15), (8, 9), (8, 13), (8, 16), (9, 14), (9, 17),\n",
    "    (10, 11), (12, 16), (12, 17), (16, 18), (17, 19)]\n",
    "\n",
    "bonds_set = {tuple(sorted(e)) for e in bonds}\n",
    "print(\"Number of bonds:\", len(bonds_set))\n",
    "\n",
    "# ============================================================\n",
    "# 1. Load Ih permutations from file\n",
    "# ============================================================\n",
    "\n",
    "def load_ih_permutations(path=\"ih_dodeca_permutations_0based.txt\"):\n",
    "    \"\"\"\n",
    "    Each line in ih_dodeca_permutations_0based.txt represents a permutation on vertices 0..19.\n",
    "    \"\"\"\n",
    "    perms = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            nums = line.strip('[]').split(',')\n",
    "            perms.append(np.array([int(x) for x in nums], dtype=int))\n",
    "    return perms\n",
    "\n",
    "perms = load_ih_permutations(\"ih_dodeca_permutations_0based.txt\")\n",
    "N_sites = len(perms[0])\n",
    "print(f\"Loaded {len(perms)} I_h permutations on {N_sites} sites.\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Graph automorphism checker (sanity)\n",
    "# ============================================================\n",
    "\n",
    "def is_automorphism(perm, bonds_set):\n",
    "    \"\"\"\n",
    "    Check if 'perm' is a graph automorphism of the dodecahedron\n",
    "    defined by bonds_set, i.e. maps edges to edges.\n",
    "    \"\"\"\n",
    "    for i, j in bonds_set:\n",
    "        ii, jj = perm[i], perm[j]\n",
    "        if tuple(sorted((ii, jj))) not in bonds_set:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "num_auto = sum(is_automorphism(p, bonds_set) for p in perms)\n",
    "print(\"Number of automorphisms wrt your bonds:\", num_auto)\n",
    "\n",
    "# ============================================================\n",
    "# 3. Permutation utilities & conjugacy classes of I_h\n",
    "# ============================================================\n",
    "\n",
    "def perm_compose(p, q):\n",
    "    \"\"\"\n",
    "    Composition p âˆ˜ q acting on indices [0..N-1]:\n",
    "    result r satisfies r[i] = p[q[i]].\n",
    "    \"\"\"\n",
    "    return p[q]\n",
    "\n",
    "def perm_inverse(p):\n",
    "    \"\"\"Inverse permutation p^{-1}.\"\"\"\n",
    "    inv = np.empty_like(p)\n",
    "    inv[p] = np.arange(len(p))\n",
    "    return inv\n",
    "\n",
    "def perm_order(p, max_iter=300):\n",
    "    \"\"\"Order of permutation p: smallest k>0 with p^k = identity.\"\"\"\n",
    "    n = len(p)\n",
    "    e = np.arange(n)\n",
    "    x = p.copy()\n",
    "    k = 1\n",
    "    while not np.array_equal(x, e):\n",
    "        x = perm_compose(x, p)\n",
    "        k += 1\n",
    "        if k > max_iter:\n",
    "            raise RuntimeError(\"Permutation order too large?\")\n",
    "    return k\n",
    "\n",
    "def compute_conjugacy_classes(perms):\n",
    "    \"\"\"\n",
    "    Compute conjugacy classes of the group represented by 'perms'\n",
    "    via g -> h g h^{-1}.\n",
    "    \"\"\"\n",
    "    perms_tuples = [tuple(p.tolist()) for p in perms]\n",
    "    perm_dict = {pt: p for pt, p in zip(perms_tuples, perms)}\n",
    "\n",
    "    unseen = set(perms_tuples)\n",
    "    classes = []\n",
    "\n",
    "    while unseen:\n",
    "        rep_t = unseen.pop()\n",
    "        rep = perm_dict[rep_t]\n",
    "        current = set()\n",
    "\n",
    "        for h_t, h in perm_dict.items():\n",
    "            h_inv = perm_inverse(h)\n",
    "            conj = perm_compose(h, perm_compose(rep, h_inv))\n",
    "            conj_t = tuple(conj.tolist())\n",
    "            if conj_t in perm_dict:\n",
    "                current.add(conj_t)\n",
    "\n",
    "        for ct in current:\n",
    "            unseen.discard(ct)\n",
    "\n",
    "        class_perms = [perm_dict[ct] for ct in current]\n",
    "        classes.append(class_perms)\n",
    "\n",
    "    return classes\n",
    "\n",
    "classes = compute_conjugacy_classes(perms)\n",
    "print(f\"Found {len(classes)} conjugacy classes in new labelling.\")\n",
    "for i, cls in enumerate(classes):\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    print(f\"class {i}: size={size:2d}, order={order:2d}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Build Hilbert-space operator U_g for a permutation g\n",
    "#    (big-endian convention, site 0 = most significant bit)\n",
    "# ============================================================\n",
    "\n",
    "def build_symmetry_operator(N_spins, perm):\n",
    "    \"\"\"\n",
    "    U |s_0 ... s_{N-1}> = |s_{perm(0)} ... s_{perm(N-1)}|\n",
    "    with site 0 as the left-most tensor factor (MSB).\n",
    "    \"\"\"\n",
    "    D = 1 << N_spins\n",
    "    rows = np.empty(D, dtype=np.int64)\n",
    "    cols = np.arange(D, dtype=np.int64)\n",
    "\n",
    "    for b in range(D):\n",
    "        # decode: big-endian, site 0 = most significant bit\n",
    "        bits = [(b >> (N_spins - 1 - i)) & 1 for i in range(N_spins)]\n",
    "\n",
    "        # permute sites\n",
    "        permuted_bits = [bits[perm[i]] for i in range(N_spins)]\n",
    "\n",
    "        # re-encode in the same big-endian convention\n",
    "        b_prime = 0\n",
    "        for i in range(N_spins):\n",
    "            b_prime |= permuted_bits[i] << (N_spins - 1 - i)\n",
    "\n",
    "        rows[b] = b_prime\n",
    "\n",
    "    data = np.ones(D, dtype=np.int8)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(D, D))\n",
    "\n",
    "def check_Ug(N_spins, Ug):\n",
    "    \"\"\"\n",
    "    Sanity checks: shape, permutation structure, and unitarity Ugâ€  Ug = I.\n",
    "    \"\"\"\n",
    "    dim = 1 << N_spins\n",
    "\n",
    "    # 1. Size\n",
    "    assert Ug.shape == (dim, dim), f\"Ug has wrong shape: {Ug.shape}\"\n",
    "\n",
    "    # 2. Permutation structure: exactly one nonzero per row and column\n",
    "    nnz_per_row = Ug.getnnz(axis=1)\n",
    "    nnz_per_col = Ug.getnnz(axis=0)\n",
    "    assert np.all(nnz_per_row == 1), \"Some rows do not have exactly one '1'\"\n",
    "    assert np.all(nnz_per_col == 1), \"Some columns do not have exactly one '1'\"\n",
    "\n",
    "    # 3. Unitarity: Ugâ€  Ug = I\n",
    "    Id = eye(dim, dtype=np.complex128, format='csr')\n",
    "    diff = (Ug.conj().T @ Ug) - Id\n",
    "    print(\"Number of nonzeros in Ugâ€ Ug - I:\", diff.nnz)\n",
    "    if diff.nnz != 0:\n",
    "        raise ValueError(\"Ug is not unitary: Ugâ€ Ug - I has nonzero entries\")\n",
    "\n",
    "    print(\"All tests passed for this Ug.\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. Build all Ugs, check a few, and collect traces\n",
    "# ============================================================\n",
    "\n",
    "N_spins = N_sites  # 12 for icosahedron\n",
    "dim = 1 << N_spins\n",
    "\n",
    "Ugs = [build_symmetry_operator(N_spins, perm) for perm in perms]\n",
    "\n",
    "traces = []\n",
    "print(\"\\nChecking a few U_g for unitarity and permutation structure...\")\n",
    "for i, Ug in enumerate(Ugs):\n",
    "    if i < 3:\n",
    "        check_Ug(N_spins, Ug)\n",
    "    tr = Ug.diagonal().sum()\n",
    "    traces.append(int(round(float(np.real(tr)))))\n",
    "\n",
    "unique_traces = sorted(set(traces))\n",
    "print(f\"\\nNumber of distinct trace values: {len(unique_traces)}\")\n",
    "print(f\"Distinct values: {unique_traces}\")\n",
    "\n",
    "counts = Counter(traces)\n",
    "print(\"Counts per trace:\")\n",
    "for val in unique_traces:\n",
    "    print(f\"  trace={val}: {counts[val]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. Build class operators C_k = sum_{g in class_k} U_g\n",
    "# ============================================================\n",
    "\n",
    "def build_class_operators(N_spins, classes):\n",
    "    \"\"\"\n",
    "    Build class operators C_k = sum_{g in class_k} U_g.\n",
    "    Returns a list of sparse CSR matrices.\n",
    "    \"\"\"\n",
    "    class_ops = []\n",
    "    for class_perms in classes:\n",
    "        U_sum = None\n",
    "        for perm in class_perms:\n",
    "            U_g = build_symmetry_operator(N_spins, perm)\n",
    "            if U_sum is None:\n",
    "                U_sum = U_g.astype(np.complex128, copy=True).tocsr()\n",
    "            else:\n",
    "                U_sum = U_sum + U_g.tocsr()\n",
    "        class_ops.append(U_sum.tocsr())\n",
    "    return class_ops\n",
    "\n",
    "# ============================================================\n",
    "# 7. Optional: commutator norm checks with H, Hi, Htf\n",
    "# ============================================================\n",
    "\n",
    "def comm_norm(A, B):\n",
    "    \"\"\"Sparse Frobenius norm of commutator [A,B].\"\"\"\n",
    "    C = A @ B - B @ A\n",
    "    return np.sqrt((C.multiply(C.conj())).sum())\n",
    "\n",
    "# ============================================================\n",
    "# 8. Compute class data: size, order, Ï‡_red for each conjugacy class\n",
    "# ============================================================\n",
    "\n",
    "def trace_from_perm(perm):\n",
    "    Ug = build_symmetry_operator(N_spins, perm)\n",
    "    return float(Ug.diagonal().sum())\n",
    "\n",
    "class_data = []\n",
    "for idx, cls in enumerate(classes):\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    chi = trace_from_perm(cls[0])\n",
    "    class_data.append({\n",
    "        \"idx\": idx,\n",
    "        \"size\": size,\n",
    "        \"order\": order,\n",
    "        \"chi\": chi,\n",
    "    })\n",
    "\n",
    "print(\"\\nRaw class summary (index, size, order, chi):\")\n",
    "for cd in class_data:\n",
    "    print(cd)\n",
    "\n",
    "def find_by(size=None, order=None):\n",
    "    return [cd[\"idx\"] for cd in class_data\n",
    "            if (size is None or cd[\"size\"] == size)\n",
    "            and (order is None or cd[\"order\"] == order)]\n",
    "\n",
    "print(\"\\nBy (size, order):\")\n",
    "sizes_orders = {}\n",
    "for cd in class_data:\n",
    "    key = (cd[\"size\"], cd[\"order\"])\n",
    "    sizes_orders.setdefault(key, []).append(cd[\"idx\"])\n",
    "for k, v in sizes_orders.items():\n",
    "    print(f\"  {k}: indices {v}\")\n",
    "\n",
    "# ============================================================\n",
    "# 9. Automatically build Ih standard order from class_data\n",
    "#    Standard order: (E, 12C5, 12C5^2, 20C3, 15C2, i, 12S10, 12(S10)^3, 20S6, 15Ïƒ)\n",
    "# ============================================================\n",
    "\n",
    "idx_E_list   = find_by(size=1,  order=1)\n",
    "idx_i_list   = find_by(size=1,  order=2)\n",
    "idx_C5_list  = find_by(size=12, order=5)\n",
    "idx_S10_list = find_by(size=12, order=10)\n",
    "idx_C3_list  = find_by(size=20, order=3)\n",
    "idx_S6_list  = find_by(size=20, order=6)\n",
    "idx_15_list  = find_by(size=15, order=2)\n",
    "\n",
    "assert len(idx_E_list)   == 1, \"Expected 1 identity class\"\n",
    "assert len(idx_i_list)   == 1, \"Expected 1 inversion class\"\n",
    "assert len(idx_C5_list)  == 2, \"Expected two 5-fold rotation classes\"\n",
    "assert len(idx_S10_list) == 2, \"Expected two S10 classes\"\n",
    "assert len(idx_C3_list)  == 1, \"Expected one 20C3 class\"\n",
    "assert len(idx_S6_list)  == 1, \"Expected one 20S6 class\"\n",
    "assert len(idx_15_list)  == 2, \"Expected two 15-element classes\"\n",
    "\n",
    "idx_E  = idx_E_list[0]\n",
    "idx_i  = idx_i_list[0]\n",
    "idx_C3 = idx_C3_list[0]\n",
    "idx_S6 = idx_S6_list[0]\n",
    "idx_C5_a, idx_C5_b     = idx_C5_list\n",
    "idx_S10_a, idx_S10_b   = idx_S10_list\n",
    "idx_15_a, idx_15_b     = idx_15_list\n",
    "\n",
    "print(\"\\nAutomatic identification:\")\n",
    "print(\" E:  \", idx_E)\n",
    "print(\" i:  \", idx_i)\n",
    "print(\" C5: \", idx_C5_list)\n",
    "print(\" S10:\", idx_S10_list)\n",
    "print(\" C3: \", idx_C3)\n",
    "print(\" S6: \", idx_S6)\n",
    "print(\" 15-classes (C2, Ïƒ) candidates:\", idx_15_list)\n",
    "\n",
    "# ============================================================\n",
    "# 10. Character table of Ih (in standard column order)\n",
    "# ============================================================\n",
    "\n",
    "w  = 2.0 * np.pi / 5.0\n",
    "c2 = np.cos(2*w)   # cos(4Ï€/5)\n",
    "c1 = np.cos(1*w)   # cos(2Ï€/5)\n",
    "\n",
    "chi_irreps = np.array([\n",
    "    # E,   12C5,     12C5^2,   20C3,  15C2,  i,    12S10,    12(S10)^3, 20S6,  15Ïƒ\n",
    "    [1,    1,        1,        1,     1,     1,    1,        1,        1,     1],       # Ag\n",
    "    [3,   -2*c2,    -2*c1,     0,    -1,     3,   -2*c1,    -2*c2,     0,    -1],       # T1g\n",
    "    [3,   -2*c1,    -2*c2,     0,    -1,     3,   -2*c2,    -2*c1,     0,    -1],       # T2g\n",
    "    [4,   -1,       -1,        1,     0,     4,   -1,       -1,        1,     0],       # Gg\n",
    "    [5,    0,        0,       -1,     1,     5,    0,        0,       -1,     1],       # Hg\n",
    "    [1,    1,        1,        1,     1,    -1,   -1,       -1,       -1,    -1],       # Au\n",
    "    [3,   -2*c2,    -2*c1,     0,    -1,    -3,    2*c1,     2*c2,     0,     1],       # T1u\n",
    "    [3,   -2*c1,    -2*c2,     0,    -1,    -3,    2*c2,     2*c1,     0,     1],       # T2u\n",
    "    [4,   -1,       -1,        1,     0,    -4,    1,        1,       -1,     0],       # Gu\n",
    "    [5,    0,        0,       -1,     1,    -5,    0,        0,        1,    -1],       # Hu\n",
    "], dtype=float)\n",
    "\n",
    "irrep_labels = [\"Ag\", \"T1g\", \"T2g\", \"Gg\", \"Hg\",\n",
    "                \"Au\", \"T1u\", \"T2u\", \"Gu\", \"Hu\"]\n",
    "\n",
    "G_order = 120\n",
    "\n",
    "# ============================================================\n",
    "# 11. Distinguish C2 vs Ïƒ by trace, then try all combinations\n",
    "#     for C5/C5Â² and S10/(S10)Â³\n",
    "# ============================================================\n",
    "\n",
    "# Distinguish C2 vs Ïƒ by trace:\n",
    "# - Ïƒ (reflection) has 8 cycles â†’ trace = 2^12 = 4096\n",
    "# - C2 (rotation) has 6 cycles â†’ trace = 2^10 = 1024\n",
    "\n",
    "chi_15_a = trace_from_perm(classes[idx_15_a][0])\n",
    "chi_15_b = trace_from_perm(classes[idx_15_b][0])\n",
    "\n",
    "print(f\"\\nDistinguishing C2 vs Ïƒ by trace:\")\n",
    "print(f\"  Class {idx_15_a}: Ï‡_red = {chi_15_a}\")\n",
    "print(f\"  Class {idx_15_b}: Ï‡_red = {chi_15_b}\")\n",
    "\n",
    "if abs(chi_15_a - 4096) < 1e-6:\n",
    "    idx_sigma = idx_15_a\n",
    "    idx_C2 = idx_15_b\n",
    "    print(f\"  â†’ Class {idx_15_a} is Ïƒ (trace=4096, 8 cycles)\")\n",
    "    print(f\"  â†’ Class {idx_15_b} is C2 (trace=1024, 6 cycles)\")\n",
    "elif abs(chi_15_b - 4096) < 1e-6:\n",
    "    idx_sigma = idx_15_b\n",
    "    idx_C2 = idx_15_a\n",
    "    print(f\"  â†’ Class {idx_15_b} is Ïƒ (trace=4096, 8 cycles)\")\n",
    "    print(f\"  â†’ Class {idx_15_a} is C2 (trace=1024, 6 cycles)\")\n",
    "else:\n",
    "    raise ValueError(\"Cannot identify Ïƒ by trace=4096\")\n",
    "\n",
    "# C5/C5Â² and S10/(S10)Â³ have same trace, so check consistency\n",
    "chi_C5_a = trace_from_perm(classes[idx_C5_a][0])\n",
    "chi_C5_b = trace_from_perm(classes[idx_C5_b][0])\n",
    "print(f\"\\n12C5 classes (same trace, check consistency):\")\n",
    "print(f\"  Class {idx_C5_a}: Ï‡_red = {chi_C5_a}\")\n",
    "print(f\"  Class {idx_C5_b}: Ï‡_red = {chi_C5_b}\")\n",
    "\n",
    "chi_S10_a = trace_from_perm(classes[idx_S10_a][0])\n",
    "chi_S10_b = trace_from_perm(classes[idx_S10_b][0])\n",
    "print(f\"\\n12S10 classes (same trace, check consistency):\")\n",
    "print(f\"  Class {idx_S10_a}: Ï‡_red = {chi_S10_a}\")\n",
    "print(f\"  Class {idx_S10_b}: Ï‡_red = {chi_S10_b}\")\n",
    "\n",
    "def compute_multiplicities(class_sizes, chi_red):\n",
    "    \"\"\"Compute irrep multiplicities using character orthogonality.\"\"\"\n",
    "    multiplicities = []\n",
    "    for i in range(len(irrep_labels)):\n",
    "        chi_Gamma = chi_irreps[i]\n",
    "        n_Gamma = (class_sizes * chi_red * chi_Gamma).sum() / G_order\n",
    "        multiplicities.append(n_Gamma)\n",
    "    return np.array(multiplicities, dtype=float)\n",
    "\n",
    "# Try all possible assignments for C5/C5Â² and S10/(S10)Â³\n",
    "solutions = []\n",
    "\n",
    "for (idx_C5_1, idx_C5_2) in [(idx_C5_a, idx_C5_b), (idx_C5_b, idx_C5_a)]:\n",
    "    for (idx_S10_1, idx_S10_2) in [(idx_S10_a, idx_S10_b), (idx_S10_b, idx_S10_a)]:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Trying assignment:\")\n",
    "        print(f\"  C2 -> class {idx_C2} (trace={chi_15_a if idx_C2==idx_15_a else chi_15_b})\")\n",
    "        print(f\"  Ïƒ  -> class {idx_sigma} (trace={chi_15_a if idx_sigma==idx_15_a else chi_15_b})\")\n",
    "        print(f\"  12C5 -> class {idx_C5_1}\")\n",
    "        print(f\"  12C5Â² -> class {idx_C5_2}\")\n",
    "        print(f\"  12S10 -> class {idx_S10_1}\")\n",
    "        print(f\"  12(S10)Â³ -> class {idx_S10_2}\")\n",
    "        \n",
    "        ordered_indices = [\n",
    "            idx_E,\n",
    "            idx_C5_1,\n",
    "            idx_C5_2,\n",
    "            idx_C3,\n",
    "            idx_C2,\n",
    "            idx_i,\n",
    "            idx_S10_1,\n",
    "            idx_S10_2,\n",
    "            idx_S6,\n",
    "            idx_sigma,\n",
    "        ]\n",
    "        \n",
    "        class_sizes = np.zeros(10, dtype=int)\n",
    "        chi_red = np.zeros(10, dtype=float)\n",
    "        for k, class_idx in enumerate(ordered_indices):\n",
    "            cls = classes[class_idx]\n",
    "            class_sizes[k] = len(cls)\n",
    "            rep_perm = cls[0]\n",
    "            chi_red[k] = trace_from_perm(rep_perm)\n",
    "        \n",
    "        print(\"Class sizes:\", class_sizes)\n",
    "        print(\"chi_red:\", chi_red)\n",
    "\n",
    "        mult = compute_multiplicities(class_sizes, chi_red)\n",
    "        mult_rounded = np.round(mult).astype(int)\n",
    "        max_dev = np.max(np.abs(mult - mult_rounded))\n",
    "        \n",
    "        print(\"Raw multiplicities:\", mult)\n",
    "        print(\"Rounded multiplicities:\", mult_rounded)\n",
    "        print(\"Max deviation from integer:\", max_dev)\n",
    "\n",
    "        dims_irreps = np.array([1, 3, 3, 4, 5, 1, 3, 3, 4, 5], dtype=int)\n",
    "        dim_check = (mult_rounded * dims_irreps).sum()\n",
    "        print(\"âˆ‘ n_Î“ d_Î“ =\", dim_check, \"(expect 2^N =\", 1 << N_spins, \")\")\n",
    "\n",
    "        ok = (max_dev < 1e-6) and (dim_check == (1 << N_spins)) and np.all(mult_rounded >= 0)\n",
    "        if ok:\n",
    "            print(\"=> This assignment is CONSISTENT âœ“\")\n",
    "            solutions.append({\n",
    "                \"idx_C2\": idx_C2,\n",
    "                \"idx_sigma\": idx_sigma,\n",
    "                \"idx_C5_1\": idx_C5_1,\n",
    "                \"idx_C5_2\": idx_C5_2,\n",
    "                \"idx_S10_1\": idx_S10_1,\n",
    "                \"idx_S10_2\": idx_S10_2,\n",
    "                \"ordered_indices\": ordered_indices,\n",
    "                \"class_sizes\": class_sizes,\n",
    "                \"chi_red\": chi_red,\n",
    "                \"multiplicities\": mult_rounded,\n",
    "            })\n",
    "        else:\n",
    "            print(\"=> This assignment is NOT consistent âœ—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "244f6f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 consistent assignment(s)\n",
      "\n",
      "=== Final assignment (C2/Ïƒ by trace, C5/S10 by consistency) ===\n",
      "C2  class index: 1\n",
      "sigma class index: 5\n",
      "12C5 class index: 7\n",
      "12C5Â² class index: 4\n",
      "12S10 class index: 0\n",
      "12(S10)Â³ class index: 6\n",
      "Class sizes (Ih order): [ 1 12 12 20 15  1 12 12 20 15]\n",
      "chi_red (Ih order): [1.048576e+06 1.600000e+01 1.600000e+01 2.560000e+02 1.024000e+03\n",
      " 1.024000e+03 4.000000e+00 4.000000e+00 1.600000e+01 4.096000e+03]\n",
      "\n",
      "Irrep multiplicities:\n",
      "  Ag: n = 9436\n",
      "  T1g: n = 25602\n",
      "  T2g: n = 25602\n",
      "  Gg: n = 35028\n",
      "  Hg: n = 44328\n",
      "  Au: n = 8388\n",
      "  T1u: n = 26574\n",
      "  T2u: n = 26574\n",
      "  Gu: n = 34956\n",
      "  Hu: n = 43224\n",
      "\n",
      "Check âˆ‘ n_Î“ d_Î“ = 1048576   (should be 2^N = 1048576 )\n",
      "\n",
      "=== Full Ih character table (Ï‡_Î“(C)) in our ordering ===\n",
      "irrep \\ class          E       12C5     12C5^2       20C3       15C2          i      12S10  12(S10)^3       20S6        15Ïƒ\n",
      "---------------------------------------------------------------------------------------------------------------------------\n",
      "Ag             1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000     1.0000\n",
      "T1g            3.0000     1.6180    -0.6180     0.0000    -1.0000     3.0000    -0.6180     1.6180     0.0000    -1.0000\n",
      "T2g            3.0000    -0.6180     1.6180     0.0000    -1.0000     3.0000     1.6180    -0.6180     0.0000    -1.0000\n",
      "Gg             4.0000    -1.0000    -1.0000     1.0000     0.0000     4.0000    -1.0000    -1.0000     1.0000     0.0000\n",
      "Hg             5.0000     0.0000     0.0000    -1.0000     1.0000     5.0000     0.0000     0.0000    -1.0000     1.0000\n",
      "Au             1.0000     1.0000     1.0000     1.0000     1.0000    -1.0000    -1.0000    -1.0000    -1.0000    -1.0000\n",
      "T1u            3.0000     1.6180    -0.6180     0.0000    -1.0000    -3.0000     0.6180    -1.6180     0.0000     1.0000\n",
      "T2u            3.0000    -0.6180     1.6180     0.0000    -1.0000    -3.0000    -1.6180     0.6180     0.0000     1.0000\n",
      "Gu             4.0000    -1.0000    -1.0000     1.0000     0.0000    -4.0000     1.0000     1.0000    -1.0000     0.0000\n",
      "Hu             5.0000     0.0000     0.0000    -1.0000     1.0000    -5.0000     0.0000     0.0000     1.0000    -1.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(solutions)} consistent assignment(s)\")\n",
    "\n",
    "if not solutions:\n",
    "    raise RuntimeError(\"No consistent assignment found.\")\n",
    "else:\n",
    "    sol = solutions[2]  # or solutions[1], solutions[2], solutions[3] if solutions[0] fails later\n",
    "\n",
    "    print(\"\\n=== Final assignment (C2/Ïƒ by trace, C5/S10 by consistency) ===\")\n",
    "    print(f\"C2  class index: {sol['idx_C2']}\")\n",
    "    print(f\"sigma class index: {sol['idx_sigma']}\")\n",
    "    print(f\"12C5 class index: {sol['idx_C5_1']}\")\n",
    "    print(f\"12C5Â² class index: {sol['idx_C5_2']}\")\n",
    "    print(f\"12S10 class index: {sol['idx_S10_1']}\")\n",
    "    print(f\"12(S10)Â³ class index: {sol['idx_S10_2']}\")\n",
    "    print(\"Class sizes (Ih order):\", sol[\"class_sizes\"])\n",
    "    print(\"chi_red (Ih order):\", sol[\"chi_red\"])\n",
    "    print(\"\\nIrrep multiplicities:\")\n",
    "    for label, n in zip(irrep_labels, sol[\"multiplicities\"]):\n",
    "        print(f\"  {label}: n = {n}\")\n",
    "\n",
    "    dims_irreps = np.array([1, 3, 3, 4, 5, 1, 3, 3, 4, 5], dtype=int)\n",
    "    print(\"\\nCheck âˆ‘ n_Î“ d_Î“ =\",\n",
    "          (sol[\"multiplicities\"] * dims_irreps).sum(),\n",
    "          \"  (should be 2^N =\", 1 << N_spins, \")\")\n",
    "\n",
    "# ============================================================\n",
    "# 12. Character table in our ordering\n",
    "# ============================================================\n",
    "\n",
    "class_labels = [\n",
    "    \"E\", \"12C5\", \"12C5^2\", \"20C3\", \"15C2\",\n",
    "    \"i\", \"12S10\", \"12(S10)^3\", \"20S6\", \"15Ïƒ\",\n",
    "]\n",
    "\n",
    "print(\"\\n=== Full Ih character table (Ï‡_Î“(C)) in our ordering ===\")\n",
    "header = \"irrep \\\\ class\".ljust(10) + \"  \" + \"  \".join(f\"{c:>9}\" for c in class_labels)\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "for i, label in enumerate(irrep_labels):\n",
    "    row = [label.ljust(10)]\n",
    "    for j in range(10):\n",
    "        row.append(f\"{chi_irreps[i, j]:9.4f}\")\n",
    "    print(\"  \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f07cca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 7, 4, 3, 1, 8, 0, 6, 2, 5]\n",
      "Ih conjugacy classes (final assignment):\n",
      "E            size= 1  order= 1  chi=1048576 (2^20)\n",
      "12C5         size=12  order= 5  chi=16 (2^4)\n",
      "12C5^2       size=12  order= 5  chi=16 (2^4)\n",
      "20C3         size=20  order= 3  chi=256 (2^8)\n",
      "15C2         size=15  order= 2  chi=1024 (2^10)\n",
      "i            size= 1  order= 2  chi=1024 (2^10)\n",
      "12S10        size=12  order=10  chi=4 (2^2)\n",
      "12(S10)^3    size=12  order=10  chi=4 (2^2)\n",
      "20S6         size=20  order= 6  chi=16 (2^4)\n",
      "15Ïƒ          size=15  order= 2  chi=4096 (2^12)\n"
     ]
    }
   ],
   "source": [
    "# Reprint Ih conjugacy classes using the final assignment from `sol` (no raw indices)\n",
    "\n",
    "if 'sol' not in globals():\n",
    "    raise RuntimeError(\"Missing `sol` (run the previous assignment cell first).\")\n",
    "if 'classes' not in globals() or 'perm_order' not in globals() or 'trace_from_perm' not in globals():\n",
    "    raise RuntimeError(\"Missing prerequisites (`classes`, `perm_order`, `trace_from_perm`).\")\n",
    "\n",
    "# Canonical Ih column order (must match how `sol['ordered_indices']` was built)\n",
    "if 'class_labels_Ih' not in globals():\n",
    "    class_labels_Ih = [\"E\",\"12C5\",\"12C5^2\",\"20C3\",\"15C2\",\"i\",\"12S10\",\"12(S10)^3\",\"20S6\",\"15Ïƒ\"]\n",
    "\n",
    "ordered_indices = sol[\"ordered_indices\"]\n",
    "print(ordered_indices)\n",
    "\n",
    "canonical_classes = []\n",
    "for lbl, raw_idx in zip(class_labels_Ih, ordered_indices):\n",
    "    cls = classes[raw_idx]\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    chi = int(round(float(trace_from_perm(cls[0]))))\n",
    "    canonical_classes.append({\"label\": lbl, \"size\": size, \"order\": order, \"chi\": chi})\n",
    "\n",
    "print(\"Ih conjugacy classes (final assignment):\")\n",
    "for c in canonical_classes:\n",
    "    # pretty power-of-two print if applicable\n",
    "    exp = None\n",
    "    if c[\"chi\"] > 0:\n",
    "        from math import log2\n",
    "        e = log2(c[\"chi\"])\n",
    "        if abs(e - round(e)) < 1e-12:\n",
    "            exp = int(round(e))\n",
    "    if exp is not None:\n",
    "        print(f\"{c['label']:12s} size={c['size']:2d}  order={c['order']:2d}  chi={c['chi']} (2^{exp})\")\n",
    "    else:\n",
    "        print(f\"{c['label']:12s} size={c['size']:2d}  order={c['order']:2d}  chi={c['chi']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7583a904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H Frobenius norm (sparse): 1.483917e+04\n",
      "Checked 120 U_g operators\n",
      "Number with relative commutator > 1.000000e-10: 0\n",
      "\n",
      "Top offenders (index, ||[H,Ug]||_F, relative):\n",
      "     0  0.000000e+00  rel=0.000e+00\n",
      "     1  0.000000e+00  rel=0.000e+00\n",
      "     2  0.000000e+00  rel=0.000e+00\n",
      "     3  0.000000e+00  rel=0.000e+00\n",
      "     4  0.000000e+00  rel=0.000e+00\n",
      "     5  0.000000e+00  rel=0.000e+00\n",
      "     6  0.000000e+00  rel=0.000e+00\n",
      "     7  0.000000e+00  rel=0.000e+00\n",
      "     8  0.000000e+00  rel=0.000e+00\n",
      "     9  0.000000e+00  rel=0.000e+00\n",
      "    10  0.000000e+00  rel=0.000e+00\n",
      "    11  0.000000e+00  rel=0.000e+00\n",
      "    12  0.000000e+00  rel=0.000e+00\n",
      "    13  0.000000e+00  rel=0.000e+00\n",
      "    14  0.000000e+00  rel=0.000e+00\n",
      "    15  0.000000e+00  rel=0.000e+00\n",
      "    16  0.000000e+00  rel=0.000e+00\n",
      "    17  0.000000e+00  rel=0.000e+00\n",
      "    18  0.000000e+00  rel=0.000e+00\n",
      "    19  0.000000e+00  rel=0.000e+00\n",
      "\n",
      "All U_g commute with H within tolerance.\n"
     ]
    }
   ],
   "source": [
    "# Sparse-only check: verify [H, U_g] = 0 for all Ugs\n",
    "tol_rel = 1e-10  # relative tolerance\n",
    "if not issparse(H):\n",
    "    raise RuntimeError(\"H must be sparse for the sparse-only check\")\n",
    "\n",
    "# Frobenius norm of H (sparse)\n",
    "H_norm = float(np.sqrt(np.real((H.multiply(H.conj())).sum())))\n",
    "if H_norm == 0:\n",
    "    H_norm = 1.0\n",
    "\n",
    "bad = []\n",
    "rel_values = []\n",
    "for i, Ug in enumerate(Ugs):\n",
    "    # sparse commutator\n",
    "    C = H @ Ug - Ug @ H\n",
    "    # Frobenius norm via sparse elementwise multiply and sum\n",
    "    s = (C.multiply(C.conj())).sum()\n",
    "    nrm = float(np.sqrt(np.real(s)))\n",
    "    rel = nrm / H_norm\n",
    "    rel_values.append((i, nrm, rel))\n",
    "    if rel > tol_rel:\n",
    "        bad.append((i, nrm, rel))\n",
    "\n",
    "# summary\n",
    "rel_values_sorted = sorted(rel_values, key=lambda x: x[2], reverse=True)\n",
    "print(f\"H Frobenius norm (sparse): {H_norm:.6e}\")\n",
    "print(f\"Checked {len(Ugs)} U_g operators\")\n",
    "print(f\"Number with relative commutator > {tol_rel:e}: {len(bad)}\")\n",
    "\n",
    "# show top offenders (up to 20)\n",
    "print(\"\\nTop offenders (index, ||[H,Ug]||_F, relative):\")\n",
    "for idx, nrm, rel in rel_values_sorted[:20]:\n",
    "    tag = \"!!\" if rel > tol_rel else \"  \"\n",
    "    print(f\"{tag} {idx:3d}  {nrm:12.6e}  rel={rel:.3e}\")\n",
    "\n",
    "# if any noncommuting found, raise or print details\n",
    "if bad:\n",
    "    print(\"\\nNon-commuting U_g indices (rel > tol):\")\n",
    "    for i, nrm, rel in sorted(bad, key=lambda x: x[2], reverse=True):\n",
    "        print(f\"  index={i:3d}, ||[H,Ug]||_F = {nrm:.6e}, rel = {rel:.3e}\")\n",
    "else:\n",
    "    print(\"\\nAll U_g commute with H within tolerance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2335bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity index: 0\n",
      "involution indices: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "inversion index: 71\n",
      "inversion perm: [1, 0, 19, 18, 14, 13, 17, 16, 11, 10, 9, 8, 15, 5, 4, 12, 7, 6, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "def compose(p, q): return p[q]\n",
    "\n",
    "# find identity index\n",
    "identity_idx = next(i for i, p in enumerate(perms) if np.array_equal(p, np.arange(len(p))))\n",
    "identity = perms[identity_idx]\n",
    "\n",
    "# find all involution indices (order 2, excluding identity)\n",
    "involution_indices = [i for i, p in enumerate(perms) if i != identity_idx and np.array_equal(compose(p, p), identity)]\n",
    "\n",
    "# find the unique central involution (spatial inversion)\n",
    "inversion_idx = None\n",
    "for i in involution_indices:\n",
    "    p = perms[i]\n",
    "    if all(np.array_equal(compose(p, g), compose(g, p)) for g in perms):\n",
    "        inversion_idx = i\n",
    "        break\n",
    "    \n",
    "print(\"identity index:\", identity_idx)\n",
    "print(\"involution indices:\", involution_indices)\n",
    "print(\"inversion index:\", inversion_idx)\n",
    "if inversion_idx is not None:\n",
    "    print(\"inversion perm:\", perms[inversion_idx].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0c0b8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjugacy classes (canonical label <- raw_index):\n",
      "           E  <- raw   9    size=  1, order= 1\n",
      "        12C5  <- raw   7    size= 12, order= 5\n",
      "      12C5^2  <- raw   4    size= 12, order= 5\n",
      "        20C3  <- raw   3    size= 20, order= 3\n",
      "        15C2  <- raw   1    size= 15, order= 2\n",
      "           i  <- raw   8    size=  1, order= 2\n",
      "       12S10  <- raw   0    size= 12, order=10\n",
      "   12(S10)^3  <- raw   6    size= 12, order=10\n",
      "        20S6  <- raw   2    size= 20, order= 6\n",
      "         15Ïƒ  <- raw   5    size= 15, order= 2\n",
      "\n",
      "Raw class summary (raw_idx, size, order, chi_red):\n",
      "       12S10  raw_idx=  0  size= 12  order=10  chi_red=   4.0\n",
      "        15C2  raw_idx=  1  size= 15  order= 2  chi_red=1024.0\n",
      "        20S6  raw_idx=  2  size= 20  order= 6  chi_red=  16.0\n",
      "        20C3  raw_idx=  3  size= 20  order= 3  chi_red= 256.0\n",
      "      12C5^2  raw_idx=  4  size= 12  order= 5  chi_red=  16.0\n",
      "         15Ïƒ  raw_idx=  5  size= 15  order= 2  chi_red=4096.0\n",
      "   12(S10)^3  raw_idx=  6  size= 12  order=10  chi_red=   4.0\n",
      "        12C5  raw_idx=  7  size= 12  order= 5  chi_red=  16.0\n",
      "           i  raw_idx=  8  size=  1  order= 2  chi_red=1024.0\n",
      "           E  raw_idx=  9  size=  1  order= 1  chi_red=1048576.0\n",
      "Building projector for irrep 'Ag' (dim=1)\n",
      "  Adding class 'E' contribution with chi=1.0\n",
      "  Adding class '12C5' contribution with chi=1.0\n",
      "  Adding class '12C5^2' contribution with chi=1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=1.0\n",
      "  Adding class 'i' contribution with chi=1.0\n",
      "  Adding class '12S10' contribution with chi=1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=1.0\n",
      "  Adding class '20S6' contribution with chi=1.0\n",
      "  Adding class '15Ïƒ' contribution with chi=1.0\n",
      "Building projector for irrep 'T1g' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=1.6180339887498947\n",
      "  Adding class '12C5^2' contribution with chi=-0.6180339887498949\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=3.0\n",
      "  Adding class '12S10' contribution with chi=-0.6180339887498949\n",
      "  Adding class '12(S10)^3' contribution with chi=1.6180339887498947\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15Ïƒ' contribution with chi=-1.0\n",
      "Building projector for irrep 'T2g' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=-0.6180339887498949\n",
      "  Adding class '12C5^2' contribution with chi=1.6180339887498947\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=3.0\n",
      "  Adding class '12S10' contribution with chi=1.6180339887498947\n",
      "  Adding class '12(S10)^3' contribution with chi=-0.6180339887498949\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15Ïƒ' contribution with chi=-1.0\n",
      "Building projector for irrep 'Gg' (dim=4)\n",
      "  Adding class 'E' contribution with chi=4.0\n",
      "  Adding class '12C5' contribution with chi=-1.0\n",
      "  Adding class '12C5^2' contribution with chi=-1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=0.0\n",
      "  Adding class 'i' contribution with chi=4.0\n",
      "  Adding class '12S10' contribution with chi=-1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=-1.0\n",
      "  Adding class '20S6' contribution with chi=1.0\n",
      "  Adding class '15Ïƒ' contribution with chi=0.0\n",
      "Building projector for irrep 'Hg' (dim=5)\n",
      "  Adding class 'E' contribution with chi=5.0\n",
      "  Adding class '12C5' contribution with chi=0.0\n",
      "  Adding class '12C5^2' contribution with chi=0.0\n",
      "  Adding class '20C3' contribution with chi=-1.0\n",
      "  Adding class '15C2' contribution with chi=1.0\n",
      "  Adding class 'i' contribution with chi=5.0\n",
      "  Adding class '12S10' contribution with chi=0.0\n",
      "  Adding class '12(S10)^3' contribution with chi=0.0\n",
      "  Adding class '20S6' contribution with chi=-1.0\n",
      "  Adding class '15Ïƒ' contribution with chi=1.0\n",
      "Building projector for irrep 'Au' (dim=1)\n",
      "  Adding class 'E' contribution with chi=1.0\n",
      "  Adding class '12C5' contribution with chi=1.0\n",
      "  Adding class '12C5^2' contribution with chi=1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=1.0\n",
      "  Adding class 'i' contribution with chi=-1.0\n",
      "  Adding class '12S10' contribution with chi=-1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=-1.0\n",
      "  Adding class '20S6' contribution with chi=-1.0\n",
      "  Adding class '15Ïƒ' contribution with chi=-1.0\n",
      "Building projector for irrep 'T1u' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=1.6180339887498947\n",
      "  Adding class '12C5^2' contribution with chi=-0.6180339887498949\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=-3.0\n",
      "  Adding class '12S10' contribution with chi=0.6180339887498949\n",
      "  Adding class '12(S10)^3' contribution with chi=-1.6180339887498947\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15Ïƒ' contribution with chi=1.0\n",
      "Building projector for irrep 'T2u' (dim=3)\n",
      "  Adding class 'E' contribution with chi=3.0\n",
      "  Adding class '12C5' contribution with chi=-0.6180339887498949\n",
      "  Adding class '12C5^2' contribution with chi=1.6180339887498947\n",
      "  Adding class '20C3' contribution with chi=0.0\n",
      "  Adding class '15C2' contribution with chi=-1.0\n",
      "  Adding class 'i' contribution with chi=-3.0\n",
      "  Adding class '12S10' contribution with chi=-1.6180339887498947\n",
      "  Adding class '12(S10)^3' contribution with chi=0.6180339887498949\n",
      "  Adding class '20S6' contribution with chi=0.0\n",
      "  Adding class '15Ïƒ' contribution with chi=1.0\n",
      "Building projector for irrep 'Gu' (dim=4)\n",
      "  Adding class 'E' contribution with chi=4.0\n",
      "  Adding class '12C5' contribution with chi=-1.0\n",
      "  Adding class '12C5^2' contribution with chi=-1.0\n",
      "  Adding class '20C3' contribution with chi=1.0\n",
      "  Adding class '15C2' contribution with chi=0.0\n",
      "  Adding class 'i' contribution with chi=-4.0\n",
      "  Adding class '12S10' contribution with chi=1.0\n",
      "  Adding class '12(S10)^3' contribution with chi=1.0\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.08 GiB for an array with shape (72258802,) and data type complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 81\u001b[39m\n\u001b[32m     78\u001b[39m classop = build_class_operators_in_Ih_order(N_spins, classes, ordered_indices)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Build projectors\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m projectors = build_projectors(classop, chi_irreps, dims_irreps, class_sizes_Ih, G_order)\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBuilt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(projectors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m projectors for irreps:\u001b[39m\u001b[33m\"\u001b[39m, irrep_labels)\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Quick sanity checks: idempotency (P^2 = P), Hermiticity (Pâ€  = P) and trace\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mbuild_projectors\u001b[39m\u001b[34m(class_ops, chi_irreps, dims_irreps, class_sizes, G_order)\u001b[39m\n\u001b[32m     64\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Adding class \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_lbl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m contribution with chi=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchi_Gamma[k]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m         \u001b[38;5;66;03m# sparse scalar multiplication + sparse addition keeps result sparse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         P = P + coef * C_k\n\u001b[32m     68\u001b[39m     projectors.append(P)   \u001b[38;5;66;03m# already sparse; do not convert to dense/force .tocsr()\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m projectors\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:559\u001b[39m, in \u001b[36m_spbase.__add__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m other.shape != \u001b[38;5;28mself\u001b[39m.shape:\n\u001b[32m    558\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minconsistent shapes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._add_sparse(other)\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m isdense(other):\n\u001b[32m    561\u001b[39m     other = np.broadcast_to(other, \u001b[38;5;28mself\u001b[39m.shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:386\u001b[39m, in \u001b[36m_cs_matrix._add_sparse\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_add_sparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._binopt(other, \u001b[33m'\u001b[39m\u001b[33m_plus_\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1370\u001b[39m, in \u001b[36m_cs_matrix._binopt\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   1368\u001b[39m     data = np.empty(maxnnz, dtype=np.bool_)\n\u001b[32m   1369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m     data = np.empty(maxnnz, dtype=upcast(\u001b[38;5;28mself\u001b[39m.dtype, other.dtype))\n\u001b[32m   1372\u001b[39m M, N = \u001b[38;5;28mself\u001b[39m._shape_as_2d\n\u001b[32m   1373\u001b[39m fn(M, N,\n\u001b[32m   1374\u001b[39m    np.asarray(\u001b[38;5;28mself\u001b[39m.indptr, dtype=idx_dtype),\n\u001b[32m   1375\u001b[39m    np.asarray(\u001b[38;5;28mself\u001b[39m.indices, dtype=idx_dtype),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1379\u001b[39m    other.data,\n\u001b[32m   1380\u001b[39m    indptr, indices, data)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 1.08 GiB for an array with shape (72258802,) and data type complex128"
     ]
    }
   ],
   "source": [
    "ordered_indices = sol[\"ordered_indices\"]\n",
    "\n",
    "# Canonical Ih column order\n",
    "class_labels_Ih = [\n",
    "    \"E\", \"12C5\", \"12C5^2\", \"20C3\", \"15C2\",\n",
    "    \"i\", \"12S10\", \"12(S10)^3\", \"20S6\", \"15Ïƒ\",\n",
    "]\n",
    "\n",
    "# map raw class index -> canonical Ih label\n",
    "raw_to_label = {raw: lbl for raw, lbl in zip(ordered_indices, class_labels_Ih)}\n",
    "\n",
    "print(\"Conjugacy classes (canonical label <- raw_index):\")\n",
    "for k, lbl in enumerate(class_labels_Ih):\n",
    "    raw_idx = ordered_indices[k]\n",
    "    cls = classes[raw_idx]\n",
    "    size = len(cls)\n",
    "    order = perm_order(cls[0])\n",
    "    print(f\"  {lbl:>10}  <- raw {raw_idx:3d}    size={size:3d}, order={order:2d}\")\n",
    "\n",
    "print(\"\\nRaw class summary (raw_idx, size, order, chi_red):\")\n",
    "for cd in class_data:\n",
    "    label = raw_to_label.get(cd[\"idx\"], f\"raw_{cd['idx']}\")\n",
    "    print(f\"  {label:>10}  raw_idx={cd['idx']:3d}  size={cd['size']:3d}  order={cd['order']:2d}  chi_red={cd['chi']:6.1f}\")\n",
    "\n",
    "# Build class operators in Ih order\n",
    "def build_class_operators_in_Ih_order(N_spins, classes, ordered_indices):\n",
    "    class_ops = []\n",
    "    for class_idx in ordered_indices:\n",
    "        class_perms = classes[class_idx]\n",
    "        U_sum = None\n",
    "        for perm in class_perms:\n",
    "            U_g = build_symmetry_operator(N_spins, perm)\n",
    "            if U_sum is None:\n",
    "                U_sum = U_g.astype(np.complex128, copy=True).tocsr()\n",
    "            else:\n",
    "                U_sum = U_sum + U_g\n",
    "        class_ops.append(U_sum.tocsr())\n",
    "    return class_ops\n",
    "\n",
    "def build_projectors(class_ops, chi_irreps, dims_irreps, class_sizes, G_order=120):\n",
    "    \"\"\"\n",
    "    Build orthogonal projectors P_Gamma for each irrep Gamma of group G using sparse ops only.\n",
    "    Returns a list of sparse matrices (same sparse format as used during accumulation).\n",
    "    \"\"\"\n",
    "    projectors = []\n",
    "    n_irreps, n_classes = chi_irreps.shape\n",
    "\n",
    "    # assume at least one class_op present and use its shape\n",
    "    if len(class_ops) == 0:\n",
    "        return projectors\n",
    "    dim = class_ops[0].shape[0]\n",
    "\n",
    "    for i in range(n_irreps):\n",
    "        d_Gamma = dims_irreps[i]\n",
    "        chi_Gamma = chi_irreps[i]\n",
    "        label = irrep_labels[i] if i < len(irrep_labels) else f\"irrep_{i}\"\n",
    "        print(f\"Building projector for irrep '{label}' (dim={d_Gamma})\")\n",
    "\n",
    "        # start from a sparse zero matrix (CSR) with complex dtype and accumulate sparsely\n",
    "        P = csr_matrix((dim, dim), dtype=np.complex128)\n",
    "        for k, C_k in enumerate(class_ops):\n",
    "            class_lbl = class_labels_Ih[k] if k < len(class_labels_Ih) else f\"class_{k}\"\n",
    "            coef = complex((d_Gamma / G_order) * np.conj(chi_Gamma[k]))\n",
    "            print(f\"  Adding class '{class_lbl}' contribution with chi={chi_Gamma[k]}\")\n",
    "            # sparse scalar multiplication + sparse addition keeps result sparse\n",
    "            P = P + coef * C_k\n",
    "\n",
    "        projectors.append(P)   # already sparse; do not convert to dense/force .tocsr()\n",
    "\n",
    "    return projectors\n",
    "\n",
    "# Input data (must all use the same class order!)\n",
    "G_order = 120\n",
    "class_sizes_Ih = np.array([1,12,12,20,15,1,12,12,20,15])\n",
    "dims_irreps = np.array([1,3,3,4,5,1,3,3,4,5])\n",
    "\n",
    "# Build classes\n",
    "classop = build_class_operators_in_Ih_order(N_spins, classes, ordered_indices)\n",
    "\n",
    "# Build projectors\n",
    "projectors = build_projectors(classop, chi_irreps, dims_irreps, class_sizes_Ih, G_order)\n",
    "\n",
    "print(f\"\\nBuilt {len(projectors)} projectors for irreps:\", irrep_labels)\n",
    "\n",
    "# Quick sanity checks: idempotency (P^2 = P), Hermiticity (Pâ€  = P) and trace\n",
    "err_thresh = 1e-8  # threshold below which we declare the property satisfied\n",
    "for i, P in enumerate(projectors):\n",
    "    label = irrep_labels[i] if i < len(irrep_labels) else f\"irrep_{i}\"\n",
    "    # P may be sparse CSR\n",
    "    P2 = P @ P\n",
    "    diff_idem = P2 - P\n",
    "    # idempotency error (Frobenius)\n",
    "    if issparse(diff_idem):\n",
    "        idem_err = np.sqrt((diff_idem.multiply(diff_idem.conj())).sum())\n",
    "    else:\n",
    "        idem_err = np.linalg.norm(diff_idem, ord='fro')\n",
    "    # Hermiticity error\n",
    "    diff_herm = P - P.conj().T\n",
    "    if issparse(diff_herm):\n",
    "        herm_err = np.sqrt((diff_herm.multiply(diff_herm.conj())).sum())\n",
    "    else:\n",
    "        herm_err = np.linalg.norm(diff_herm, ord='fro')\n",
    "    # trace (should equal dimension of the irrep subspace: n_Gamma * d_Gamma)\n",
    "    try:\n",
    "        tr = np.real(P.diagonal().sum())\n",
    "    except Exception:\n",
    "        tr = float(np.real(np.trace(P.toarray())))\n",
    "\n",
    "    idem_ok = idem_err < err_thresh\n",
    "    herm_ok = herm_err < err_thresh\n",
    "    ok = idem_ok and herm_ok\n",
    "\n",
    "    print(f\"\\nProjector '{label}':\")\n",
    "    print(f\"  trace = {tr:.6f}\")\n",
    "    print(f\"  Idempotent: {'YES' if idem_ok else 'NO'} (err={idem_err:.3e}, thresh={err_thresh:.1e})\")\n",
    "    print(f\"  Hermitian : {'YES' if herm_ok else 'NO'} (err={herm_err:.3e}, thresh={err_thresh:.1e})\")\n",
    "    print(f\"  Projector valid (idempotent & hermitian): {'YES' if ok else 'NO'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b92e731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of projector traces = 1048576.000000  (expected 1048576)\n",
      "|| sum(P) - I ||_F = 2.325e-13, max_abs_entry = 6.661e-16\n",
      "Sum is identity: YES\n"
     ]
    }
   ],
   "source": [
    "# Check that sum of projectors = Identity\n",
    "dim = projectors[0].shape[0]\n",
    "Id = eye(dim, dtype=np.complex128, format='csr')\n",
    "\n",
    "# sum projectors (sparse)\n",
    "S = None\n",
    "for P in projectors:\n",
    "    S = P.copy() if S is None else S + P\n",
    "\n",
    "diff = (S - Id).tocsr()\n",
    "\n",
    "# Frobenius norm of the deviation\n",
    "if issparse(diff):\n",
    "    s = (diff.multiply(diff.conj())).sum()\n",
    "    frob = float(np.sqrt(np.real(s)))  # take real part to avoid ComplexWarning\n",
    "    max_abs = float(np.max(np.abs(diff.data))) if diff.nnz > 0 else 0.0\n",
    "else:\n",
    "    frob = float(np.linalg.norm(diff, ord='fro'))\n",
    "    max_abs = float(np.max(np.abs(diff)))\n",
    "\n",
    "# Total trace should equal dim\n",
    "# (trace is linear, so either sum individual traces or trace of S)\n",
    "total_trace = float(np.real(S.diagonal().sum()))\n",
    "\n",
    "print(f\"Sum of projector traces = {total_trace:.6f}  (expected {dim})\")\n",
    "print(f\"|| sum(P) - I ||_F = {frob:.3e}, max_abs_entry = {max_abs:.3e}\")\n",
    "print(\"Sum is identity:\" , \"YES\" if frob < 1e-8 and abs(total_trace - dim) < 1e-6 else \"NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c7081083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vc0_sz0_evenparity_Ih_g_evenUg(N, projectors, irrep_labels, Ug,\n",
    "                                        rng=None, max_attempts=200):\n",
    "    \"\"\"\n",
    "    Build a single normalized vector v with:\n",
    "      - Sz = 0 and even parity (support only on those computational basis states),\n",
    "      - lying in the Ih 'g' sector (sum of irreps ending with 'g'),\n",
    "      - invariant under given Ug (i.e. (Ug @ v) â‰ˆ v).\n",
    "\n",
    "    Returns: v (shape (D,), complex128)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    idx_sector = build_sz0_even_parity_indices(N)\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(\"No Sz=0 & even-parity basis states\")\n",
    "\n",
    "    # total projector onto all 'g' irreps\n",
    "    g_indices = [i for i, lbl in enumerate(irrep_labels) if str(lbl).endswith('g')]\n",
    "    if len(g_indices) == 0:\n",
    "        raise ValueError(\"No 'g' irreps found in irrep_labels\")\n",
    "    P_g = None\n",
    "    for i in g_indices:\n",
    "        P = projectors[i]\n",
    "        P_g = P.copy() if P_g is None else (P_g + P)\n",
    "    P_g = P_g.astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    # symmetrizer for being even under Ug: S = 0.5*(I + Ug)\n",
    "    Id = eye(D, dtype=np.complex128, format='csr')\n",
    "    S = 0.5 * (Id + Ug)   # works for sparse Ug\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        amps = rng.normal(size=len(idx_sector)) + 1j * rng.normal(size=len(idx_sector))\n",
    "        v = np.zeros(D, dtype=np.complex128)\n",
    "        v[idx_sector] = amps\n",
    "\n",
    "        # project into g sector and enforce Ug-evenness\n",
    "        v = P_g @ v\n",
    "        v = S @ v\n",
    "\n",
    "        nrm = norm(v)\n",
    "        if nrm > 0:\n",
    "            v /= nrm\n",
    "            # quick sanity checks (optional)\n",
    "            # parity and magnetization\n",
    "            mag = check_magnetization_sector(v, N)\n",
    "            par = check_parity_sector(v, N)\n",
    "            # Ug invariance residual\n",
    "            resid = np.linalg.norm((Ug @ v) - v)\n",
    "            if abs(mag) < 1e-8 and par.startswith(\"even\") and resid < 1e-8:\n",
    "                return v\n",
    "            # even if tolerance not met, still return after success to avoid infinite loop\n",
    "            return v\n",
    "\n",
    "    # fallback: scan basis vectors in sector, symmetrize & project\n",
    "    for b in idx_sector:\n",
    "        e = np.zeros(D, dtype=np.complex128); e[b] = 1.0\n",
    "        v = P_g @ e\n",
    "        v = S @ v\n",
    "        nrm = norm(v)\n",
    "        if nrm > 0:\n",
    "            return v / nrm\n",
    "\n",
    "    raise RuntimeError(\"Failed to build vc0 after attempts\")\n",
    "\n",
    "def make_vc0_evenparity_Ih_g_evenUg(N, projectors, irrep_labels, Ug,\n",
    "                                    rng=None, max_attempts=200):\n",
    "    \"\"\"\n",
    "    Build a single normalized vector v with:\n",
    "      - even parity (support only on computational basis states with even number of ups),\n",
    "      - lying in the Ih 'g' sector (sum of irreps ending with 'g'),\n",
    "      - invariant under given Ug (i.e. (Ug @ v) â‰ˆ v).\n",
    "    Unlike make_vc0_sz0_evenparity_Ih_g_evenUg this DOES NOT enforce Sz = 0.\n",
    "    Returns: v (shape (D,), complex128)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    # even-parity indices only (drop the Sz=0 restriction)\n",
    "    idx_sector = [b for b in range(D) if parity(b, N) == 1]\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(\"No even-parity basis states\")\n",
    "\n",
    "    # total projector onto all 'g' irreps\n",
    "    g_indices = [i for i, lbl in enumerate(irrep_labels) if str(lbl).endswith('g')]\n",
    "    if len(g_indices) == 0:\n",
    "        raise ValueError(\"No 'g' irreps found in irrep_labels\")\n",
    "    P_g = None\n",
    "    for i in g_indices:\n",
    "        P = projectors[i]\n",
    "        P_g = P.copy() if P_g is None else (P_g + P)\n",
    "    P_g = P_g.astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    # symmetrizer for being even under Ug: S = 0.5*(I + Ug)\n",
    "    Id = eye(D, dtype=np.complex128, format='csr')\n",
    "    S = 0.5 * (Id + Ug)   # works for sparse Ug\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        amps = rng.normal(size=len(idx_sector)) + 1j * rng.normal(size=len(idx_sector))\n",
    "        v = np.zeros(D, dtype=np.complex128)\n",
    "        v[idx_sector] = amps\n",
    "\n",
    "        # project into g sector and enforce Ug-evenness\n",
    "        v = P_g @ v\n",
    "        v = S @ v\n",
    "\n",
    "        nrm = norm(v)\n",
    "        if nrm > 0:\n",
    "            v /= nrm\n",
    "            # parity check and Ug invariance residual\n",
    "            par = check_parity_sector(v, N)\n",
    "            resid = np.linalg.norm((Ug @ v) - v)\n",
    "            if par.startswith(\"even\") and resid < 1e-8:\n",
    "                return v\n",
    "            # return even if tolerance not met to avoid long loops\n",
    "            return v\n",
    "\n",
    "    # fallback: scan basis vectors in even-parity sector, symmetrize & project\n",
    "    for b in idx_sector:\n",
    "        e = np.zeros(D, dtype=np.complex128); e[b] = 1.0\n",
    "        v = P_g @ e\n",
    "        v = S @ v\n",
    "        nrm = norm(v)\n",
    "        if nrm > 0:\n",
    "            return v / nrm\n",
    "\n",
    "    raise RuntimeError(\"Failed to build vc0_evenparity after attempts\")\n",
    "\n",
    "def make_vc0_evenparity_Ih_irrep(N, projectors, irrep_labels, target_irrep,\n",
    "                                 rng=None, max_attempts=200):\n",
    "    \"\"\"\n",
    "    Build a single normalized vector v with:\n",
    "      - even parity (support only on computational basis states with even number of ups),\n",
    "      - lying in the chosen Ih irrep subspace (e.g. \"Ag\" or \"Gg\"),\n",
    "      - (no explicit Ug[55] invariance enforced).\n",
    "    Returns: v (shape (D,), complex128)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    # even-parity indices only\n",
    "    idx_sector = [b for b in range(D) if parity(b, N) == 1]\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(\"No even-parity basis states\")\n",
    "\n",
    "    # find target irrep projector\n",
    "    try:\n",
    "        i_target = irrep_labels.index(str(target_irrep))\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"target_irrep '{target_irrep}' not found in irrep_labels\")\n",
    "    P_target = projectors[i_target].astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        amps = rng.normal(size=len(idx_sector)) + 1j * rng.normal(size=len(idx_sector))\n",
    "        v = np.zeros(D, dtype=np.complex128)\n",
    "        v[idx_sector] = amps\n",
    "\n",
    "        # project into chosen irrep subspace\n",
    "        v = P_target @ v\n",
    "        nrm = norm(v)\n",
    "        if nrm > 0:\n",
    "            v /= nrm\n",
    "            # sanity: ensure most weight is in target irrep (numerical)\n",
    "            v_proj = P_target @ v\n",
    "            weight = np.vdot(v_proj, v_proj).real\n",
    "            par = check_parity_sector(v, N)\n",
    "            if par.startswith(\"even\") and weight > 1e-8:\n",
    "                return v\n",
    "            return v\n",
    "\n",
    "    # fallback: try basis vectors in even-parity sector\n",
    "    for b in idx_sector:\n",
    "        e = np.zeros(D, dtype=np.complex128); e[b] = 1.0\n",
    "        v = P_target @ e\n",
    "        nrm = norm(v)\n",
    "        if nrm > 0:\n",
    "            return v / nrm\n",
    "\n",
    "    raise RuntimeError(f\"Failed to build vector in irrep '{target_irrep}' after {max_attempts} attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f6c77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CSR helpers for sparse column vectors (shape (D,1)) ---\n",
    "def _csr_rand_vec_in_indices(D, idx_sector, rng):\n",
    "    rows = np.asarray(idx_sector, dtype=np.int64)\n",
    "    K = rows.size\n",
    "    cols = np.zeros(K, dtype=np.int64)\n",
    "    data = rng.normal(size=K) + 1j * rng.normal(size=K)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(D, 1), dtype=np.complex128)\n",
    "\n",
    "def _csr_basis_vec(D, b):\n",
    "    return csr_matrix(([1.0 + 0.0j], ([int(b)], [0])), shape=(D, 1), dtype=np.complex128)\n",
    "\n",
    "def _csr_norm(v):\n",
    "    if v.nnz == 0:\n",
    "        return 0.0\n",
    "    return float(np.sqrt(np.sum(np.abs(v.data) ** 2)))\n",
    "\n",
    "def _csr_normalize(v):\n",
    "    nrm = _csr_norm(v)\n",
    "    if nrm > 0:\n",
    "        v = v.copy()\n",
    "        v.data /= nrm\n",
    "    return v, nrm\n",
    "\n",
    "def _csr_residual(Ug, v):\n",
    "    r = Ug @ v - v\n",
    "    return _csr_norm(r)\n",
    "\n",
    "def _csr_parity_label(v, N, tol=1e-6):\n",
    "    # compute weights on even/odd parity using nonzeros only\n",
    "    coo = v.tocoo()\n",
    "    rows = coo.row\n",
    "    data = coo.data\n",
    "    w_even = 0.0\n",
    "    w_odd = 0.0\n",
    "    for idx, amp in zip(rows, data):\n",
    "        if parity(int(idx), N) == 1:\n",
    "            w_even += float((amp.conjugate() * amp).real)\n",
    "        else:\n",
    "            w_odd += float((amp.conjugate() * amp).real)\n",
    "    if w_even > 1.0 - tol:\n",
    "        return \"even\"\n",
    "    if w_odd > 1.0 - tol:\n",
    "        return \"odd\"\n",
    "    return f\"mixed (even={w_even:.4f}, odd={w_odd:.4f})\"\n",
    "\n",
    "def _csr_magnetization_avg(v, N):\n",
    "    coo = v.tocoo()\n",
    "    rows = coo.row\n",
    "    data = coo.data\n",
    "    m = 0.0\n",
    "    for idx, amp in zip(rows, data):\n",
    "        m += magnetization(int(idx), N) * float((amp.conjugate() * amp).real)\n",
    "    return m\n",
    "\n",
    "def make_vc0_sz0_evenparity_Ih_g_evenUg(N, projectors, irrep_labels, Ug,\n",
    "                                        rng=None, max_attempts=200):\n",
    "    \"\"\"\n",
    "    Build a single normalized vector v with:\n",
    "      - Sz = 0 and even parity (support only on those computational basis states),\n",
    "      - lying in the Ih 'g' sector (sum of irreps ending with 'g'),\n",
    "      - invariant under given Ug (i.e. (Ug @ v) â‰ˆ v).\n",
    "    All operations are sparse (CSR) internally.\n",
    "    Returns: v (shape (D,), complex128)\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    idx_sector = build_sz0_even_parity_indices(N)\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(\"No Sz=0 & even-parity basis states\")\n",
    "\n",
    "    # total projector onto all 'g' irreps\n",
    "    g_indices = [i for i, lbl in enumerate(irrep_labels) if str(lbl).endswith('g')]\n",
    "    if len(g_indices) == 0:\n",
    "        raise ValueError(\"No 'g' irreps found in irrep_labels\")\n",
    "    P_g = None\n",
    "    for i in g_indices:\n",
    "        P = projectors[i]\n",
    "        P_g = P.copy() if P_g is None else (P_g + P)\n",
    "    P_g = P_g.astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    # symmetrizer S = 0.5*(I + Ug)\n",
    "    Id = eye(D, dtype=np.complex128, format='csr')\n",
    "    S = (Id + Ug) * 0.5\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        v = _csr_rand_vec_in_indices(D, idx_sector, rng)\n",
    "\n",
    "        # project into g sector and enforce Ug-evenness\n",
    "        v = P_g @ v\n",
    "        v = S @ v\n",
    "\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            mag = _csr_magnetization_avg(v, N)\n",
    "            par = _csr_parity_label(v, N)\n",
    "            resid = _csr_residual(Ug, v)\n",
    "            if abs(mag) < 1e-8 and par.startswith(\"even\") and resid < 1e-8:\n",
    "                return v.toarray().ravel()\n",
    "            # return a normalized candidate anyway\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    # fallback: scan basis vectors in sector, symmetrize & project\n",
    "    for b in idx_sector:\n",
    "        v = _csr_basis_vec(D, b)\n",
    "        v = P_g @ v\n",
    "        v = S @ v\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    raise RuntimeError(\"Failed to build vc0 after attempts\")\n",
    "\n",
    "def make_vc0_evenparity_Ih_g_evenUg(N, projectors, irrep_labels, Ug,\n",
    "                                    rng=None, max_attempts=200):\n",
    "    \"\"\"\n",
    "    Build a single normalized vector v with:\n",
    "      - even parity,\n",
    "      - in the Ih 'g' sector,\n",
    "      - Ug-even.\n",
    "    Sparse (CSR) internally. Returns dense 1D vector.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    idx_sector = [b for b in range(D) if parity(b, N) == 1]\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(\"No even-parity basis states\")\n",
    "\n",
    "    g_indices = [i for i, lbl in enumerate(irrep_labels) if str(lbl).endswith('g')]\n",
    "    if len(g_indices) == 0:\n",
    "        raise ValueError(\"No 'g' irreps found in irrep_labels\")\n",
    "    P_g = None\n",
    "    for i in g_indices:\n",
    "        P = projectors[i]\n",
    "        P_g = P.copy() if P_g is None else (P_g + P)\n",
    "    P_g = P_g.astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    Id = eye(D, dtype=np.complex128, format='csr')\n",
    "    S = (Id + Ug) * 0.5\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        v = _csr_rand_vec_in_indices(D, idx_sector, rng)\n",
    "\n",
    "        v = P_g @ v\n",
    "        v = S @ v\n",
    "\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            par = _csr_parity_label(v, N)\n",
    "            resid = _csr_residual(Ug, v)\n",
    "            if par.startswith(\"even\") and resid < 1e-8:\n",
    "                return v.toarray().ravel()\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    # fallback\n",
    "    for b in idx_sector:\n",
    "        v = _csr_basis_vec(D, b)\n",
    "        v = P_g @ v\n",
    "        v = S @ v\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    raise RuntimeError(\"Failed to build vc0_evenparity after attempts\")\n",
    "\n",
    "def make_vc0_evenparity_Ih_irrep(N, projectors, irrep_labels, target_irrep,\n",
    "                                 rng=None, max_attempts=200):\n",
    "    \"\"\"\n",
    "    Build a single normalized vector v with:\n",
    "      - even parity,\n",
    "      - in the chosen Ih irrep subspace (e.g. \"Ag\" or \"Gg\").\n",
    "    Sparse (CSR) internally. Returns dense 1D vector.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    D = 1 << N\n",
    "    idx_sector = [b for b in range(D) if parity(b, N) == 1]\n",
    "    if len(idx_sector) == 0:\n",
    "        raise RuntimeError(\"No even-parity basis states\")\n",
    "\n",
    "    try:\n",
    "        i_target = irrep_labels.index(str(target_irrep))\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"target_irrep '{target_irrep}' not found in irrep_labels\")\n",
    "    P_target = projectors[i_target].astype(np.complex128, copy=False).tocsr()\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        v = _csr_rand_vec_in_indices(D, idx_sector, rng)\n",
    "\n",
    "        v = P_target @ v\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            w = _csr_norm(P_target @ v) ** 2\n",
    "            par = _csr_parity_label(v, N)\n",
    "            if par.startswith(\"even\") and w > 1e-8:\n",
    "                return v.toarray().ravel()\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    # fallback\n",
    "    for b in idx_sector:\n",
    "        v = _csr_basis_vec(D, b)\n",
    "        v = P_target @ v\n",
    "        v, nrm = _csr_normalize(v)\n",
    "        if nrm > 0:\n",
    "            return v.toarray().ravel()\n",
    "\n",
    "    raise RuntimeError(f\"Failed to build vector in irrep '{target_irrep}' after {max_attempts} attempts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96d0d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm: 1.0000000000000002\n",
      "magnetization (expected 0): -0.02800213201693939\n",
      "parity sector (expected 'even'): even\n",
      "support size: 495760\n",
      "\n",
      "Irrep weights (descending):\n",
      "    Au: 1.000000e+00\n",
      "   T2u: 9.413361e-33\n",
      "   T1u: 9.131764e-33\n",
      "    Hu: 7.553237e-33\n",
      "    Gu: 4.261261e-33\n",
      "   T1g: 1.881524e-33\n",
      "   T2g: 1.571698e-33\n",
      "    Gg: 7.647139e-34\n",
      "    Hg: 4.908504e-34\n",
      "    Ag: 2.019770e-35\n",
      "\n",
      "Sum of irrep-weights = 1.000000000000 (should be â‰ˆ 1.0)\n",
      "\n",
      "Diagnostic Ug overlap: ||Ug v - v|| = 2.00e+00, <v|Ug|v> = -1.000000\n"
     ]
    }
   ],
   "source": [
    "# ensure idx_Ug set earlier: idx_Ug = 55; Ug = Ugs[idx_Ug]\n",
    "# build a vector in a chosen Ih irrep (no Ug invariance enforced)\n",
    "#vc0 = make_vc0_evenparity_Ih_g_evenUg(N, projectors, irrep_labels, Ug, rng=None, max_attempts=200)\n",
    "vc0 = make_vc0_evenparity_Ih_irrep(N, projectors, irrep_labels, target_irrep=\"Au\", rng=None)\n",
    "\n",
    "# quick checks for vc0\n",
    "tol = 1e-8\n",
    "\n",
    "print(\"norm:\", np.vdot(vc0, vc0).real)\n",
    "\n",
    "mag = check_magnetization_sector(vc0, N)\n",
    "par = check_parity_sector(vc0, N)\n",
    "print(\"magnetization (expected 0):\", mag)\n",
    "print(\"parity sector (expected 'even'):\", par)\n",
    "\n",
    "support = np.nonzero(np.abs(vc0) > 1e-10)[0]\n",
    "print(\"support size:\", support.size)\n",
    "\n",
    "# compute membership weights in each Ih irrep: w_Gamma = || P_Gamma |v> ||^2\n",
    "weights = {}\n",
    "for P, lbl in zip(projectors, irrep_labels):\n",
    "    psi_G = P @ vc0\n",
    "    w = np.vdot(psi_G, psi_G).real\n",
    "    weights[lbl] = float(w)\n",
    "\n",
    "# summary: sorted by weight\n",
    "sorted_weights = sorted(weights.items(), key=lambda kv: -kv[1])\n",
    "print(\"\\nIrrep weights (descending):\")\n",
    "for lbl, w in sorted_weights:\n",
    "    print(f\"  {lbl:>4}: {w:.6e}\")\n",
    "\n",
    "total_weight = sum(weights.values())\n",
    "print(f\"\\nSum of irrep-weights = {total_weight:.12f} (should be â‰ˆ 1.0)\")\n",
    "\n",
    "# optional: overlap with Ug (diagnostic only, not required)\n",
    "if 'Ug' in globals():\n",
    "    resid = np.linalg.norm(Ug @ vc0 - vc0)\n",
    "    ov = (np.vdot(vc0, Ug @ vc0) / np.vdot(vc0, vc0)).real\n",
    "    print(f\"\\nDiagnostic Ug overlap: ||Ug v - v|| = {resid:.2e}, <v|Ug|v> = {ov:.6f}\")\n",
    "\n",
    "# sanity checks (raise only if major failures)\n",
    "assert par.startswith(\"even\"), \"not in even-parity sector\"\n",
    "if abs(total_weight - 1.0) > 1e-6:\n",
    "    print(\"WARNING: sum of irrep weights deviates from 1 by\", total_weight - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9e7f448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 iterations with m=500, pad=0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, n_steps + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         Phi, evals = chebyshev_filter_v0_numpy(H, current, Emin=Emin, Emax=Emax,\n\u001b[32m     19\u001b[39m                                                target_E0=target, m=m, pad=pad, use_jackson=use_jackson)\n\u001b[32m     20\u001b[39m         \u001b[38;5;66;03m# basic sanity checks\u001b[39;00m\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(evals):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 724\u001b[39m, in \u001b[36mchebyshev_filter_v0_numpy\u001b[39m\u001b[34m(H, v0, Emin, Emax, target_E0, m, pad, use_jackson, rng)\u001b[39m\n\u001b[32m    721\u001b[39m tk   = t1\n\u001b[32m    723\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, m+\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     tkp1 = \u001b[32m2.0\u001b[39m * Htilde_dot(tk) - tkm1\n\u001b[32m    725\u001b[39m     filt = filt + alpha[k] * tkp1\n\u001b[32m    726\u001b[39m     tkm1, tk = tk, tkp1\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 708\u001b[39m, in \u001b[36mchebyshev_filter_v0_numpy.<locals>.Htilde_dot\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mHtilde_dot\u001b[39m(v):\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m     Hv = H @ v   \u001b[38;5;66;03m# works for dense or sparse\u001b[39;00m\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (Hv - c * v) / d\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:732\u001b[39m, in \u001b[36m_spbase.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[32m    730\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mScalar operands are not allowed, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    731\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33muse \u001b[39m\u001b[33m'\u001b[39m\u001b[33m*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m instead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._matmul_dispatch(other)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:617\u001b[39m, in \u001b[36m_spbase._matmul_dispatch\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m other.\u001b[34m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m np.ndarray:\n\u001b[32m    615\u001b[39m     \u001b[38;5;66;03m# Fast path for the most common case\u001b[39;00m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m other.shape == (N,):\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._matmul_vector(other)\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m other.shape == (N, \u001b[32m1\u001b[39m):\n\u001b[32m    619\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._matmul_vector(other.ravel())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\camipolv\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:526\u001b[39m, in \u001b[36m_cs_matrix._matmul_vector\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    524\u001b[39m \u001b[38;5;66;03m# csr_matvec or csc_matvec\u001b[39;00m\n\u001b[32m    525\u001b[39m fn = \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m.format + \u001b[33m'\u001b[39m\u001b[33m_matvec\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m fn(M, N, \u001b[38;5;28mself\u001b[39m.indptr, \u001b[38;5;28mself\u001b[39m.indices, \u001b[38;5;28mself\u001b[39m.data, other, result)\n\u001b[32m    528\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# run many short Chebyshev filters (m=500) repeatedly instead of one huge m\n",
    "m = 500\n",
    "n_steps = 50\n",
    "pad = 0.05\n",
    "use_jackson = True\n",
    "\n",
    "start_vec = vc0\n",
    "current = start_vec\n",
    "Emin = -62.51489576\n",
    "Emax = 62.60812227\n",
    "target = 0.0\n",
    "\n",
    "print(f\"Running {n_steps} iterations with m={m}, pad={pad}\")\n",
    "\n",
    "last_eval = None\n",
    "try:\n",
    "    for i in range(1, n_steps + 1):\n",
    "        Phi, evals = chebyshev_filter_v0_numpy(H, current, Emin=Emin, Emax=Emax,\n",
    "                                               target_E0=target, m=m, pad=pad, use_jackson=use_jackson)\n",
    "        # basic sanity checks\n",
    "        if not np.isfinite(evals):\n",
    "            print(f\"Stopped at step {i}: non-finite eval {evals}\")\n",
    "            break\n",
    "        if not np.all(np.isfinite(Phi)):\n",
    "            print(f\"Stopped at step {i}: non-finite entries in Phi\")\n",
    "            break\n",
    "\n",
    "        current = Phi\n",
    "        last_eval = evals\n",
    "\n",
    "        # print every ~10% of total steps (works for n_steps=10 too)\n",
    "        if (i % max(1, n_steps // 10) ) == 0 or i == 1 or i == n_steps:\n",
    "            support = np.count_nonzero(np.abs(current) > 1e-10)\n",
    "            print(f\"step {i:4d}: approx E = {last_eval:.8f}, support = {support}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(\"RuntimeError during filtering:\", e)\n",
    "\n",
    "# final result in `current`, last Rayleigh estimate in `last_eval`\n",
    "Phi_final = current\n",
    "E_final = last_eval\n",
    "print(\"Done. Final approx E:\", E_final)\n",
    "print(\"Final support size:\", np.count_nonzero(np.abs(Phi_final) > 1e-10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01483b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from random vector\n",
    "v0 = np.random.randn(H.shape[0])\n",
    "\n",
    "Emin0 = -62.51489576\n",
    "Emax0 = 62.60812227\n",
    "\n",
    "target_E0 = -4.0\n",
    "vc, Ec = chebyshev_filter_v0_numpy(H, v0, Emin=Emin0, Emax=Emax0, target_E0=target_E0, m=100000, pad=0.05, use_jackson=True)\n",
    "print(Ec, np.count_nonzero(np.abs(vc) > 1e-10))\n",
    "vc1, Ec1 = chebyshev_filter_v0_numpy(H, vc, Emin=Emin0, Emax=Emax0, target_E0=target_E0, m=100000, pad=0.05, use_jackson=True)\n",
    "print(Ec1, np.count_nonzero(np.abs(vc1) > 1e-10))\n",
    "vc2, Ec2 = chebyshev_filter_v0_numpy(H, vc1, Emin=Emin0, Emax=Emax0, target_E0=target_E0, m=100000, pad=0.05, use_jackson=True)\n",
    "print(Ec2, np.count_nonzero(np.abs(vc2) > 1e-10))\n",
    "vc3, Ec3 = chebyshev_filter_v0_numpy(H, vc2, Emin=Emin0, Emax=Emax0, target_E0=target_E0, m=100000, pad=0.05, use_jackson=True)\n",
    "print(Ec3, np.count_nonzero(np.abs(vc3) > 1e-10))\n",
    "vc4, Ec4 = chebyshev_filter_v0_numpy(H, vc3, Emin=Emin0, Emax=Emax0, target_E0=target_E0, m=100000, pad=0.05, use_jackson=True)\n",
    "print(Ec4, np.count_nonzero(np.abs(vc4) > 1e-10))\n",
    "vc5, Ec5 = chebyshev_filter_v0_numpy(H, vc4, Emin=Emin0, Emax=Emax0, target_E0=target_E0, m=100000, pad=0.05, use_jackson=True)\n",
    "print(Ec5, np.count_nonzero(np.abs(vc5) > 1e-10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
