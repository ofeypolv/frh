{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "from scipy.linalg import eigh, qr, null_space\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from scipy.sparse import eye, kron, identity, csr_matrix, csc_matrix, lil_matrix, dok_matrix, issparse, coo_matrix\n",
    "from scipy.sparse.linalg import eigsh, eigs, lobpcg, LinearOperator, ArpackNoConvergence\n",
    "from scipy.optimize import curve_fit\n",
    "from qutip import Qobj, ptrace, entropy_vn, qeye, tensor\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from itertools import product\n",
    "from functools import reduce\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import sympy as sp\n",
    "from collections import Counter, defaultdict, deque\n",
    "from IPython.display import display, HTML\n",
    "import networkx as nx\n",
    "from sympy.combinatorics import Permutation, PermutationGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotations: 60\n",
      "Full I_h: 120\n",
      "[(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), (0, 1, 2, 3, 5, 4, 7, 6, 9, 8, 11, 10), (0, 1, 4, 7, 2, 9, 10, 3, 8, 5, 6, 11), (0, 1, 4, 7, 9, 2, 3, 10, 5, 8, 11, 6), (0, 1, 5, 6, 2, 8, 11, 3, 9, 4, 7, 10), (0, 1, 5, 6, 8, 2, 3, 11, 4, 9, 10, 7), (0, 1, 8, 11, 5, 9, 10, 6, 4, 2, 3, 7), (0, 1, 8, 11, 9, 5, 6, 10, 2, 4, 7, 3), (0, 1, 9, 10, 4, 8, 11, 7, 5, 2, 3, 6), (0, 1, 9, 10, 8, 4, 7, 11, 2, 5, 6, 3), (1, 0, 3, 2, 6, 7, 4, 5, 10, 11, 8, 9), (1, 0, 3, 2, 7, 6, 5, 4, 11, 10, 9, 8), (1, 0, 6, 5, 3, 11, 8, 2, 10, 7, 4, 9), (1, 0, 6, 5, 11, 3, 2, 8, 7, 10, 9, 4), (1, 0, 7, 4, 3, 10, 9, 2, 11, 6, 5, 8), (1, 0, 7, 4, 10, 3, 2, 9, 6, 11, 8, 5), (1, 0, 10, 9, 7, 11, 8, 4, 6, 3, 2, 5), (1, 0, 10, 9, 11, 7, 4, 8, 3, 6, 5, 2), (1, 0, 11, 8, 6, 10, 9, 5, 7, 3, 2, 4), (1, 0, 11, 8, 10, 6, 5, 9, 3, 7, 4, 2), (2, 3, 0, 1, 6, 7, 4, 5, 8, 9, 10, 11), (2, 3, 0, 1, 7, 6, 5, 4, 9, 8, 11, 10), (2, 3, 6, 5, 0, 9, 10, 1, 8, 7, 4, 11), (2, 3, 6, 5, 9, 0, 1, 10, 7, 8, 11, 4), (2, 3, 7, 4, 0, 8, 11, 1, 9, 6, 5, 10), (2, 3, 7, 4, 8, 0, 1, 11, 6, 9, 10, 5), (2, 3, 8, 11, 7, 9, 10, 4, 6, 0, 1, 5), (2, 3, 8, 11, 9, 7, 4, 10, 0, 6, 5, 1), (2, 3, 9, 10, 6, 8, 11, 5, 7, 0, 1, 4), (2, 3, 9, 10, 8, 6, 5, 11, 0, 7, 4, 1), (3, 2, 1, 0, 4, 5, 6, 7, 10, 11, 8, 9), (3, 2, 1, 0, 5, 4, 7, 6, 11, 10, 9, 8), (3, 2, 4, 7, 1, 11, 8, 0, 10, 5, 6, 9), (3, 2, 4, 7, 11, 1, 0, 8, 5, 10, 9, 6), (3, 2, 5, 6, 1, 10, 9, 0, 11, 4, 7, 8), (3, 2, 5, 6, 10, 1, 0, 9, 4, 11, 8, 7), (3, 2, 10, 9, 5, 11, 8, 6, 4, 1, 0, 7), (3, 2, 10, 9, 11, 5, 6, 8, 1, 4, 7, 0), (3, 2, 11, 8, 4, 10, 9, 7, 5, 1, 0, 6), (3, 2, 11, 8, 10, 4, 7, 9, 1, 5, 6, 0), (4, 7, 0, 1, 3, 10, 9, 2, 5, 8, 11, 6), (4, 7, 0, 1, 10, 3, 2, 9, 8, 5, 6, 11), (4, 7, 3, 2, 0, 8, 11, 1, 5, 10, 9, 6), (4, 7, 3, 2, 8, 0, 1, 11, 10, 5, 6, 9), (4, 7, 5, 6, 8, 10, 9, 11, 0, 3, 2, 1), (4, 7, 5, 6, 10, 8, 11, 9, 3, 0, 1, 2), (4, 7, 8, 11, 3, 5, 6, 2, 10, 0, 1, 9), (4, 7, 8, 11, 5, 3, 2, 6, 0, 10, 9, 1), (4, 7, 10, 9, 0, 5, 6, 1, 8, 3, 2, 11), (4, 7, 10, 9, 5, 0, 1, 6, 3, 8, 11, 2), (5, 6, 0, 1, 3, 11, 8, 2, 4, 9, 10, 7), (5, 6, 0, 1, 11, 3, 2, 8, 9, 4, 7, 10), (5, 6, 3, 2, 0, 9, 10, 1, 4, 11, 8, 7), (5, 6, 3, 2, 9, 0, 1, 10, 11, 4, 7, 8), (5, 6, 4, 7, 9, 11, 8, 10, 0, 3, 2, 1), (5, 6, 4, 7, 11, 9, 10, 8, 3, 0, 1, 2), (5, 6, 9, 10, 3, 4, 7, 2, 11, 0, 1, 8), (5, 6, 9, 10, 4, 3, 2, 7, 0, 11, 8, 1), (5, 6, 11, 8, 0, 4, 7, 1, 9, 3, 2, 10), (5, 6, 11, 8, 4, 0, 1, 7, 3, 9, 10, 2), (6, 5, 1, 0, 2, 8, 11, 3, 7, 10, 9, 4), (6, 5, 1, 0, 8, 2, 3, 11, 10, 7, 4, 9), (6, 5, 2, 3, 1, 10, 9, 0, 7, 8, 11, 4), (6, 5, 2, 3, 10, 1, 0, 9, 8, 7, 4, 11), (6, 5, 7, 4, 8, 10, 9, 11, 2, 1, 0, 3), (6, 5, 7, 4, 10, 8, 11, 9, 1, 2, 3, 0), (6, 5, 8, 11, 1, 7, 4, 0, 10, 2, 3, 9), (6, 5, 8, 11, 7, 1, 0, 4, 2, 10, 9, 3), (6, 5, 10, 9, 2, 7, 4, 3, 8, 1, 0, 11), (6, 5, 10, 9, 7, 2, 3, 4, 1, 8, 11, 0), (7, 4, 1, 0, 2, 9, 10, 3, 6, 11, 8, 5), (7, 4, 1, 0, 9, 2, 3, 10, 11, 6, 5, 8), (7, 4, 2, 3, 1, 11, 8, 0, 6, 9, 10, 5), (7, 4, 2, 3, 11, 1, 0, 8, 9, 6, 5, 10), (7, 4, 6, 5, 9, 11, 8, 10, 2, 1, 0, 3), (7, 4, 6, 5, 11, 9, 10, 8, 1, 2, 3, 0), (7, 4, 9, 10, 1, 6, 5, 0, 11, 2, 3, 8), (7, 4, 9, 10, 6, 1, 0, 5, 2, 11, 8, 3), (7, 4, 11, 8, 2, 6, 5, 3, 9, 1, 0, 10), (7, 4, 11, 8, 6, 2, 3, 5, 1, 9, 10, 0), (8, 11, 0, 1, 6, 10, 9, 5, 2, 4, 7, 3), (8, 11, 0, 1, 10, 6, 5, 9, 4, 2, 3, 7), (8, 11, 2, 3, 4, 10, 9, 7, 0, 6, 5, 1), (8, 11, 2, 3, 10, 4, 7, 9, 6, 0, 1, 5), (8, 11, 4, 7, 2, 6, 5, 3, 0, 10, 9, 1), (8, 11, 4, 7, 6, 2, 3, 5, 10, 0, 1, 9), (8, 11, 6, 5, 0, 4, 7, 1, 2, 10, 9, 3), (8, 11, 6, 5, 4, 0, 1, 7, 10, 2, 3, 9), (8, 11, 10, 9, 0, 2, 3, 1, 4, 6, 5, 7), (8, 11, 10, 9, 2, 0, 1, 3, 6, 4, 7, 5), (9, 10, 0, 1, 7, 11, 8, 4, 2, 5, 6, 3), (9, 10, 0, 1, 11, 7, 4, 8, 5, 2, 3, 6), (9, 10, 2, 3, 5, 11, 8, 6, 0, 7, 4, 1), (9, 10, 2, 3, 11, 5, 6, 8, 7, 0, 1, 4), (9, 10, 5, 6, 2, 7, 4, 3, 0, 11, 8, 1), (9, 10, 5, 6, 7, 2, 3, 4, 11, 0, 1, 8), (9, 10, 7, 4, 0, 5, 6, 1, 2, 11, 8, 3), (9, 10, 7, 4, 5, 0, 1, 6, 11, 2, 3, 8), (9, 10, 11, 8, 0, 2, 3, 1, 5, 7, 4, 6), (9, 10, 11, 8, 2, 0, 1, 3, 7, 5, 6, 4), (10, 9, 1, 0, 4, 8, 11, 7, 3, 6, 5, 2), (10, 9, 1, 0, 8, 4, 7, 11, 6, 3, 2, 5), (10, 9, 3, 2, 6, 8, 11, 5, 1, 4, 7, 0), (10, 9, 3, 2, 8, 6, 5, 11, 4, 1, 0, 7), (10, 9, 4, 7, 1, 6, 5, 0, 3, 8, 11, 2), (10, 9, 4, 7, 6, 1, 0, 5, 8, 3, 2, 11), (10, 9, 6, 5, 3, 4, 7, 2, 1, 8, 11, 0), (10, 9, 6, 5, 4, 3, 2, 7, 8, 1, 0, 11), (10, 9, 8, 11, 1, 3, 2, 0, 6, 4, 7, 5), (10, 9, 8, 11, 3, 1, 0, 2, 4, 6, 5, 7), (11, 8, 1, 0, 5, 9, 10, 6, 3, 7, 4, 2), (11, 8, 1, 0, 9, 5, 6, 10, 7, 3, 2, 4), (11, 8, 3, 2, 7, 9, 10, 4, 1, 5, 6, 0), (11, 8, 3, 2, 9, 7, 4, 10, 5, 1, 0, 6), (11, 8, 5, 6, 1, 7, 4, 0, 3, 9, 10, 2), (11, 8, 5, 6, 7, 1, 0, 4, 9, 3, 2, 10), (11, 8, 7, 4, 3, 5, 6, 2, 1, 9, 10, 0), (11, 8, 7, 4, 5, 3, 2, 6, 9, 1, 0, 10), (11, 8, 9, 10, 1, 3, 2, 0, 7, 5, 6, 4), (11, 8, 9, 10, 3, 1, 0, 2, 5, 7, 4, 6)]\n"
     ]
    }
   ],
   "source": [
    "bonds = [\n",
    "    (0, 2), (0, 4), (0, 5), (0, 8), (0, 9),\n",
    "    (1, 3), (1, 6), (1, 7), (1, 10), (1, 11),\n",
    "    (2, 6), (2, 7), (2, 8), (2, 9), (3, 4),\n",
    "    (3, 5), (3, 10), (3, 11), (4, 5), (4, 8),\n",
    "    (4, 10), (5, 9), (5, 11), (6, 7), (6, 8),\n",
    "    (6, 10), (7, 9), (7, 11), (8, 10), (9, 11)\n",
    "]\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(range(12))\n",
    "G.add_edges_from(bonds)\n",
    "\n",
    "# --- all automorphisms (size 120)\n",
    "GM = nx.algorithms.isomorphism.GraphMatcher(G, G)\n",
    "autos = sorted({tuple(iso[i] for i in range(12)) for iso in GM.isomorphisms_iter()})\n",
    "assert len(autos) == 120, f\"Expected 120 automorphisms, got {len(autos)}\"\n",
    "\n",
    "# --- planar embedding to get a rotation system\n",
    "is_planar, embedding = nx.check_planarity(G, True)\n",
    "assert is_planar\n",
    "\n",
    "def neighbors_cw(v):\n",
    "    # returns the neighbors of v in clockwise order per the embedding\n",
    "    return list(embedding.neighbors_cw_order(v))\n",
    "\n",
    "def is_cyclic_shift(a, b):\n",
    "    # checks if list a is a cyclic rotation of list b (same orientation)\n",
    "    if len(a) != len(b): return False\n",
    "    if not a: return True\n",
    "    try:\n",
    "        i = b.index(a[0])\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return all(a[k] == b[(i + k) % len(b)] for k in range(len(a)))\n",
    "\n",
    "def preserves_rotation_system(p):\n",
    "    # For each vertex v, the image of its CW neighbor list must be a CW cyclic shift\n",
    "    for v in range(12):\n",
    "        src_cw = neighbors_cw(v)\n",
    "        # map neighbors under p\n",
    "        mapped = [p[n] for n in src_cw]\n",
    "        # target cw list at p[v]\n",
    "        tgt_cw = neighbors_cw(p[v])\n",
    "        if not is_cyclic_shift(mapped, tgt_cw):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# --- keep only orientation-preserving automorphisms (the 60 rotations)\n",
    "rotations = [p for p in autos if preserves_rotation_system(p)]\n",
    "assert len(rotations) == 60, f\"Expected 60 rotations, got {len(rotations)}\"\n",
    "\n",
    "# --- inversion: map each vertex to the unique vertex at graph distance 3\n",
    "inv = [-1]*12\n",
    "for v in range(12):\n",
    "    dist = nx.single_source_shortest_path_length(G, v)\n",
    "    opp = [u for u, d in dist.items() if d == 3]\n",
    "    assert len(opp) == 1\n",
    "    inv[v] = opp[0]\n",
    "inv = tuple(inv)\n",
    "assert all(inv[inv[i]] == i for i in range(12))\n",
    "\n",
    "def compose(p, q):\n",
    "    # (p ∘ q)[i] = p[q[i]]\n",
    "    return tuple(p[q[i]] for i in range(12))\n",
    "\n",
    "# --- full I_h = rotations ∪ (inversion ∘ rotations)\n",
    "I_h = {tuple(r) for r in rotations}\n",
    "I_h.update(compose(inv, r) for r in rotations)\n",
    "I_h = sorted(I_h)\n",
    "assert len(I_h) == 120, f\"Expected 120 elements, got {len(I_h)}\"\n",
    "\n",
    "print(\"Rotations:\", len(rotations))\n",
    "print(\"Full I_h:\", len(I_h))\n",
    "print(I_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying element: (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11)\n",
      "Class index: 0\n",
      "Character: 5\n",
      "Classifying element: (0, 1, 2, 3, 5, 4, 7, 6, 9, 8, 11, 10)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (0, 1, 4, 7, 2, 9, 10, 3, 8, 5, 6, 11)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (0, 1, 4, 7, 9, 2, 3, 10, 5, 8, 11, 6)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (0, 1, 5, 6, 2, 8, 11, 3, 9, 4, 7, 10)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (0, 1, 5, 6, 8, 2, 3, 11, 4, 9, 10, 7)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (0, 1, 8, 11, 5, 9, 10, 6, 4, 2, 3, 7)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (0, 1, 8, 11, 9, 5, 6, 10, 2, 4, 7, 3)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (0, 1, 9, 10, 4, 8, 11, 7, 5, 2, 3, 6)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (0, 1, 9, 10, 8, 4, 7, 11, 2, 5, 6, 3)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (1, 0, 3, 2, 6, 7, 4, 5, 10, 11, 8, 9)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (1, 0, 3, 2, 7, 6, 5, 4, 11, 10, 9, 8)\n",
      "Class index: 5\n",
      "Character: 5\n",
      "Classifying element: (1, 0, 6, 5, 3, 11, 8, 2, 10, 7, 4, 9)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (1, 0, 6, 5, 11, 3, 2, 8, 7, 10, 9, 4)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (1, 0, 7, 4, 3, 10, 9, 2, 11, 6, 5, 8)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (1, 0, 7, 4, 10, 3, 2, 9, 6, 11, 8, 5)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (1, 0, 10, 9, 7, 11, 8, 4, 6, 3, 2, 5)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (1, 0, 10, 9, 11, 7, 4, 8, 3, 6, 5, 2)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (1, 0, 11, 8, 6, 10, 9, 5, 7, 3, 2, 4)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (1, 0, 11, 8, 10, 6, 5, 9, 3, 7, 4, 2)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (2, 3, 0, 1, 6, 7, 4, 5, 8, 9, 10, 11)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (2, 3, 0, 1, 7, 6, 5, 4, 9, 8, 11, 10)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (2, 3, 6, 5, 0, 9, 10, 1, 8, 7, 4, 11)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (2, 3, 6, 5, 9, 0, 1, 10, 7, 8, 11, 4)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (2, 3, 7, 4, 0, 8, 11, 1, 9, 6, 5, 10)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (2, 3, 7, 4, 8, 0, 1, 11, 6, 9, 10, 5)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (2, 3, 8, 11, 7, 9, 10, 4, 6, 0, 1, 5)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (2, 3, 8, 11, 9, 7, 4, 10, 0, 6, 5, 1)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (2, 3, 9, 10, 6, 8, 11, 5, 7, 0, 1, 4)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (2, 3, 9, 10, 8, 6, 5, 11, 0, 7, 4, 1)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (3, 2, 1, 0, 4, 5, 6, 7, 10, 11, 8, 9)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (3, 2, 1, 0, 5, 4, 7, 6, 11, 10, 9, 8)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (3, 2, 4, 7, 1, 11, 8, 0, 10, 5, 6, 9)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (3, 2, 4, 7, 11, 1, 0, 8, 5, 10, 9, 6)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (3, 2, 5, 6, 1, 10, 9, 0, 11, 4, 7, 8)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (3, 2, 5, 6, 10, 1, 0, 9, 4, 11, 8, 7)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (3, 2, 10, 9, 5, 11, 8, 6, 4, 1, 0, 7)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (3, 2, 10, 9, 11, 5, 6, 8, 1, 4, 7, 0)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (3, 2, 11, 8, 4, 10, 9, 7, 5, 1, 0, 6)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (3, 2, 11, 8, 10, 4, 7, 9, 1, 5, 6, 0)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (4, 7, 0, 1, 3, 10, 9, 2, 5, 8, 11, 6)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (4, 7, 0, 1, 10, 3, 2, 9, 8, 5, 6, 11)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (4, 7, 3, 2, 0, 8, 11, 1, 5, 10, 9, 6)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (4, 7, 3, 2, 8, 0, 1, 11, 10, 5, 6, 9)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (4, 7, 5, 6, 8, 10, 9, 11, 0, 3, 2, 1)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (4, 7, 5, 6, 10, 8, 11, 9, 3, 0, 1, 2)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (4, 7, 8, 11, 3, 5, 6, 2, 10, 0, 1, 9)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (4, 7, 8, 11, 5, 3, 2, 6, 0, 10, 9, 1)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (4, 7, 10, 9, 0, 5, 6, 1, 8, 3, 2, 11)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (4, 7, 10, 9, 5, 0, 1, 6, 3, 8, 11, 2)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (5, 6, 0, 1, 3, 11, 8, 2, 4, 9, 10, 7)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (5, 6, 0, 1, 11, 3, 2, 8, 9, 4, 7, 10)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (5, 6, 3, 2, 0, 9, 10, 1, 4, 11, 8, 7)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (5, 6, 3, 2, 9, 0, 1, 10, 11, 4, 7, 8)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (5, 6, 4, 7, 9, 11, 8, 10, 0, 3, 2, 1)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (5, 6, 4, 7, 11, 9, 10, 8, 3, 0, 1, 2)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (5, 6, 9, 10, 3, 4, 7, 2, 11, 0, 1, 8)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (5, 6, 9, 10, 4, 3, 2, 7, 0, 11, 8, 1)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (5, 6, 11, 8, 0, 4, 7, 1, 9, 3, 2, 10)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (5, 6, 11, 8, 4, 0, 1, 7, 3, 9, 10, 2)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (6, 5, 1, 0, 2, 8, 11, 3, 7, 10, 9, 4)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (6, 5, 1, 0, 8, 2, 3, 11, 10, 7, 4, 9)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (6, 5, 2, 3, 1, 10, 9, 0, 7, 8, 11, 4)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (6, 5, 2, 3, 10, 1, 0, 9, 8, 7, 4, 11)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (6, 5, 7, 4, 8, 10, 9, 11, 2, 1, 0, 3)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (6, 5, 7, 4, 10, 8, 11, 9, 1, 2, 3, 0)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (6, 5, 8, 11, 1, 7, 4, 0, 10, 2, 3, 9)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (6, 5, 8, 11, 7, 1, 0, 4, 2, 10, 9, 3)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (6, 5, 10, 9, 2, 7, 4, 3, 8, 1, 0, 11)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (6, 5, 10, 9, 7, 2, 3, 4, 1, 8, 11, 0)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (7, 4, 1, 0, 2, 9, 10, 3, 6, 11, 8, 5)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (7, 4, 1, 0, 9, 2, 3, 10, 11, 6, 5, 8)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (7, 4, 2, 3, 1, 11, 8, 0, 6, 9, 10, 5)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (7, 4, 2, 3, 11, 1, 0, 8, 9, 6, 5, 10)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (7, 4, 6, 5, 9, 11, 8, 10, 2, 1, 0, 3)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (7, 4, 6, 5, 11, 9, 10, 8, 1, 2, 3, 0)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (7, 4, 9, 10, 1, 6, 5, 0, 11, 2, 3, 8)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (7, 4, 9, 10, 6, 1, 0, 5, 2, 11, 8, 3)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (7, 4, 11, 8, 2, 6, 5, 3, 9, 1, 0, 10)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (7, 4, 11, 8, 6, 2, 3, 5, 1, 9, 10, 0)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (8, 11, 0, 1, 6, 10, 9, 5, 2, 4, 7, 3)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (8, 11, 0, 1, 10, 6, 5, 9, 4, 2, 3, 7)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (8, 11, 2, 3, 4, 10, 9, 7, 0, 6, 5, 1)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (8, 11, 2, 3, 10, 4, 7, 9, 6, 0, 1, 5)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (8, 11, 4, 7, 2, 6, 5, 3, 0, 10, 9, 1)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (8, 11, 4, 7, 6, 2, 3, 5, 10, 0, 1, 9)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (8, 11, 6, 5, 0, 4, 7, 1, 2, 10, 9, 3)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (8, 11, 6, 5, 4, 0, 1, 7, 10, 2, 3, 9)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (8, 11, 10, 9, 0, 2, 3, 1, 4, 6, 5, 7)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (8, 11, 10, 9, 2, 0, 1, 3, 6, 4, 7, 5)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (9, 10, 0, 1, 7, 11, 8, 4, 2, 5, 6, 3)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (9, 10, 0, 1, 11, 7, 4, 8, 5, 2, 3, 6)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (9, 10, 2, 3, 5, 11, 8, 6, 0, 7, 4, 1)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (9, 10, 2, 3, 11, 5, 6, 8, 7, 0, 1, 4)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (9, 10, 5, 6, 2, 7, 4, 3, 0, 11, 8, 1)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (9, 10, 5, 6, 7, 2, 3, 4, 11, 0, 1, 8)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (9, 10, 7, 4, 0, 5, 6, 1, 2, 11, 8, 3)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (9, 10, 7, 4, 5, 0, 1, 6, 11, 2, 3, 8)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (9, 10, 11, 8, 0, 2, 3, 1, 5, 7, 4, 6)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (9, 10, 11, 8, 2, 0, 1, 3, 7, 5, 6, 4)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (10, 9, 1, 0, 4, 8, 11, 7, 3, 6, 5, 2)\n",
      "Class index: 3\n",
      "Character: 0\n",
      "Classifying element: (10, 9, 1, 0, 8, 4, 7, 11, 6, 3, 2, 5)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (10, 9, 3, 2, 6, 8, 11, 5, 1, 4, 7, 0)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (10, 9, 3, 2, 8, 6, 5, 11, 4, 1, 0, 7)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (10, 9, 4, 7, 1, 6, 5, 0, 3, 8, 11, 2)\n",
      "Class index: 9\n",
      "Character: 0\n",
      "Classifying element: (10, 9, 4, 7, 6, 1, 0, 5, 8, 3, 2, 11)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (10, 9, 6, 5, 3, 4, 7, 2, 1, 8, 11, 0)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (10, 9, 6, 5, 4, 3, 2, 7, 8, 1, 0, 11)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (10, 9, 8, 11, 1, 3, 2, 0, 6, 4, 7, 5)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (10, 9, 8, 11, 3, 1, 0, 2, 4, 6, 5, 7)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (11, 8, 1, 0, 5, 9, 10, 6, 3, 7, 4, 2)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (11, 8, 1, 0, 9, 5, 6, 10, 7, 3, 2, 4)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (11, 8, 3, 2, 7, 9, 10, 4, 1, 5, 6, 0)\n",
      "Class index: 1\n",
      "Character: 1\n",
      "Classifying element: (11, 8, 3, 2, 9, 7, 4, 10, 5, 1, 0, 6)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (11, 8, 5, 6, 1, 7, 4, 0, 3, 9, 10, 2)\n",
      "Class index: 4\n",
      "Character: 0\n",
      "Classifying element: (11, 8, 5, 6, 7, 1, 0, 4, 9, 3, 2, 10)\n",
      "Class index: 8\n",
      "Character: 0\n",
      "Classifying element: (11, 8, 7, 4, 3, 5, 6, 2, 1, 9, 10, 0)\n",
      "Class index: 6\n",
      "Character: 1\n",
      "Classifying element: (11, 8, 7, 4, 5, 3, 2, 6, 9, 1, 0, 10)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "Classifying element: (11, 8, 9, 10, 1, 3, 2, 0, 7, 5, 6, 4)\n",
      "Class index: 7\n",
      "Character: -1\n",
      "Classifying element: (11, 8, 9, 10, 3, 1, 0, 2, 5, 7, 4, 6)\n",
      "Class index: 2\n",
      "Character: -1\n",
      "||P_Hg^2 - P_Hg|| = 8.427828685313985e-16\n",
      "||P_Hg - P_Hg†|| = 0.0\n",
      "Tr(P_Hg) = 5.0\n"
     ]
    }
   ],
   "source": [
    "# size of group\n",
    "G_size = 120\n",
    "d_Hg = 5\n",
    "\n",
    "# characters of H_g by class (ordered as above)\n",
    "chi_Hg = [5, 1, -1, 0, 0, 5, 1, -1, 0, 0]\n",
    "\n",
    "# number of elements in each class\n",
    "class_sizes = [1, 15, 20, 12, 12, 1, 15, 20, 12, 12]\n",
    "\n",
    "# function that assigns each permutation g to class index 0..9\n",
    "# (you must implement this, e.g., by checking rotation order or parity)\n",
    "def classify_element(perm):\n",
    "    \n",
    "    #Classify a group element (as a tuple/list of 12 ints) into one of the 10 conjugacy classes of Ih.\n",
    "    #Returns an integer 0..9 (class index).\n",
    "    \n",
    "    # Identity\n",
    "    if tuple(perm) == tuple(range(12)):\n",
    "        return 0\n",
    "\n",
    "    # Inversion\n",
    "    if tuple(perm) == inv:\n",
    "        return 5\n",
    "\n",
    "    # Is it a pure rotation?\n",
    "    is_rotation = perm in rotations\n",
    "\n",
    "    # Compose with inversion to check if it's inversion * rotation\n",
    "    is_inverted = False\n",
    "    if not is_rotation:\n",
    "        for r in rotations:\n",
    "            if tuple(perm) == tuple(inv[r[i]] for i in range(12)):\n",
    "                is_inverted = True\n",
    "                underlying_rot = r\n",
    "                break\n",
    "\n",
    "    # Helper: get order and cycle structure\n",
    "    def perm_cycles(p):\n",
    "        seen = [False]*12\n",
    "        cycles = []\n",
    "        for i in range(12):\n",
    "            if not seen[i]:\n",
    "                j = i\n",
    "                cycle = []\n",
    "                while not seen[j]:\n",
    "                    seen[j] = True\n",
    "                    cycle.append(j)\n",
    "                    j = p[j]\n",
    "                if len(cycle) > 1:\n",
    "                    cycles.append(tuple(cycle))\n",
    "        return cycles\n",
    "\n",
    "    def perm_order(p):\n",
    "        from math import lcm\n",
    "        cycles = perm_cycles(p)\n",
    "        order = 1\n",
    "        for cyc in cycles:\n",
    "            order = lcm(order, len(cyc))\n",
    "        return order\n",
    "\n",
    "    # Classify by order and type\n",
    "    if is_rotation:\n",
    "        order = perm_order(perm)\n",
    "        cycles = perm_cycles(perm)\n",
    "        if order == 2:\n",
    "            return 1\n",
    "        elif order == 3:\n",
    "            return 2\n",
    "        elif order == 5:\n",
    "            # Two types: distinguished by which vertices are fixed\n",
    "            fixed = [i for i in range(12) if perm[i] == i]\n",
    "            # Each 5-fold rotation fixes 2 points\n",
    "            # The set of fixed points distinguishes the type\n",
    "            # Let's sort and use the tuple as a key\n",
    "            # Build a list of all such fixed point pairs for all 5-fold rotations\n",
    "            # The first 12 unique pairs are type 1, the next 12 are type 2\n",
    "            # So, build a sorted list of all fixed pairs\n",
    "            all_5folds = [p for p in rotations if perm_order(p) == 5]\n",
    "            fixed_pairs = sorted([tuple(sorted([i for i in range(12) if p[i] == i])) for p in all_5folds])\n",
    "            my_pair = tuple(sorted(fixed))\n",
    "            idx = fixed_pairs.index(my_pair)\n",
    "            return 3 if idx < 12 else 4\n",
    "    elif is_inverted:\n",
    "        order = perm_order(underlying_rot)\n",
    "        cycles = perm_cycles(underlying_rot)\n",
    "        if order == 2:\n",
    "            return 6\n",
    "        elif order == 3:\n",
    "            return 7\n",
    "        elif order == 5:\n",
    "            fixed = [i for i in range(12) if underlying_rot[i] == i]\n",
    "            all_5folds = [p for p in rotations if perm_order(p) == 5]\n",
    "            fixed_pairs = sorted([tuple(sorted([i for i in range(12) if p[i] == i])) for p in all_5folds])\n",
    "            my_pair = tuple(sorted(fixed))\n",
    "            idx = fixed_pairs.index(my_pair)\n",
    "            return 8 if idx < 12 else 9\n",
    "\n",
    "    raise ValueError(\"Permutation does not match any known class.\")\n",
    "\n",
    "\n",
    "# your D(g): representation on Hilbert space\n",
    "def D(perm):\n",
    "    # for example, permutation matrix acting on 12 sites\n",
    "    mat = np.zeros((12,12))\n",
    "    for i in range(12):\n",
    "        mat[perm[i], i] = 1.0\n",
    "  \n",
    "    return mat  \n",
    "\n",
    "# --- build projector\n",
    "P_Hg = np.zeros((12,12))\n",
    "for g in I_h:\n",
    "    print(\"Classifying element:\", g)\n",
    "    class_idx = classify_element(g)\n",
    "    print(\"Class index:\", class_idx)\n",
    "    print(\"Character:\", chi_Hg[class_idx])\n",
    "    P_Hg += np.conjugate(chi_Hg[class_idx]) * D(g)\n",
    "\n",
    "P_Hg *= d_Hg / G_size\n",
    "\n",
    "print(\"||P_Hg^2 - P_Hg|| =\", np.linalg.norm(P_Hg @ P_Hg - P_Hg))\n",
    "print(\"||P_Hg - P_Hg†|| =\", np.linalg.norm(P_Hg - P_Hg.conj().T))\n",
    "print(\"Tr(P_Hg) =\", np.trace(P_Hg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element index | Permutation | Class index | Class label\n",
      "  0 | (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11) | 0 | Identity\n",
      "  1 | (0, 1, 2, 3, 5, 4, 7, 6, 9, 8, 11, 10) | 6 | C2*inv\n",
      "  2 | (0, 1, 4, 7, 2, 9, 10, 3, 8, 5, 6, 11) | 6 | C2*inv\n",
      "  3 | (0, 1, 4, 7, 9, 2, 3, 10, 5, 8, 11, 6) | 3 | C5 (5-fold rotation, type 1)\n",
      "  4 | (0, 1, 5, 6, 2, 8, 11, 3, 9, 4, 7, 10) | 3 | C5 (5-fold rotation, type 1)\n",
      "  5 | (0, 1, 5, 6, 8, 2, 3, 11, 4, 9, 10, 7) | 6 | C2*inv\n",
      "  6 | (0, 1, 8, 11, 5, 9, 10, 6, 4, 2, 3, 7) | 3 | C5 (5-fold rotation, type 1)\n",
      "  7 | (0, 1, 8, 11, 9, 5, 6, 10, 2, 4, 7, 3) | 6 | C2*inv\n",
      "  8 | (0, 1, 9, 10, 4, 8, 11, 7, 5, 2, 3, 6) | 6 | C2*inv\n",
      "  9 | (0, 1, 9, 10, 8, 4, 7, 11, 2, 5, 6, 3) | 3 | C5 (5-fold rotation, type 1)\n",
      " 10 | (1, 0, 3, 2, 6, 7, 4, 5, 10, 11, 8, 9) | 1 | C2 (2-fold rotation)\n",
      " 11 | (1, 0, 3, 2, 7, 6, 5, 4, 11, 10, 9, 8) | 5 | Inversion\n",
      " 12 | (1, 0, 6, 5, 3, 11, 8, 2, 10, 7, 4, 9) | 8 | C5*inv (type 1)\n",
      " 13 | (1, 0, 6, 5, 11, 3, 2, 8, 7, 10, 9, 4) | 1 | C2 (2-fold rotation)\n",
      " 14 | (1, 0, 7, 4, 3, 10, 9, 2, 11, 6, 5, 8) | 1 | C2 (2-fold rotation)\n",
      " 15 | (1, 0, 7, 4, 10, 3, 2, 9, 6, 11, 8, 5) | 8 | C5*inv (type 1)\n",
      " 16 | (1, 0, 10, 9, 7, 11, 8, 4, 6, 3, 2, 5) | 1 | C2 (2-fold rotation)\n",
      " 17 | (1, 0, 10, 9, 11, 7, 4, 8, 3, 6, 5, 2) | 8 | C5*inv (type 1)\n",
      " 18 | (1, 0, 11, 8, 6, 10, 9, 5, 7, 3, 2, 4) | 8 | C5*inv (type 1)\n",
      " 19 | (1, 0, 11, 8, 10, 6, 5, 9, 3, 7, 4, 2) | 1 | C2 (2-fold rotation)\n",
      " 20 | (2, 3, 0, 1, 6, 7, 4, 5, 8, 9, 10, 11) | 6 | C2*inv\n",
      " 21 | (2, 3, 0, 1, 7, 6, 5, 4, 9, 8, 11, 10) | 1 | C2 (2-fold rotation)\n",
      " 22 | (2, 3, 6, 5, 0, 9, 10, 1, 8, 7, 4, 11) | 4 | C5 (5-fold rotation, type 2)\n",
      " 23 | (2, 3, 6, 5, 9, 0, 1, 10, 7, 8, 11, 4) | 7 | C3*inv\n",
      " 24 | (2, 3, 7, 4, 0, 8, 11, 1, 9, 6, 5, 10) | 7 | C3*inv\n",
      " 25 | (2, 3, 7, 4, 8, 0, 1, 11, 6, 9, 10, 5) | 4 | C5 (5-fold rotation, type 2)\n",
      " 26 | (2, 3, 8, 11, 7, 9, 10, 4, 6, 0, 1, 5) | 8 | C5*inv (type 1)\n",
      " 27 | (2, 3, 8, 11, 9, 7, 4, 10, 0, 6, 5, 1) | 2 | C3 (3-fold rotation)\n",
      " 28 | (2, 3, 9, 10, 6, 8, 11, 5, 7, 0, 1, 4) | 2 | C3 (3-fold rotation)\n",
      " 29 | (2, 3, 9, 10, 8, 6, 5, 11, 0, 7, 4, 1) | 9 | C5*inv (type 2)\n",
      " 30 | (3, 2, 1, 0, 4, 5, 6, 7, 10, 11, 8, 9) | 6 | C2*inv\n",
      " 31 | (3, 2, 1, 0, 5, 4, 7, 6, 11, 10, 9, 8) | 1 | C2 (2-fold rotation)\n",
      " 32 | (3, 2, 4, 7, 1, 11, 8, 0, 10, 5, 6, 9) | 2 | C3 (3-fold rotation)\n",
      " 33 | (3, 2, 4, 7, 11, 1, 0, 8, 5, 10, 9, 6) | 9 | C5*inv (type 2)\n",
      " 34 | (3, 2, 5, 6, 1, 10, 9, 0, 11, 4, 7, 8) | 9 | C5*inv (type 2)\n",
      " 35 | (3, 2, 5, 6, 10, 1, 0, 9, 4, 11, 8, 7) | 2 | C3 (3-fold rotation)\n",
      " 36 | (3, 2, 10, 9, 5, 11, 8, 6, 4, 1, 0, 7) | 7 | C3*inv\n",
      " 37 | (3, 2, 10, 9, 11, 5, 6, 8, 1, 4, 7, 0) | 4 | C5 (5-fold rotation, type 2)\n",
      " 38 | (3, 2, 11, 8, 4, 10, 9, 7, 5, 1, 0, 6) | 3 | C5 (5-fold rotation, type 1)\n",
      " 39 | (3, 2, 11, 8, 10, 4, 7, 9, 1, 5, 6, 0) | 7 | C3*inv\n",
      " 40 | (4, 7, 0, 1, 3, 10, 9, 2, 5, 8, 11, 6) | 7 | C3*inv\n",
      " 41 | (4, 7, 0, 1, 10, 3, 2, 9, 8, 5, 6, 11) | 4 | C5 (5-fold rotation, type 2)\n",
      " 42 | (4, 7, 3, 2, 0, 8, 11, 1, 5, 10, 9, 6) | 1 | C2 (2-fold rotation)\n",
      " 43 | (4, 7, 3, 2, 8, 0, 1, 11, 10, 5, 6, 9) | 8 | C5*inv (type 1)\n",
      " 44 | (4, 7, 5, 6, 8, 10, 9, 11, 0, 3, 2, 1) | 2 | C3 (3-fold rotation)\n",
      " 45 | (4, 7, 5, 6, 10, 8, 11, 9, 3, 0, 1, 2) | 7 | C3*inv\n",
      " 46 | (4, 7, 8, 11, 3, 5, 6, 2, 10, 0, 1, 9) | 4 | C5 (5-fold rotation, type 2)\n",
      " 47 | (4, 7, 8, 11, 5, 3, 2, 6, 0, 10, 9, 1) | 9 | C5*inv (type 2)\n",
      " 48 | (4, 7, 10, 9, 0, 5, 6, 1, 8, 3, 2, 11) | 6 | C2*inv\n",
      " 49 | (4, 7, 10, 9, 5, 0, 1, 6, 3, 8, 11, 2) | 2 | C3 (3-fold rotation)\n",
      " 50 | (5, 6, 0, 1, 3, 11, 8, 2, 4, 9, 10, 7) | 4 | C5 (5-fold rotation, type 2)\n",
      " 51 | (5, 6, 0, 1, 11, 3, 2, 8, 9, 4, 7, 10) | 7 | C3*inv\n",
      " 52 | (5, 6, 3, 2, 0, 9, 10, 1, 4, 11, 8, 7) | 8 | C5*inv (type 1)\n",
      " 53 | (5, 6, 3, 2, 9, 0, 1, 10, 11, 4, 7, 8) | 1 | C2 (2-fold rotation)\n",
      " 54 | (5, 6, 4, 7, 9, 11, 8, 10, 0, 3, 2, 1) | 7 | C3*inv\n",
      " 55 | (5, 6, 4, 7, 11, 9, 10, 8, 3, 0, 1, 2) | 2 | C3 (3-fold rotation)\n",
      " 56 | (5, 6, 9, 10, 3, 4, 7, 2, 11, 0, 1, 8) | 9 | C5*inv (type 2)\n",
      " 57 | (5, 6, 9, 10, 4, 3, 2, 7, 0, 11, 8, 1) | 3 | C5 (5-fold rotation, type 1)\n",
      " 58 | (5, 6, 11, 8, 0, 4, 7, 1, 9, 3, 2, 10) | 2 | C3 (3-fold rotation)\n",
      " 59 | (5, 6, 11, 8, 4, 0, 1, 7, 3, 9, 10, 2) | 6 | C2*inv\n",
      " 60 | (6, 5, 1, 0, 2, 8, 11, 3, 7, 10, 9, 4) | 9 | C5*inv (type 2)\n",
      " 61 | (6, 5, 1, 0, 8, 2, 3, 11, 10, 7, 4, 9) | 2 | C3 (3-fold rotation)\n",
      " 62 | (6, 5, 2, 3, 1, 10, 9, 0, 7, 8, 11, 4) | 3 | C5 (5-fold rotation, type 1)\n",
      " 63 | (6, 5, 2, 3, 10, 1, 0, 9, 8, 7, 4, 11) | 6 | C2*inv\n",
      " 64 | (6, 5, 7, 4, 8, 10, 9, 11, 2, 1, 0, 3) | 7 | C3*inv\n",
      " 65 | (6, 5, 7, 4, 10, 8, 11, 9, 1, 2, 3, 0) | 2 | C3 (3-fold rotation)\n",
      " 66 | (6, 5, 8, 11, 1, 7, 4, 0, 10, 2, 3, 9) | 7 | C3*inv\n",
      " 67 | (6, 5, 8, 11, 7, 1, 0, 4, 2, 10, 9, 3) | 1 | C2 (2-fold rotation)\n",
      " 68 | (6, 5, 10, 9, 2, 7, 4, 3, 8, 1, 0, 11) | 4 | C5 (5-fold rotation, type 2)\n",
      " 69 | (6, 5, 10, 9, 7, 2, 3, 4, 1, 8, 11, 0) | 8 | C5*inv (type 1)\n",
      " 70 | (7, 4, 1, 0, 2, 9, 10, 3, 6, 11, 8, 5) | 2 | C3 (3-fold rotation)\n",
      " 71 | (7, 4, 1, 0, 9, 2, 3, 10, 11, 6, 5, 8) | 9 | C5*inv (type 2)\n",
      " 72 | (7, 4, 2, 3, 1, 11, 8, 0, 6, 9, 10, 5) | 6 | C2*inv\n",
      " 73 | (7, 4, 2, 3, 11, 1, 0, 8, 9, 6, 5, 10) | 3 | C5 (5-fold rotation, type 1)\n",
      " 74 | (7, 4, 6, 5, 9, 11, 8, 10, 2, 1, 0, 3) | 2 | C3 (3-fold rotation)\n",
      " 75 | (7, 4, 6, 5, 11, 9, 10, 8, 1, 2, 3, 0) | 7 | C3*inv\n",
      " 76 | (7, 4, 9, 10, 1, 6, 5, 0, 11, 2, 3, 8) | 1 | C2 (2-fold rotation)\n",
      " 77 | (7, 4, 9, 10, 6, 1, 0, 5, 2, 11, 8, 3) | 7 | C3*inv\n",
      " 78 | (7, 4, 11, 8, 2, 6, 5, 3, 9, 1, 0, 10) | 9 | C5*inv (type 2)\n",
      " 79 | (7, 4, 11, 8, 6, 2, 3, 5, 1, 9, 10, 0) | 4 | C5 (5-fold rotation, type 2)\n",
      " 80 | (8, 11, 0, 1, 6, 10, 9, 5, 2, 4, 7, 3) | 2 | C3 (3-fold rotation)\n",
      " 81 | (8, 11, 0, 1, 10, 6, 5, 9, 4, 2, 3, 7) | 9 | C5*inv (type 2)\n",
      " 82 | (8, 11, 2, 3, 4, 10, 9, 7, 0, 6, 5, 1) | 6 | C2*inv\n",
      " 83 | (8, 11, 2, 3, 10, 4, 7, 9, 6, 0, 1, 5) | 3 | C5 (5-fold rotation, type 1)\n",
      " 84 | (8, 11, 4, 7, 2, 6, 5, 3, 0, 10, 9, 1) | 1 | C2 (2-fold rotation)\n",
      " 85 | (8, 11, 4, 7, 6, 2, 3, 5, 10, 0, 1, 9) | 7 | C3*inv\n",
      " 86 | (8, 11, 6, 5, 0, 4, 7, 1, 2, 10, 9, 3) | 9 | C5*inv (type 2)\n",
      " 87 | (8, 11, 6, 5, 4, 0, 1, 7, 10, 2, 3, 9) | 3 | C5 (5-fold rotation, type 1)\n",
      " 88 | (8, 11, 10, 9, 0, 2, 3, 1, 4, 6, 5, 7) | 2 | C3 (3-fold rotation)\n",
      " 89 | (8, 11, 10, 9, 2, 0, 1, 3, 6, 4, 7, 5) | 7 | C3*inv\n",
      " 90 | (9, 10, 0, 1, 7, 11, 8, 4, 2, 5, 6, 3) | 8 | C5*inv (type 1)\n",
      " 91 | (9, 10, 0, 1, 11, 7, 4, 8, 5, 2, 3, 6) | 2 | C3 (3-fold rotation)\n",
      " 92 | (9, 10, 2, 3, 5, 11, 8, 6, 0, 7, 4, 1) | 3 | C5 (5-fold rotation, type 1)\n",
      " 93 | (9, 10, 2, 3, 11, 5, 6, 8, 7, 0, 1, 4) | 6 | C2*inv\n",
      " 94 | (9, 10, 5, 6, 2, 7, 4, 3, 0, 11, 8, 1) | 7 | C3*inv\n",
      " 95 | (9, 10, 5, 6, 7, 2, 3, 4, 11, 0, 1, 8) | 1 | C2 (2-fold rotation)\n",
      " 96 | (9, 10, 7, 4, 0, 5, 6, 1, 2, 11, 8, 3) | 4 | C5 (5-fold rotation, type 2)\n",
      " 97 | (9, 10, 7, 4, 5, 0, 1, 6, 11, 2, 3, 8) | 9 | C5*inv (type 2)\n",
      " 98 | (9, 10, 11, 8, 0, 2, 3, 1, 5, 7, 4, 6) | 7 | C3*inv\n",
      " 99 | (9, 10, 11, 8, 2, 0, 1, 3, 7, 5, 6, 4) | 2 | C3 (3-fold rotation)\n",
      "100 | (10, 9, 1, 0, 4, 8, 11, 7, 3, 6, 5, 2) | 3 | C5 (5-fold rotation, type 1)\n",
      "101 | (10, 9, 1, 0, 8, 4, 7, 11, 6, 3, 2, 5) | 7 | C3*inv\n",
      "102 | (10, 9, 3, 2, 6, 8, 11, 5, 1, 4, 7, 0) | 8 | C5*inv (type 1)\n",
      "103 | (10, 9, 3, 2, 8, 6, 5, 11, 4, 1, 0, 7) | 1 | C2 (2-fold rotation)\n",
      "104 | (10, 9, 4, 7, 1, 6, 5, 0, 3, 8, 11, 2) | 9 | C5*inv (type 2)\n",
      "105 | (10, 9, 4, 7, 6, 1, 0, 5, 8, 3, 2, 11) | 4 | C5 (5-fold rotation, type 2)\n",
      "106 | (10, 9, 6, 5, 3, 4, 7, 2, 1, 8, 11, 0) | 2 | C3 (3-fold rotation)\n",
      "107 | (10, 9, 6, 5, 4, 3, 2, 7, 8, 1, 0, 11) | 6 | C2*inv\n",
      "108 | (10, 9, 8, 11, 1, 3, 2, 0, 6, 4, 7, 5) | 2 | C3 (3-fold rotation)\n",
      "109 | (10, 9, 8, 11, 3, 1, 0, 2, 4, 6, 5, 7) | 7 | C3*inv\n",
      "110 | (11, 8, 1, 0, 5, 9, 10, 6, 3, 7, 4, 2) | 7 | C3*inv\n",
      "111 | (11, 8, 1, 0, 9, 5, 6, 10, 7, 3, 2, 4) | 4 | C5 (5-fold rotation, type 2)\n",
      "112 | (11, 8, 3, 2, 7, 9, 10, 4, 1, 5, 6, 0) | 1 | C2 (2-fold rotation)\n",
      "113 | (11, 8, 3, 2, 9, 7, 4, 10, 5, 1, 0, 6) | 8 | C5*inv (type 1)\n",
      "114 | (11, 8, 5, 6, 1, 7, 4, 0, 3, 9, 10, 2) | 4 | C5 (5-fold rotation, type 2)\n",
      "115 | (11, 8, 5, 6, 7, 1, 0, 4, 9, 3, 2, 10) | 8 | C5*inv (type 1)\n",
      "116 | (11, 8, 7, 4, 3, 5, 6, 2, 1, 9, 10, 0) | 6 | C2*inv\n",
      "117 | (11, 8, 7, 4, 5, 3, 2, 6, 9, 1, 0, 10) | 2 | C3 (3-fold rotation)\n",
      "118 | (11, 8, 9, 10, 1, 3, 2, 0, 7, 5, 6, 4) | 7 | C3*inv\n",
      "119 | (11, 8, 9, 10, 3, 1, 0, 2, 5, 7, 4, 6) | 2 | C3 (3-fold rotation)\n",
      "Class 0 (Identity): 1 elements\n",
      "Class 1 (C2 (2-fold rotation)): 15 elements\n",
      "Class 2 (C3 (3-fold rotation)): 20 elements\n",
      "Class 3 (C5 (5-fold rotation, type 1)): 12 elements\n",
      "Class 4 (C5 (5-fold rotation, type 2)): 12 elements\n",
      "Class 5 (Inversion): 1 elements\n",
      "Class 6 (C2*inv): 15 elements\n",
      "Class 7 (C3*inv): 20 elements\n",
      "Class 8 (C5*inv (type 1)): 12 elements\n",
      "Class 9 (C5*inv (type 2)): 12 elements\n"
     ]
    }
   ],
   "source": [
    "# Human-readable class names (optional)\n",
    "class_labels = [\n",
    "    \"Identity\",\n",
    "    \"C2 (2-fold rotation)\",\n",
    "    \"C3 (3-fold rotation)\",\n",
    "    \"C5 (5-fold rotation, type 1)\",\n",
    "    \"C5 (5-fold rotation, type 2)\",\n",
    "    \"Inversion\",\n",
    "    \"C2*inv\",\n",
    "    \"C3*inv\",\n",
    "    \"C5*inv (type 1)\",\n",
    "    \"C5*inv (type 2)\"\n",
    "]\n",
    "\n",
    "print(\"Element index | Permutation | Class index | Class label\")\n",
    "for idx, g in enumerate(I_h):\n",
    "    class_idx = classify_element(g)\n",
    "    print(f\"{idx:3d} | {g} | {class_idx} | {class_labels[class_idx]}\")\n",
    "\n",
    "class_indices = [classify_element(g) for g in I_h]\n",
    "counts = Counter(class_indices)\n",
    "for idx, count in sorted(counts.items()):\n",
    "    print(f\"Class {idx} ({class_labels[idx]}): {count} elements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauli_x():\n",
    "    \"\"\"Pauli X matrix.\"\"\"\n",
    "    return np.array([[0, 1], [1, 0]])\n",
    "\n",
    "def pauli_z():\n",
    "    \"\"\"Pauli Z matrix.\"\"\"\n",
    "    return np.array([[1, 0], [0, -1]])\n",
    "\n",
    "def icosahedral_bonds():\n",
    "    \n",
    "    bonds = [\n",
    "        (0, 2), (0, 4), (0, 5), (0, 8), (0, 9),\n",
    "        (1, 3), (1, 6), (1, 7), (1, 10), (1, 11),\n",
    "        (2, 6), (2, 7), (2, 8), (2, 9), (3, 4),\n",
    "        (3, 5), (3, 10), (3, 11), (4, 5), (4, 8),\n",
    "        (4, 10), (5, 9), (5, 11), (6, 7), (6, 8),\n",
    "        (6, 10), (7, 9), (7, 11), (8, 10), (9, 11)\n",
    "    ]\n",
    "    return bonds\n",
    "\n",
    "def transverse_field_ising_icosahedral(N, J, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an icosahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the icosahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 12:\n",
    "        raise ValueError(\"Icosahedral molecules typically have N = 12 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get icosahedral bonds\n",
    "    bonds = icosahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for icosahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def ising_icosahedron(N, J):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an icosahedral molecular structure without transverse field.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the icosahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        \"\"\"\n",
    "    if N != 12:\n",
    "        raise ValueError(\"Icosahedral molecules typically have N = 12 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    X = csr_matrix(pauli_x())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get icosahedral bonds\n",
    "    bonds = icosahedral_bonds()\n",
    "    \n",
    "    # Interaction term: J * sigma_i^x * sigma_j^x for icosahedral connectivity\n",
    "    for i, j in bonds:\n",
    "        term = 1\n",
    "        for k in range(N):\n",
    "            if k == i or k == j:\n",
    "                term = kron(term, X, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += J * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "def transverse_field_icosahedral(N, h):\n",
    "    \"\"\"\n",
    "    Constructs the Hamiltonian for the transverse field Ising model on an icosahedral molecular structure.\n",
    "    \n",
    "    Parameters:\n",
    "        N (int): Number of spins (should match the icosahedral molecule, typically N=20).\n",
    "        J (float): Interaction strength.\n",
    "        h (float): Transverse field strength.\n",
    "    \n",
    "    Returns:\n",
    "        H (scipy.sparse.csr_matrix): The Hamiltonian matrix in sparse format.\n",
    "    \"\"\"\n",
    "    if N != 12:\n",
    "        raise ValueError(\"Icosahedral molecules typically have N = 12 sites.\")\n",
    "\n",
    "    # Sparse identity matrix\n",
    "    I = identity(2, format=\"csr\")\n",
    "    \n",
    "    # Pauli matrices as sparse matrices\n",
    "    Z = csr_matrix(pauli_z())\n",
    "    \n",
    "    # Initialize the Hamiltonian\n",
    "    H = csr_matrix((2**N, 2**N), dtype=np.float64)\n",
    "    \n",
    "    # Get icosahedral bonds\n",
    "    bonds = icosahedral_bonds()\n",
    "    \n",
    "    # Transverse field term: -h * sigma_i^z\n",
    "    for i in range(N):\n",
    "        term = 1\n",
    "        for j in range(N):\n",
    "            if j == i:\n",
    "                term = kron(term, Z, format=\"csr\")\n",
    "            else:\n",
    "                term = kron(term, I, format=\"csr\")\n",
    "        H += -h * term\n",
    "    \n",
    "    return H\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "'''\n",
    "def partial_trace_qubit(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits.\"\"\"\n",
    "    keep_dims = np.prod([dims[i] for i in keep])\n",
    "    trace_dims = np.prod([dims[i] for i in range(len(dims)) if i not in keep])\n",
    "    rho = rho.reshape([keep_dims, trace_dims, keep_dims, trace_dims])\n",
    "    return np.trace(rho, axis1=1, axis2=3).reshape([keep_dims, keep_dims])\n",
    "\n",
    "def partial_trace_qubit_torch(rho, keep, dims):\n",
    "    \"\"\"Compute the partial trace of a density matrix of qubits using PyTorch.\"\"\"\n",
    "    keep_dims = torch.prod(torch.tensor([dims[i] for i in keep]))\n",
    "    trace_dims = torch.prod(torch.tensor([dims[i] for i in range(len(dims)) if i not in keep]))\n",
    "    rho = rho.view(keep_dims, trace_dims, keep_dims, trace_dims)\n",
    "    # Compute the partial trace\n",
    "    traced_rho = torch.zeros((keep_dims, keep_dims), dtype=rho.dtype)\n",
    "    for i in range(trace_dims):\n",
    "        traced_rho += rho[:, i, :, i]\n",
    "    #return traced_rho.view(keep_dims, keep_dims)\n",
    "    return traced_rho'''\n",
    "\n",
    "def isket_numpy(arr):\n",
    "    \"\"\"\n",
    "    Check if a NumPy array is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: np.ndarray, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(\"Input must be a NumPy array\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_numpy(Q, sel, dims): # numpy function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using NumPy.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: numpy object, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - numpy object, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = np.asarray(dims[0], dtype=np.int32).ravel()\n",
    "    nd = len(rd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = np.array([sel])\n",
    "    else:\n",
    "        sel = np.asarray(sel)\n",
    "    sel = list(np.sort(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = (rd[sel]).tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(np.arange(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = (rd[qtrace]).tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = list(rd)\n",
    "    if isket_numpy(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        vmat = (Q\n",
    "                .reshape(rd)\n",
    "                .transpose(sel + qtrace)\n",
    "                .reshape([np.prod(dkeep), np.prod(dtrace)]))\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat.dot(vmat.conj().T)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        rhomat = np.trace(Q\n",
    "                          .reshape(rd + rd)\n",
    "                          .transpose(qtrace + [nd + q for q in qtrace] +\n",
    "                                     sel + [nd + q for q in sel])\n",
    "                          .reshape([np.prod(dtrace),\n",
    "                                    np.prod(dtrace),\n",
    "                                    np.prod(dkeep),\n",
    "                                    np.prod(dkeep)]))\n",
    "    return rhomat\n",
    "\n",
    "\n",
    "def ptrace_sparse(psi_sparse, keep, dims):\n",
    "    \"\"\"\n",
    "    Compute the partial trace over arbitrary subsystems using sparse matrix operations.\n",
    "\n",
    "    Args:\n",
    "        psi_sparse (scipy.sparse matrix): Full density matrix of shape (D, D), where D = product(dims)\n",
    "        keep (list of int): Subsystems to keep (indices, 0-indexed)\n",
    "        dims (list of int): List of subsystem dimensions, e.g., [2]*n for n qubits\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: Reduced density matrix over kept subsystems\n",
    "    \"\"\"\n",
    "    if not issparse(psi_sparse):\n",
    "        raise ValueError(\"psi_sparse must be a scipy.sparse matrix\")\n",
    "    n = len(dims)\n",
    "    D = np.prod(dims)\n",
    "    if psi_sparse.shape != (D, D):\n",
    "        raise ValueError(\"Density matrix shape does not match dims\")\n",
    "    trace = [i for i in range(n) if i not in keep]\n",
    "    d_keep = np.prod([dims[i] for i in keep])\n",
    "    # Prepare output\n",
    "    data = []\n",
    "    row_idx = []\n",
    "    col_idx = []\n",
    "\n",
    "    # Precompute bit masks\n",
    "    def idx_to_bits(idx):\n",
    "        return np.array(list(np.binary_repr(idx, width=n))).astype(int)\n",
    "    \n",
    "\n",
    "    psi_sparse = psi_sparse.tocoo()\n",
    "    for i, j, val in zip(psi_sparse.row, psi_sparse.col, psi_sparse.data):\n",
    "        bi = idx_to_bits(i)\n",
    "        bj = idx_to_bits(j)\n",
    "\n",
    "\n",
    "        # Only sum terms where traced-out subsystems agree\n",
    "        if np.all(bi[trace] == bj[trace]):\n",
    "            # Extract kept bits and convert to reduced indices\n",
    "            #print('condition met for i, j:', i, j)\n",
    "            i_red_bits = bi[keep]\n",
    "            j_red_bits = bj[keep]\n",
    "            i_red = int(\"\".join(i_red_bits.astype(str)), 2)\n",
    "            j_red = int(\"\".join(j_red_bits.astype(str)), 2)\n",
    "\n",
    "\n",
    "            data.append(val)\n",
    "            row_idx.append(i_red)\n",
    "            col_idx.append(j_red)\n",
    "    \n",
    "    return coo_matrix((data, (row_idx, col_idx)), shape=(d_keep, d_keep)).tocsr()\n",
    "\n",
    "\n",
    "def isket_torch(arr):\n",
    "    \"\"\"\n",
    "    Check if a PyTorch tensor is a ket (column vector).\n",
    "\n",
    "    Parameters:\n",
    "    - arr: torch.Tensor, the array to check.\n",
    "\n",
    "    Returns:\n",
    "    - bool, True if the array is a ket, False otherwise.\n",
    "    \"\"\"\n",
    "    if not isinstance(arr, torch.Tensor):\n",
    "        raise ValueError(\"Input must be a PyTorch tensor\")\n",
    "\n",
    "    shape = arr.shape\n",
    "\n",
    "    if len(shape) == 2 and shape[1] == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def ptrace_torch(Q, sel, dims): # torch function adapted from ptrace of qutip\n",
    "    \"\"\"\n",
    "    Compute the partial trace of a density matrix of qubits using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - Q: torch.Tensor, the quantum object (density matrix or state vector).\n",
    "    - sel: list of int, indices of the subsystems to keep.\n",
    "    - dims: list of int, dimensions of the subsystems.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor, the reduced density matrix after tracing out the specified subsystems.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the subsystems\n",
    "    rd = torch.tensor(dims[0], dtype=torch.int32).flatten()\n",
    "    nd = len(rd)\n",
    "    #print(\"rd\", rd)\n",
    "    #print(\"nd\", nd)\n",
    "    \n",
    "    # Ensure sel is a sorted array of indices\n",
    "    if isinstance(sel, int):\n",
    "        sel = torch.tensor([sel])\n",
    "    else:\n",
    "        sel = torch.tensor(sel)\n",
    "    sel = torch.sort(sel).values.tolist()\n",
    "    \n",
    "    # Dimensions of the subsystems to keep\n",
    "    dkeep = rd[sel].tolist()\n",
    "    \n",
    "    # Indices of the subsystems to trace out\n",
    "    qtrace = list(set(range(nd)) - set(sel))\n",
    "    \n",
    "    # Dimensions of the subsystems to trace out\n",
    "    dtrace = rd[qtrace].tolist()\n",
    "    \n",
    "    # Reshape the density matrix or state vector\n",
    "    rd = rd.tolist()\n",
    "    if isket_torch(Q):\n",
    "        # Reshape and transpose for state vector\n",
    "        reshaped_Q = Q.reshape(rd)\n",
    "        #print(reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(sel + qtrace)\n",
    "        #print(transposed_Q.shape)\n",
    "        vmat = transposed_Q.reshape([torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dtrace))])\n",
    "        #print(vmat.shape)\n",
    "        # Compute the reduced density matrix\n",
    "        rhomat = vmat @ vmat.conj().T\n",
    "        #print(rhomat.shape)\n",
    "    else:\n",
    "        # Reshape and transpose for density matrix\n",
    "        reshaped_Q = Q.reshape(rd + rd)\n",
    "        #print(\"reshaped_Q\", reshaped_Q.shape)\n",
    "        transposed_Q = reshaped_Q.permute(qtrace + [nd + q for q in qtrace] + sel + [nd + q for q in sel])\n",
    "        #print(\"transposed_Q\", transposed_Q.shape)\n",
    "        reshaped_transposed_Q = transposed_Q.reshape([torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dtrace)), torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))])\n",
    "        #print(\"reshaped_transposed_Q\", reshaped_transposed_Q.shape)\n",
    "        #rhomat = torch.trace(reshaped_transposed_Q)\n",
    "        rhomat = torch.einsum('iikl->kl', reshaped_transposed_Q)\n",
    "        # Trace out the first two dimensions\n",
    "        #rhomat = torch.zeros((torch.prod(torch.tensor(dkeep)), torch.prod(torch.tensor(dkeep))), dtype=Q.dtype)\n",
    "        #for i in range(reshaped_transposed_Q.shape[0]):\n",
    "        #    for j in range(reshaped_transposed_Q.shape[1]):\n",
    "        #        rhomat += reshaped_transposed_Q[i, j, :, :]\n",
    "        #print(\"rhomat\", rhomat.shape)\n",
    "    return rhomat\n",
    "\n",
    "def entanglement_entropy(psi, subsystem, total_size):\n",
    "\n",
    "    '''Computes the bipartite entanglement entropy of a pure state.\n",
    "    \n",
    "    Parameters:\n",
    "    psi : np.array\n",
    "        The wavefunction (state vector) of the full system.\n",
    "    subsystem_size : int\n",
    "        The number of qubits in subsystem A.\n",
    "    total_size : int\n",
    "        The total number of qubits in the system.\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        The von Neumann entanglement entropy S_A.'''\n",
    "    \n",
    "    psi_matrix =  np.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_numpy(psi_matrix, subsystem, [[2]*total_size, [2]*total_size])  # Partial trace over B\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rho_A)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch(psi, subsystem, total_size):\n",
    "    \"\"\"\n",
    "    Computes the bipartite entanglement entropy of a pure state using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), the wavefunction (state vector) of the full system.\n",
    "    - subsystem_size: int, the number of qubits in subsystem A.\n",
    "    - total_size: int, the total number of qubits in the system.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), the von Neumann entanglement entropy S_A.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(psi, torch.Tensor):\n",
    "        psi = torch.tensor(psi, dtype=torch.complex64)\n",
    "    \n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Compute the density matrix |psi><psi|\n",
    "    psi_matrix = torch.outer(psi, psi.conj())\n",
    "\n",
    "    # Compute the reduced density matrix rho_A = Tr_B(|psi><psi|)\n",
    "    rho_A = ptrace_torch(psi_matrix, subsystem, [[2] * total_size, [2] * total_size])  # Partial trace over B\n",
    "\n",
    "    #rho_A = rho_A.to(dtype=torch.float64)\n",
    "    \n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigvals = torch.linalg.eigvalsh(rho_A)\n",
    "\n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "\n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_qutip(psi, subsystem, total_size):\n",
    "    \n",
    "    # Convert the wavefunction to a QuTiP Qobj\n",
    "    density_matrix = np.outer(psi, psi.conj())\n",
    "    density_matrix_qobj = Qobj(density_matrix, dims=[[2]*total_size, [2]*total_size])\n",
    "\n",
    "    rho_A = ptrace(density_matrix_qobj, subsystem)\n",
    "    # Compute the von Neumann entropy S_A\n",
    "    entropy = entropy_vn(rho_A, base=2)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_np_ptrace(rdm):\n",
    "    # rdm already computed and converted to numpy\n",
    "    # Compute eigenvalues of rho_A\n",
    "    eigenvalues = np.linalg.eigvalsh(rdm)\n",
    "    \n",
    "    # Filter out zero eigenvalues to avoid numerical issues in log calculation\n",
    "    eigenvalues = eigenvalues[eigenvalues > 0]\n",
    "    \n",
    "    # Compute von Neumann entropy S_A = -Tr(rho_A log rho_A)\n",
    "    entropy = -np.sum(eigenvalues * np.log2(eigenvalues))\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def entanglement_entropy_torch_ptrace(rdm):\n",
    "\n",
    "    eigvals = torch.linalg.eigvalsh(rdm)\n",
    "    eigvals = eigvals[eigvals > 0]\n",
    "    entropy = -torch.sum(eigvals * torch.log2(eigvals))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def entanglement_entropy_qutip_torch(psi, N):\n",
    "    \"\"\"\n",
    "    Compute the von Neumann entanglement entropy using qutip.\n",
    "\n",
    "    Parameters:\n",
    "    - psi: torch.Tensor (complex), state vector of a quantum system.\n",
    "    - N: int, total number of qubits.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor (scalar), von Neumann entropy.\n",
    "    \"\"\"\n",
    "    # Ensure psi is normalized\n",
    "    psi = psi / torch.norm(psi)\n",
    "\n",
    "    # Convert PyTorch tensor to NumPy for QuTiP\n",
    "    psi_np = psi.detach().numpy()\n",
    "\n",
    "    rho_np = np.outer(psi_np, psi_np.conj())\n",
    "    rho_qobj = Qobj(rho_np, dims=[[2] * N, [2] * N])\n",
    "\n",
    "    rho_A = ptrace(rho_qobj, list(range(N // 2)))\n",
    "\n",
    "    # Compute von Neumann entropy\n",
    "    entropy = entropy_vn(rho_A, base=2)  # Compute in log base 2\n",
    "\n",
    "    # Convert back to PyTorch tensor to allow gradient flow\n",
    "    return torch.tensor(entropy, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "# Define the linear combination function - numpy\n",
    "def linear_combination_np(coeffs, psis):\n",
    "    # Ensure psis are numpy tensors\n",
    "    psi_np = [np.array(psi) for psi in psis]\n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi = sum(c * psi for c, psi in zip(coeffs, psis))\n",
    "    \n",
    "    return psi\n",
    "\n",
    "# Define the linear combination function - torch\n",
    "def linear_combination(coeffs, psis):\n",
    "    # Ensure psis are PyTorch tensors\n",
    "    psis_torch = [torch.tensor(psi, dtype=torch.complex64) if not isinstance(psi, torch.Tensor) else psi for psi in psis]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    psi_torch = sum(c * psi for c, psi in zip(coeffs, psis_torch))\n",
    "    \n",
    "    return psi_torch\n",
    "\n",
    "# Define the linear combination function - torch but after computing the ptrace of outer products of scars\n",
    "def linear_combination_outer(coeffs, outs):\n",
    "    # Ensure outs are PyTorch tensors\n",
    "    outs_torch = [torch.tensor(out, dtype=torch.complex64) if not isinstance(out, torch.Tensor) else out for out in outs]\n",
    "    torch_coeffs = torch.tensor(coeffs, dtype=torch.complex64)\n",
    "\n",
    "    # Compute the PyTorch tensor of out_coeffs which is the product of all possible combinations of c_i^* times c_j\n",
    "    out_coeffs = torch.zeros((len(torch_coeffs), len(torch_coeffs)), dtype=torch.complex64)\n",
    "    for i in range(len(torch_coeffs)):\n",
    "        for j in range(len(torch_coeffs)):\n",
    "            out_coeffs[i, j] = torch.conj(torch_coeffs[i]) * torch_coeffs[j]\n",
    "    \n",
    "    # Compute the linear combination in PyTorch\n",
    "    lin_torch = sum(out_coeffs[i, j] * outs_torch[i] for i in range(len(coeffs)) for j in range(len(coeffs)))\n",
    "    \n",
    "    return lin_torch\n",
    "\n",
    "######################################################\n",
    "\n",
    "# Function to apply permutation to a given spin configuration\n",
    "def apply_permutation(state_bits, N, perm):\n",
    "    new_bits = [0] * N\n",
    "    for i in range(N):\n",
    "        new_bits[perm[i]] = state_bits[i]  # Map value at index i to perm[i]\n",
    "    return new_bits\n",
    "\n",
    "# Function to convert an index to its binary representation\n",
    "def index_to_binary(index, num_qubits):\n",
    "    return format(index, f'0{num_qubits}b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 12  # Number of spins\n",
    "J = 1.0  # Interaction strength\n",
    "h = 3.0  # Transverse field strength # this is the value in the paper. maybe try  other values too, including the critical value one (h=J=1)\n",
    "\n",
    "#keep_qubits = [0, 4, 5]\n",
    "#keep_qubits = [0, 4, 5, 11] # 4 spins rdm full rank\n",
    "#keep_qubits = [0, 4, 5, 9]  # 4 spins - 2 adjacent triangular plaquettes - this is when i observe exactly 5 degenerate scars\n",
    "#keep_qubits = [0, 4, 5, 9, 11]  # 5 spins - 3 adjacent triangular plaquettes\n",
    "keep_qubits = [2, 4, 5, 8, 9] # 5 spins - pentagon around 0\n",
    "\n",
    "trace_qubits = [i for i in range(N) if i not in keep_qubits]\n",
    "\n",
    "\n",
    "# Assuming transverse_field_ising is defined and returns a sparse Hermitian matrix\n",
    "H = transverse_field_ising_icosahedral(N, J, h)\n",
    "\n",
    "# project H into the even-parity, H_g block:\n",
    "# (You can then run eigsh on the smaller projected space by building an orthonormal basis for the range.)\n",
    "H_Hg_full = (P @ (H @ P)).tocsr()\n",
    "\n",
    "#print(f\"Hamiltonian shape: {H.shape}\")\n",
    "#print(f\"Non-zero elements in H: {H.nnz}\")\n",
    "\n",
    "# Define the C5 permutation mapping for your case - around axis through vert 9 and 10\n",
    "perm = {\n",
    "    0: 2,\n",
    "    2: 7,\n",
    "    7: 11,\n",
    "    11: 5,\n",
    "    5: 0,\n",
    "    1: 3,\n",
    "    3: 4,\n",
    "    4: 8,\n",
    "    8: 6,\n",
    "    6: 1,\n",
    "    9: 9,   # Fixed\n",
    "    10: 10  # Fixed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All eigenvalues of H\n",
    "# Compute all eigenvalues and corresponding eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(H_even_Hg.toarray())\n",
    "\n",
    "print(f\"Eigenvalues of H: {np.sort(eigenvalues)}\")\n",
    "\n",
    "# Count the number of (near-)zero components in each eigenvector\n",
    "zero_threshold = 1e-6\n",
    "nzero_counts = []\n",
    "for i in range(eigenvectors.shape[1]):\n",
    "    num_nzero = np.sum(np.abs(eigenvectors[:, i]) > zero_threshold)\n",
    "    nzero_counts.append(num_nzero)\n",
    "    print(f\"Eigenvector {i}, eigenvalue {eigenvalues[i]}: {num_nzero} components > {zero_threshold}\")\n",
    "\n",
    "# Optionally, print a summary\n",
    "print(\"Zero count distribution:\", Counter(nzero_counts))\n",
    "\n",
    "# Check if each eigenvector is complex or real\n",
    "for i in range(eigenvectors.shape[1]):\n",
    "    vec = eigenvectors[:, i]\n",
    "    #if np.any(np.abs(vec.imag) > 1e-14):\n",
    "    #    print(f\"Eigenvector {i} is complex.\")\n",
    "    #else:\n",
    "    #    print(f\"Eigenvector {i} is real.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_indices = []\n",
    "for i in range(eigenvectors.shape[1]):\n",
    "    if nzero_counts[i] < 1000:\n",
    "        print(f\"Eigenvector {i} with eigenvalue {eigenvalues[i]} has {nzero_counts[i]} non-zero components.\")\n",
    "        sparse_indices.append(i)\n",
    "\n",
    "print(\"Indices of sparse eigenvectors:\", sparse_indices)\n",
    "\n",
    "plt.plot(eigenvalues, nzero_counts, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_indices = [1266,1267,1268,1269,1270, 1527] # 5 scars for 5 spins rdm with keep_qubits = [2,4,5,8,9] and h=3J   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scars + tf field - sparse\n",
    "\n",
    "\n",
    "for i in tqdm(sparse_indices):\n",
    "    # Construct the density matrix for each eigenvector (as sparse)\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    print(\"Nonzero elements in state vector (tol=1e-12):\", np.sum(np.abs(min_eigenvector) > 1e-6))\n",
    "    min_eigenvector[np.abs(min_eigenvector) < 1e-7] = 0\n",
    "    min_eig_sparse = csr_matrix(min_eigenvector.reshape(-1, 1))  # Convert to sparse column vector\n",
    "    \n",
    "    # Apply the transverse field operator to the sparse vector\n",
    "    vecs = transverse_field_icosahedral(N, h) @ min_eig_sparse\n",
    "    vecs = vecs.toarray()  # Convert to dense array for further processing\n",
    "    \n",
    "    # Print information about the result\n",
    "    print(f\"Shape of result: {vecs.shape}\")\n",
    "    print(f\"for {i}-th eigenvector: Number of nonzero elements in result: {np.count_nonzero(vecs)}\")\n",
    "    print(f\"Max absolute value in result: {np.max(np.abs(vecs.data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if commutator [Htf, Hi] is zero on eigenvectors of sparse indices\n",
    "print(\"Checking commutator [Htf, Hi] on sparse eigenvectors...\")\n",
    "\n",
    "# Build the Hamiltonians\n",
    "Hi = ising_icosahedron(N, J)\n",
    "Htf = transverse_field_icosahedral(N, h)\n",
    "\n",
    "# Compute the commutator [Htf, Hi] = Htf * Hi - Hi * Htf\n",
    "print(\"Computing commutator [Htf, Hi]...\")\n",
    "commutator = Htf @ Hi - Hi @ Htf\n",
    "print(f\"Commutator computed. Shape: {commutator.shape}\")\n",
    "print(f\"Commutator nnz: {commutator.nnz}\")\n",
    "\n",
    "# Check the action of the commutator on each sparse eigenvector\n",
    "commutator_norms = []\n",
    "commutator_results = []\n",
    "\n",
    "for i in sparse_indices:\n",
    "    vec = eigenvectors[:, i]\n",
    "    eigenval = eigenvalues[i]\n",
    "    \n",
    "    print(f\"\\nTesting eigenvector {i} (eigenvalue: {eigenval:.6f})...\")\n",
    "    \n",
    "    # Apply commutator to the eigenvector\n",
    "    comm_vec = commutator @ vec\n",
    "    \n",
    "    # Compute the norm of the result\n",
    "    comm_norm = np.linalg.norm(comm_vec)\n",
    "    commutator_norms.append(comm_norm)\n",
    "    commutator_results.append(comm_vec)\n",
    "    \n",
    "    print(f\"  ||[Htf, Hi] |ψ_{i}⟩|| = {comm_norm:.2e}\")\n",
    "    \n",
    "    # Check if it's effectively zero\n",
    "    if comm_norm < 1e-10:\n",
    "        print(f\"  ✓ Commutator effectively zero on this eigenvector\")\n",
    "        \n",
    "        # Verify this is a simultaneous eigenvector\n",
    "        Hi_vec = Hi @ vec\n",
    "        Htf_vec = Htf @ vec\n",
    "        \n",
    "        # Check if Hi_vec is proportional to vec\n",
    "        nonzero_mask = np.abs(vec) > 1e-12\n",
    "        if np.any(nonzero_mask):\n",
    "            Hi_ratios = Hi_vec[nonzero_mask] / vec[nonzero_mask]\n",
    "            Hi_ratio_std = np.std(Hi_ratios)\n",
    "            Hi_eigenval = np.mean(Hi_ratios)\n",
    "            \n",
    "            if Hi_ratio_std < 1e-8:\n",
    "                print(f\"    Hi eigenvalue: {Hi_eigenval:.6f}\")\n",
    "                \n",
    "                # Check if Htf_vec is proportional to vec\n",
    "                Htf_ratios = Htf_vec[nonzero_mask] / vec[nonzero_mask]\n",
    "                Htf_ratio_std = np.std(Htf_ratios)\n",
    "                Htf_eigenval = np.mean(Htf_ratios)\n",
    "                \n",
    "                if Htf_ratio_std < 1e-8:\n",
    "                    print(f\"    Htf eigenvalue: {Htf_eigenval:.6f}\")\n",
    "                    print(f\"    Total H eigenvalue: {Hi_eigenval + Htf_eigenval:.6f}\")\n",
    "                    print(f\"    Expected H eigenvalue: {eigenval:.6f}\")\n",
    "                    print(f\"    Match: {abs(Hi_eigenval + Htf_eigenval - eigenval) < 1e-6}\")\n",
    "                else:\n",
    "                    print(f\"    Not a clean Htf eigenvector (std: {Htf_ratio_std:.2e})\")\n",
    "            else:\n",
    "                print(f\"    Not a clean Hi eigenvector (std: {Hi_ratio_std:.2e})\")\n",
    "    else:\n",
    "        print(f\"  ❌ Commutator NOT zero on this eigenvector\")\n",
    "        \n",
    "        # Show the largest components of the commutator result\n",
    "        largest_indices = np.argsort(np.abs(comm_vec))[-5:]\n",
    "        print(f\"  Largest commutator components:\")\n",
    "        for idx in largest_indices:\n",
    "            binary_state = format(idx, f'0{N}b')\n",
    "            print(f\"    |{binary_state}⟩: {comm_vec[idx]:.6f}\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Commutator norms: {commutator_norms}\")\n",
    "zero_comm_count = sum(1 for norm in commutator_norms if norm < 1e-10)\n",
    "print(f\"Number of eigenvectors with effectively zero commutator: {zero_comm_count}/{len(sparse_indices)}\")\n",
    "\n",
    "# Optional: Check if the commutator itself has any special structure\n",
    "print(f\"\\nCommutator properties:\")\n",
    "print(f\"  Is Hermitian: {np.allclose(commutator.toarray(), commutator.toarray().conj().T)}\")\n",
    "print(f\"  Frobenius norm: {np.linalg.norm(commutator.toarray(), ord='fro'):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sparse eigenstates are simultaneous eigenvectors of Htf and Hi\n",
    "print(\"Analyzing simultaneous eigenstate properties of sparse eigenvectors...\")\n",
    "\n",
    "# Build the Hamiltonians\n",
    "Hi = ising_icosahedron(N, J)\n",
    "Htf = transverse_field_icosahedral(N, h)\n",
    "\n",
    "# Analyze each sparse eigenvector\n",
    "simultaneous_eigenstates = []\n",
    "eigenvalue_analysis = []\n",
    "\n",
    "for idx, i in enumerate(sparse_indices):\n",
    "    vec = eigenvectors[:, i]\n",
    "    H_eigenval = eigenvalues[i]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Analyzing eigenvector {i} (H eigenvalue: {H_eigenval:.8f})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Test if it's an eigenvector of Hi (Ising term)\n",
    "    Hi_vec = Hi @ vec\n",
    "    nonzero_mask = np.abs(vec) > 1e-12\n",
    "    \n",
    "    if np.any(nonzero_mask):\n",
    "        Hi_ratios = Hi_vec[nonzero_mask] / vec[nonzero_mask]\n",
    "        Hi_ratio_std = np.std(Hi_ratios)\n",
    "        Hi_eigenval = np.mean(Hi_ratios)\n",
    "        \n",
    "        print(f\"Hi analysis:\")\n",
    "        print(f\"  Mean eigenvalue: {Hi_eigenval:.8f}\")\n",
    "        print(f\"  Ratio std: {Hi_ratio_std:.2e}\")\n",
    "        print(f\"  Is integer? {abs(Hi_eigenval - round(Hi_eigenval)) < 1e-8}\")\n",
    "        if abs(Hi_eigenval - round(Hi_eigenval)) < 1e-8:\n",
    "            print(f\"  Rounded eigenvalue: {round(Hi_eigenval)}\")\n",
    "        \n",
    "        Hi_is_eigenstate = Hi_ratio_std < 1e-10\n",
    "        print(f\"  Is Hi eigenstate: {Hi_is_eigenstate}\")\n",
    "        \n",
    "        # Test if it's an eigenvector of Htf (transverse field term)\n",
    "        Htf_vec = Htf @ vec\n",
    "        if np.any(nonzero_mask):\n",
    "            Htf_ratios = Htf_vec[nonzero_mask] / vec[nonzero_mask]\n",
    "            Htf_ratio_std = np.std(Htf_ratios)\n",
    "            Htf_eigenval = np.mean(Htf_ratios)\n",
    "            \n",
    "            print(f\"\\nHtf analysis:\")\n",
    "            print(f\"  Mean eigenvalue: {Htf_eigenval:.8f}\")\n",
    "            print(f\"  Ratio std: {Htf_ratio_std:.2e}\")\n",
    "            print(f\"  Is Htf eigenstate: {Htf_ratio_std < 1e-10}\")\n",
    "            \n",
    "            Htf_is_eigenstate = Htf_ratio_std < 1e-10\n",
    "            \n",
    "            # Check if it's a simultaneous eigenstate\n",
    "            if Hi_is_eigenstate and Htf_is_eigenstate:\n",
    "                expected_H_eigenval = Hi_eigenval + Htf_eigenval\n",
    "                eigenval_match = abs(expected_H_eigenval - H_eigenval) < 1e-8\n",
    "                \n",
    "                print(f\"\\n*** SIMULTANEOUS EIGENSTATE FOUND ***\")\n",
    "                print(f\"  Hi eigenvalue: {Hi_eigenval:.8f}\")\n",
    "                print(f\"  Htf eigenvalue: {Htf_eigenval:.8f}\")\n",
    "                print(f\"  Expected H eigenvalue: {expected_H_eigenval:.8f}\")\n",
    "                print(f\"  Actual H eigenvalue: {H_eigenval:.8f}\")\n",
    "                print(f\"  Eigenvalue match: {eigenval_match}\")\n",
    "                \n",
    "                if eigenval_match:\n",
    "                    simultaneous_eigenstates.append(i)\n",
    "                    eigenvalue_analysis.append({\n",
    "                        'index': i,\n",
    "                        'H_eigenval': H_eigenval,\n",
    "                        'Hi_eigenval': Hi_eigenval,\n",
    "                        'Htf_eigenval': Htf_eigenval,\n",
    "                        'Hi_ratio_std': Hi_ratio_std,\n",
    "                        'Htf_ratio_std': Htf_ratio_std\n",
    "                    })\n",
    "                    \n",
    "                    # Additional analysis for simultaneous eigenstates\n",
    "                    print(f\"\\n  Additional properties:\")\n",
    "                    print(f\"    Hi eigenvalue is integer: {abs(Hi_eigenval - round(Hi_eigenval)) < 1e-8}\")\n",
    "                    print(f\"    Number of nonzero components: {np.sum(nonzero_mask)}\")\n",
    "                    \n",
    "                    # Check commutator [Hi, Htf] acting on this vector\n",
    "                    commutator_vec = (Hi @ Htf @ vec) - (Htf @ Hi @ vec)\n",
    "                    comm_norm = np.linalg.norm(commutator_vec)\n",
    "                    print(f\"    ||[Hi, Htf] |ψ⟩||: {comm_norm:.2e}\")\n",
    "                    \n",
    "            elif Hi_is_eigenstate and not Htf_is_eigenstate:\n",
    "                print(f\"\\n  → Only Hi eigenstate (eigenvalue: {Hi_eigenval:.8f})\")\n",
    "                print(f\"  → NOT Htf eigenstate (std: {Htf_ratio_std:.2e})\")\n",
    "                \n",
    "                # Show some sample Htf ratios for debugging\n",
    "                print(f\"  Sample Htf ratios (first 5 significant components):\")\n",
    "                sample_indices = np.where(nonzero_mask)[0][:5]\n",
    "                for j, idx in enumerate(sample_indices):\n",
    "                    binary_state = format(idx, f'0{N}b')\n",
    "                    if j < len(Htf_ratios):\n",
    "                        print(f\"    |{binary_state}⟩: {Htf_ratios[j]:.8f}\")\n",
    "                        \n",
    "            elif not Hi_is_eigenstate and Htf_is_eigenstate:\n",
    "                print(f\"\\n  → Only Htf eigenstate (eigenvalue: {Htf_eigenval:.8f})\")\n",
    "                print(f\"  → NOT Hi eigenstate (std: {Hi_ratio_std:.2e})\")\n",
    "                \n",
    "                # Show some sample Hi ratios for debugging\n",
    "                print(f\"  Sample Hi ratios (first 5 significant components):\")\n",
    "                sample_indices = np.where(nonzero_mask)[0][:5]\n",
    "                for j, idx in enumerate(sample_indices):\n",
    "                    binary_state = format(idx, f'0{N}b')\n",
    "                    if j < len(Hi_ratios):\n",
    "                        print(f\"    |{binary_state}⟩: {Hi_ratios[j]:.8f}\")\n",
    "                        \n",
    "            else:\n",
    "                print(f\"\\n  → NOT an eigenstate of either Hi or Htf\")\n",
    "                print(f\"  → Hi ratio std: {Hi_ratio_std:.2e}\")\n",
    "                print(f\"  → Htf ratio std: {Htf_ratio_std:.2e}\")\n",
    "                \n",
    "        else:\n",
    "            print(f\"  No significant nonzero components in Htf calculation\")\n",
    "    else:\n",
    "        print(f\"  No significant nonzero components in vector\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total sparse indices analyzed: {len(sparse_indices)}\")\n",
    "print(f\"Simultaneous eigenstates found: {len(simultaneous_eigenstates)}\")\n",
    "\n",
    "if simultaneous_eigenstates:\n",
    "    print(f\"\\nSimultaneous eigenstate indices: {simultaneous_eigenstates}\")\n",
    "    print(f\"\\nDetailed eigenvalue breakdown:\")\n",
    "    for analysis in eigenvalue_analysis:\n",
    "        print(f\"  Index {analysis['index']}:\")\n",
    "        print(f\"    H  = {analysis['H_eigenval']:.8f}\")\n",
    "        print(f\"    Hi = {analysis['Hi_eigenval']:.8f} (std: {analysis['Hi_ratio_std']:.2e})\")\n",
    "        print(f\"    Htf= {analysis['Htf_eigenval']:.8f} (std: {analysis['Htf_ratio_std']:.2e})\")\n",
    "        print(f\"    Hi + Htf = {analysis['Hi_eigenval'] + analysis['Htf_eigenval']:.8f}\")\n",
    "        print(f\"    Difference: {abs(analysis['H_eigenval'] - (analysis['Hi_eigenval'] + analysis['Htf_eigenval'])):.2e}\")\n",
    "        \n",
    "    # Check for patterns in the eigenvalues\n",
    "    Hi_eigenvals = [a['Hi_eigenval'] for a in eigenvalue_analysis]\n",
    "    Htf_eigenvals = [a['Htf_eigenval'] for a in eigenvalue_analysis]\n",
    "    \n",
    "    print(f\"\\nEigenvalue patterns:\")\n",
    "    print(f\"  Hi eigenvalues: {Hi_eigenvals}\")\n",
    "    print(f\"  Htf eigenvalues: {Htf_eigenvals}\")\n",
    "    print(f\"  Unique Hi eigenvalues: {list(set(Hi_eigenvals))}\")\n",
    "    print(f\"  Unique Htf eigenvalues: {list(set(Htf_eigenvals))}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"No simultaneous eigenstates found among the sparse indices.\")\n",
    "    print(f\"This suggests the quantum scars do not simultaneously diagonalize both terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scars + tf field - sparse\n",
    "\n",
    "\n",
    "for i in tqdm(sparse_indices):\n",
    "    # Construct the density matrix for each eigenvector (as sparse)\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    print(\"Nonzero elements in state vector (tol=1e-12):\", np.sum(np.abs(min_eigenvector) > 1e-6))\n",
    "    min_eigenvector[np.abs(min_eigenvector) < 1e-7] = 0\n",
    "    min_eig_sparse = csr_matrix(min_eigenvector.reshape(-1, 1))  # Convert to sparse column vector\n",
    "    \n",
    "    # Apply the ising operator to the sparse vector\n",
    "    vecs = ising_icosahedron(N, J) @ min_eig_sparse\n",
    "    vecs = vecs.toarray()  # Convert to dense array for further processing\n",
    "    \n",
    "    # Print information about the result\n",
    "    print(f\"Shape of result: {vecs.shape}\")\n",
    "    print(f\"for {i}-th eigenvector: Number of nonzero elements in result: {np.count_nonzero(vecs)}\")\n",
    "    print(f\"Max absolute value in result: {np.max(np.abs(vecs.data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze eigenvector 1527: expectation values and action of transverse field term\n",
    "\n",
    "idx = 2057\n",
    "vec = eigenvectors[:, idx]\n",
    "\n",
    "# Build Ising icosahedron Hamiltonian (no transverse field)\n",
    "H_ising = ising_icosahedron(N, J)\n",
    "\n",
    "# Build transverse field Hamiltonian only\n",
    "H_tf = transverse_field_icosahedral(N, h)\n",
    "\n",
    "# Compute expectation values\n",
    "eig_ising = np.vdot(vec, H_ising @ vec)\n",
    "eig_tf = np.vdot(vec, H_tf @ vec)\n",
    "\n",
    "print(f\"Eigenvector {idx}:\")\n",
    "print(f\"  Expectation value w.r.t. Ising icosahedron term: {eig_ising}\")\n",
    "print(f\"  Expectation value w.r.t. transverse field term: {eig_tf}\")\n",
    "\n",
    "# Analyze H_tf @ vec\n",
    "tf_vec = H_tf @ vec\n",
    "print(f\"\\nAnalysis of H_tf @ vec for eigenvector {idx}:\")\n",
    "print(f\"  Norm: {np.linalg.norm(tf_vec)}\")\n",
    "print(f\"  Max abs value: {np.max(np.abs(tf_vec))}\")\n",
    "print(f\"  Number of nonzero components (>1e-12): {np.sum(np.abs(tf_vec) > 1e-12)}\")\n",
    "print(f\"  Is tf_vec proportional to vec? Ratio: {np.allclose(tf_vec, eig_tf * vec)}\")\n",
    "\n",
    "# Analyze H_ising @ vec\n",
    "ising_vec = H_ising @ vec\n",
    "print(f\"\\nAnalysis of H_ising @ vec for eigenvector {idx}:\")\n",
    "print(f\"  Norm: {np.linalg.norm(ising_vec)}\")\n",
    "print(f\"  Max abs value: {np.max(np.abs(ising_vec))}\")\n",
    "print(f\"  Number of nonzero components (>1e-12): {np.sum(np.abs(ising_vec) > 1e-12)}\")\n",
    "print(f\"  Is ising_vec proportional to vec? Ratio: {np.allclose(ising_vec, eig_ising * vec)}\")\n",
    "\n",
    "# Check orthogonality of vec and H_tf @ vec\n",
    "\n",
    "inner_product = np.vdot(vec, tf_vec)\n",
    "print(f\"Inner product <vec|H_tf|vec>: {inner_product}\")\n",
    "print(f\"Is orthogonal (abs(inner_product) < 1e-12)? {np.abs(inner_product) < 1e-12}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ising_vec and vec are numpy arrays\n",
    "def check_proportional(ising_vec, vec, tol=1e-8):\n",
    "    # Find indices where vec is not zero to avoid division by zero\n",
    "    nonzero_indices = np.where(np.abs(vec) > tol)[0]\n",
    "    if len(nonzero_indices) == 0:\n",
    "        return False, None  # Cannot determine proportionality\n",
    "\n",
    "    # Calculate proportionality constants for nonzero elements\n",
    "    ratios = ising_vec[nonzero_indices] / vec[nonzero_indices]\n",
    "    # Check if all ratios are (almost) equal\n",
    "    if np.allclose(ratios, ratios[0], atol=tol, rtol=tol):\n",
    "        constant = ratios[0]\n",
    "        # Optionally, check the full vector proportionality\n",
    "        if np.allclose(ising_vec, constant * vec, atol=tol, rtol=tol):\n",
    "            return True, constant\n",
    "    return False, None\n",
    "\n",
    "# Example usage:\n",
    "is_proportional, constant = check_proportional(ising_vec, vec)\n",
    "if is_proportional:\n",
    "    print(f\"ising_vec is proportional to vec with constant {constant}\")\n",
    "else:\n",
    "    print(\"ising_vec is not proportional to vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### RDMS + EE #################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# rdm - qutip\n",
    "\n",
    "min_eigenvalues = []\n",
    "min_rdms = []\n",
    "rdm_eigenvalues = []\n",
    "\n",
    "for i in tqdm(range(len(eigenvalues))):\n",
    "    # Construct the density matrix for each eigenvector\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    density_matrix = np.outer(min_eigenvector, min_eigenvector.conj())\n",
    "    density_matrix_qobj = Qobj(density_matrix, dims=[[2]*N, [2]*N])\n",
    "\n",
    "    # Trace out qubits\n",
    "    traced_out_density_matrix = ptrace(density_matrix_qobj, keep_qubits)\n",
    "\n",
    "    # Convert the result back to a dense matrix if needed\n",
    "    traced_out_density_matrix_dense = traced_out_density_matrix.full()\n",
    "    # Check if the rank is not full and print it\n",
    "    rank = np.linalg.matrix_rank(traced_out_density_matrix_dense)\n",
    "    if rank < traced_out_density_matrix_dense.shape[0]:\n",
    "        print(f\"Traced-out density matrix rank: {rank}\")\n",
    "    # Diagonalize the traced-out density matrix\n",
    "    eigenvalues_traced, eigenvectors_traced = np.linalg.eigh(traced_out_density_matrix_dense)\n",
    "\n",
    "    # Find the minimum eigenvalue of the traced-out density matrix\n",
    "    min_eigenvalue = np.min(eigenvalues_traced) \n",
    "    min_eigenvalues.append(min_eigenvalue)\n",
    "\n",
    "    if min_eigenvalue < 1e-16:\n",
    "      min_rdms.append(traced_out_density_matrix_dense) #store the scarred rdms - step needed for optimization\n",
    "      rdm_eigenvalues.append(eigenvalues_traced) #store the eigenvalues of the scarred rdms# Define the threshold - qutip\n",
    "threshold = 1e-16\n",
    "min_eigenvalues = np.array(min_eigenvalues)\n",
    "\n",
    "# Count points with y-component less than the threshold\n",
    "count = sum(1 for y in min_eigenvalues if y < threshold)\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues]\n",
    "\n",
    "# Plot the minimum eigenvalue of the traced-out density matrix as a function of the eigenvalue of the Hamiltonian H\n",
    "plt.scatter(eigenvalues, np.abs(min_eigenvalues), color=colors, s=1)\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel(r\"$\\lambda_{\\text{min}}$\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# Find indices of red points - qutip\n",
    "red_indices = [i for i, y in enumerate(min_eigenvalues) if y < threshold]\n",
    "print(f'Indices of red points: {red_indices}')\n",
    "\n",
    "red_eigenvectors = []\n",
    "\n",
    "# Print eigenvalues, RDM minimum eigenvalues, and scalar products of eigenvectors for red points\n",
    "for i,ind in enumerate(red_indices):\n",
    "    print(i, ind)\n",
    "    print(f'Eigenvalue: {eigenvalues[ind]}, rdm Minimum Eigenvalue: {min_eigenvalues[ind]}')\n",
    "    print(f'Eigenvector {ind}: rdm rank: {np.linalg.matrix_rank(min_rdms[i])}')\n",
    "    red_eigenvectors.append(eigenvectors[:, ind])\n",
    "\n",
    "for i in range(len(red_indices)):\n",
    "    for j in range(len(red_indices)):\n",
    "        idx1, idx2 = red_indices[i], red_indices[j]\n",
    "        dot_product = np.dot(eigenvectors[:, idx1], np.conj(eigenvectors[:, idx2]))\n",
    "        print(f\"Dot product between eigenvectors {idx1} and {idx2}: {dot_product}\")\n",
    "\n",
    "# Count entries of rdm_eigenvalues[i] - eigenvalues of the scarred rdms - that are non-zero\n",
    "counts = [np.sum(eigenvalues > 1e-16) for eigenvalues in rdm_eigenvalues]\n",
    "print(f'Counts of non-zero eigenvalues of the scarred rdms: {counts}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdm - sparse\n",
    "\n",
    "min_eigenvalues_sparse = []\n",
    "min_rdms_sparse = []\n",
    "rdm_ranks_sparse = []\n",
    "\n",
    "red_indices_sparse = sparse_indices\n",
    "#red_indices_sparse = [1266,1267,1268,1269,1270, 1527] # 5 scars for 5 spins rdm with keep_qubits = [2,4,5,8,9] and h=3J\n",
    "\n",
    "for i in tqdm(red_indices_sparse):\n",
    "    # Construct the density matrix for each eigenvector (as sparse)\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    print(\"Nonzero elements in state vector (tol=1e-12):\", np.sum(np.abs(min_eigenvector) > 1e-6))\n",
    "    min_eigenvector[np.abs(min_eigenvector) < 1e-7] = 0\n",
    "    min_eig_sparse = csr_matrix(min_eigenvector.reshape(-1, 1))  # Convert to sparse column vector\n",
    "    density_matrix_sparse = min_eig_sparse @ min_eig_sparse.getH()  # Outer product to form density matrix\n",
    "\n",
    "    print(\"Number of nonzero elements of dm (tol=1e-12):\", np.sum(np.abs(density_matrix_sparse.data) > 1e-6))    #Trace out qubits using qutip partial trace\n",
    "    rdm = ptrace_sparse(density_matrix_sparse, keep_qubits, [2]*N) # Use the custom ptrace_sparse function\n",
    "    # Find the minimum eigenvalue of the traced-out density matrix\n",
    "    eigenvalues_traced, eigenvectors_traced = np.linalg.eigh(rdm.toarray())\n",
    "    min_eigenvalue = np.min(eigenvalues_traced)\n",
    "    min_eigenvalues_sparse.append(min_eigenvalue)\n",
    "\n",
    "\n",
    "    min_rdms_sparse.append(rdm)  # store the sparse RDM\n",
    "    rdm_ranks_sparse.append(np.linalg.matrix_rank(rdm.toarray()))  # store the rank\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 1e-16\n",
    "min_eigenvalues_sparse = np.array(min_eigenvalues_sparse)\n",
    "\n",
    "# Count points with y-component less than the threshold\n",
    "count = sum(1 for y in min_eigenvalues_sparse if y < threshold)\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues_sparse]\n",
    "\n",
    "x = eigenvalues[red_indices_sparse]\n",
    "print(f\"x: {x}\")\n",
    "# Plot the minimum eigenvalue of the traced-out density matrix as a function of the eigenvalue of the Hamiltonian H\n",
    "plt.scatter(x, np.abs(min_eigenvalues_sparse), color=colors, s=1)\n",
    "#plt.xlim(-7,-5)\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel(r\"$\\lambda_{\\text{min}}$\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# Find indices of red points - sparse\n",
    "#red_indices_sparse = [i for i, y in enumerate(min_eigenvalues_sparse) if y < threshold]\n",
    "#print(f'Indices of red points: {red_indices_sparse}')\n",
    "\n",
    "red_eigenvectors_sparse = []\n",
    "\n",
    "# Print eigenvalues, RDM minimum eigenvalues, and ranks for red points\n",
    "for i, ind in enumerate(red_indices_sparse):\n",
    "    print(i, ind)\n",
    "    print(f'Eigenvalue: {eigenvalues[ind]}, rdm Minimum Eigenvalue: {min_eigenvalues_sparse[i]}')\n",
    "    print(f'Eigenvector {ind}: rdm rank: {rdm_ranks_sparse[i]}')\n",
    "    red_eigenvectors_sparse.append(eigenvectors[:, ind])\n",
    "\n",
    "# Print the ranks of the scarred rdms\n",
    "print(f'Ranks of the scarred rdms: {rdm_ranks_sparse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scars + tf field - sparse\n",
    "\n",
    "red_indices_np = sparse_indices #[1266,1267,1268,1269,1270]\n",
    "\n",
    "for i in tqdm(red_indices_np):\n",
    "    # Construct the density matrix for each eigenvector (as sparse)\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    print(\"Nonzero elements in state vector (tol=1e-12):\", np.sum(np.abs(min_eigenvector) > 1e-6))\n",
    "    min_eigenvector[np.abs(min_eigenvector) < 1e-7] = 0\n",
    "    min_eig_sparse = csr_matrix(min_eigenvector.reshape(-1, 1))  # Convert to sparse column vector\n",
    "    \n",
    "    # Apply the transverse field operator to the sparse vector\n",
    "    vecs = transverse_field_icosahedral(N, h) @ min_eig_sparse\n",
    "    vecs = vecs.toarray()  # Convert to dense array for further processing\n",
    "    \n",
    "    # Print information about the result\n",
    "    print(f\"Shape of result: {vecs.shape}\")\n",
    "    print(f\"for {i}-th eigenvector: Number of nonzero elements in result: {np.count_nonzero(vecs)}\")\n",
    "    print(f\"Max absolute value in result: {np.max(np.abs(vecs.data))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute commutator [H_tf, ρ_scar] for each scarred state\n",
    "\n",
    "H_tf = transverse_field_icosahedral(N, h)  # Transverse field Hamiltonian (sparse)\n",
    "commutator_norms = []\n",
    "\n",
    "for i in red_indices_sparse:\n",
    "    scar_vec = eigenvectors[:, i]\n",
    "    # Density matrix of the scarred state\n",
    "    rho_scar = np.outer(scar_vec, scar_vec.conj())\n",
    "    # Convert to sparse for multiplication\n",
    "    rho_scar_sparse = csr_matrix(rho_scar)\n",
    "    # Compute commutator: [H_tf, ρ_scar] = H_tf * ρ_scar - ρ_scar * H_tf\n",
    "    comm = H_tf @ rho_scar_sparse - rho_scar_sparse @ H_tf\n",
    "    # Compute the Frobenius norm of the commutator\n",
    "    comm_norm = np.linalg.norm(comm.toarray(), ord='fro')\n",
    "    commutator_norms.append(comm_norm)\n",
    "    print(f\"Scar index {i}: ||[H_tf, ρ_scar]||_F = {comm_norm:.3e}\")\n",
    "\n",
    "print(\"All commutator norms:\", commutator_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute commutator [H_tf_sub, RDM] for each scarred state, all in sparse, using ptrace_sparse\n",
    "\n",
    "def transverse_field_subsystem_sparse(n, h):\n",
    "    \"\"\"Transverse field Hamiltonian for n spins (subsystem), sparse.\"\"\"\n",
    "    Z = csr_matrix(np.array([[1, 0], [0, -1]]))\n",
    "    I = identity(2, format=\"csr\")\n",
    "    H = csr_matrix((2**n, 2**n), dtype=np.complex128)\n",
    "    for i in range(n):\n",
    "        ops = [I] * n\n",
    "        ops[i] = Z\n",
    "        term = ops[0]\n",
    "        for op in ops[1:]:\n",
    "            term = kron(term, op, format=\"csr\")\n",
    "        H += -h * term\n",
    "    return H\n",
    "\n",
    "some_indices_nnsparse =  [1275]\n",
    "n_sub = len(keep_qubits)\n",
    "H_tf_sub_sparse = transverse_field_subsystem_sparse(n_sub, h)\n",
    "\n",
    "# Compute RDMs for all scarred states using ptrace_sparse (all sparse)\n",
    "rdms_sparse = []\n",
    "for i in red_indices_sparse:\n",
    "    scar_vec = eigenvectors[:, i]\n",
    "    scar_vec[np.abs(scar_vec) < 1e-7] = 0\n",
    "    scar_vec_sparse = csr_matrix(scar_vec.reshape(-1, 1))\n",
    "    rho_sparse = scar_vec_sparse @ scar_vec_sparse.getH()\n",
    "    rdm_sparse = ptrace_sparse(rho_sparse, keep_qubits, [2]*N)\n",
    "    rdms_sparse.append(rdm_sparse)\n",
    "\n",
    "# Compute commutator norms\n",
    "commutator_norms_rdm_sparse = []\n",
    "for idx, rdm in enumerate(rdms_sparse):\n",
    "    comm = H_tf_sub_sparse @ rdm - rdm @ H_tf_sub_sparse\n",
    "    comm_norm = np.linalg.norm(comm.toarray(), ord='fro')\n",
    "    print(f\"Scar RDM {idx} (index {red_indices_sparse[idx]}): ||[H_tf_sub, RDM]||_F = {comm_norm:.3e}\")\n",
    "    commutator_norms_rdm_sparse.append(comm_norm)\n",
    "\n",
    "print(\"All commutator norms for sparse RDMs:\", commutator_norms_rdm_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdm - numpy\n",
    "\n",
    "min_eigenvalues_np = []\n",
    "min_rdms_np =[]\n",
    "rdm_eigenvalues_np = []\n",
    "\n",
    "for i in tqdm(range(len(eigenvalues))):\n",
    "    # Construct the density matrix for each eigenvector\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    density_matrix = np.outer(min_eigenvector, min_eigenvector.conj())\n",
    "\n",
    "    # Trace out qubits\n",
    "    traced_out_density_matrix = ptrace_numpy(density_matrix, keep_qubits, [[2]*N, [2]*N])\n",
    "\n",
    "    # Diagonalize the traced-out density matrix\n",
    "    eigenvalues_traced, eigenvectors_traced = np.linalg.eigh(traced_out_density_matrix)\n",
    "\n",
    "    # Find the minimum eigenvalue of the traced-out density matrix\n",
    "    min_eigenvalue = np.min(eigenvalues_traced) \n",
    "    min_eigenvalues_np.append(min_eigenvalue)\n",
    "\n",
    "    if min_eigenvalue < 1e-16:\n",
    "        min_rdms_np.append(traced_out_density_matrix) #store the scarred rdms - step needed for optimization\n",
    "        rdm_eigenvalues_np.append(eigenvalues_traced) #store the eigenvalues of the scarred rdms\n",
    "\n",
    "# numpy\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 1e-16\n",
    "min_eigenvalues_np = np.array(min_eigenvalues_np)\n",
    "\n",
    "# Count points with y-component less than the threshold\n",
    "count = sum(1 for y in min_eigenvalues_np if y < threshold)\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues_np]\n",
    "\n",
    "# Plot the minimum eigenvalue of the traced-out density matrix as a function of the eigenvalue of the Hamiltonian H\n",
    "plt.scatter(eigenvalues, np.abs(min_eigenvalues_np), color=colors, s=1)\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel(r\"$\\lambda_{\\text{min}}$\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# Find indices of red points - numpy\n",
    "red_indices_np = [i for i, y in enumerate(min_eigenvalues_np) if y < threshold]\n",
    "print(f'Indices of red points: {red_indices_np}')\n",
    "\n",
    "red_eigenvectors_np = []\n",
    "\n",
    "# Print eigenvalues, RDM minimum eigenvalues, and scalar products of eigenvectors for red points\n",
    "for i,ind in enumerate(red_indices_np):\n",
    "    print(i, ind)\n",
    "    print(f'Eigenvalue: {eigenvalues[ind]}, rdm Minimum Eigenvalue: {min_eigenvalues_np[ind]}')\n",
    "    print(f'Eigenvector {ind}: rdm rank: {np.linalg.matrix_rank(min_rdms_np[i])}')\n",
    "    red_eigenvectors_np.append(eigenvectors[:, ind])\n",
    "\n",
    "#for i in range(len(red_indices_np)):\n",
    "#    for j in range(len(red_indices_np)):\n",
    "#        idx1, idx2 = red_indices_np[i], red_indices_np[j]\n",
    "#        dot_product = np.dot(eigenvectors[:, idx1], np.conj(eigenvectors[:, idx2]))\n",
    "#        print(f\"Dot product between eigenvectors {idx1} and {idx2}: {dot_product}\")\n",
    "\n",
    "# Count entries of rdm_eigenvalues_np[i] - eigenvalues of the scarred rdms - that are non-zero\n",
    "counts_np = [np.sum(eigenvalues > 1e-16) for eigenvalues in rdm_eigenvalues_np]\n",
    "print(f'Counts of non-zero eigenvalues of the scarred rdms: {counts_np}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# rdm - torch\n",
    "\n",
    "min_eigenvalues_to = []\n",
    "min_rdms_to = []\n",
    "rdm_eigenvalues_to = []\n",
    "\n",
    "for i in tqdm(range(len(eigenvalues))):\n",
    "    # Construct the density matrix for each eigenvector\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    min_eigenvector_torch = torch.tensor(min_eigenvector, dtype=torch.float64)\n",
    "    density_matrix = torch.outer(min_eigenvector_torch, min_eigenvector_torch.conj())\n",
    "\n",
    "    # Trace out qubits\n",
    "    traced_out_density_matrix = ptrace_torch(density_matrix, keep_qubits, [[2] * N, [2] * N])\n",
    "    traced_out_density_matrix = torch.tensor(traced_out_density_matrix, dtype=torch.float64) # necessary step to ensure that the scarred states have lambda_min of the correct order - <1e-16 \n",
    "\n",
    "    # Diagonalize the traced-out density matrix\n",
    "    eigenvalues_traced, eigenvectors_traced = torch.linalg.eigh(traced_out_density_matrix)\n",
    "\n",
    "    # Find the minimum eigenvalue of the traced-out density matrix\n",
    "    min_eigenvalue = torch.min(eigenvalues_traced).item()\n",
    "    min_eigenvalues_to.append(min_eigenvalue)\n",
    "\n",
    "    if min_eigenvalue < 1e-16:\n",
    "        min_rdms_to.append(traced_out_density_matrix.detach().cpu().numpy())  # store the scarred rdms - step needed for optimization\n",
    "        rdm_eigenvalues_to.append(eigenvalues_traced.detach().cpu().numpy()) # store the eigenvalues of the scarred rdms\n",
    "\n",
    "# Define the threshold\n",
    "threshold = 1e-16\n",
    "min_eigenvalues_to = np.array(min_eigenvalues_to)\n",
    "\n",
    "# Count points with y-component less than the threshold\n",
    "count = sum(1 for y in min_eigenvalues_to if y < threshold)\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues_to]\n",
    "\n",
    "# Plot the minimum eigenvalue of the traced-out density matrix as a function of the eigenvalue of the Hamiltonian H\n",
    "plt.scatter(eigenvalues, np.abs(min_eigenvalues_to), color=colors, s=1)\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel(r\"$\\lambda_{\\text{min}}$\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "# Find indices of red points - torch\n",
    "red_indices_to = [i for i, y in enumerate(min_eigenvalues_to) if y < threshold]\n",
    "print(f'Indices of red points: {red_indices_to}')\n",
    "\n",
    "red_eigenvectors_to = []\n",
    "\n",
    "# Print eigenvalues, RDM minimum eigenvalues, and scalar products of eigenvectors for red points\n",
    "for i,ind in enumerate(red_indices_to):\n",
    "    print(i, ind)\n",
    "    print(f'Eigenvalue: {eigenvalues[ind]}, rdm Minimum Eigenvalue: {min_eigenvalues_to[ind]}')\n",
    "    print(f'Eigenvector {ind}: rdm rank: {np.linalg.matrix_rank(min_rdms_to[i])}')\n",
    "    red_eigenvectors_to.append(eigenvectors[:, ind])\n",
    "\n",
    "for i in range(len(red_indices_to)):\n",
    "    for j in range(len(red_indices_to)):\n",
    "        idx1, idx2 = red_indices_to[i], red_indices_to[j]\n",
    "        dot_product = np.dot(eigenvectors[:, idx1], np.conj(eigenvectors[:, idx2]))\n",
    "        print(f\"Dot product between eigenvectors {idx1} and {idx2}: {dot_product}\")\n",
    "\n",
    "# Count entries of rdm_eigenvalues_to[i] - eigenvalues of the scarred rdms - that are non-zero\n",
    "counts_to = [np.sum(eigenvalues > 1e-15) for eigenvalues in rdm_eigenvalues_to]\n",
    "print(f'Counts of non-zero eigenvalues of the scarred rdms: {counts_to}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_v = [0,2,4,5,8,9]\n",
    "half_h = [0,2,5,7,9,11]\n",
    "\n",
    "half = half_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random complex coefficients\n",
    "random_coeffs = np.random.rand(len(red_indices_np)) + 1j* np.random.rand(len(red_indices_np))\n",
    "\n",
    "# Normalize the coefficients\n",
    "random_coeffs /= np.linalg.norm(random_coeffs)\n",
    "print(random_coeffs)\n",
    "\n",
    "print(\"coeffs norm\",sum(np.abs(random_coeffs)**2))\n",
    "\n",
    "# Define random scar state from 5 scarred states using random coefficients\n",
    "rnd_scar = np.sum(eigenvectors[:, red_indices_np] * random_coeffs, axis=1)\n",
    "\n",
    "print(len(rnd_scar))\n",
    "\n",
    "# Save eigenvalues corresponding to red indices into a numpy array\n",
    "red_eigenvalues = np.array([eigenvalues[i] for i in red_indices_np])\n",
    "\n",
    "# Count the number of zero entries\n",
    "num_zeros = np.count_nonzero((rnd_scar.real < 1e-16) & (rnd_scar.imag < 1e-16))\n",
    "print(f'Number of zero entries: {num_zeros}')\n",
    "\n",
    "# RANDOM SCAR - RANDOM LINEAR COMBINATION OF SCARRED STATES\n",
    "\n",
    "rnd_scar = linear_combination_np(random_coeffs, red_eigenvectors_np)\n",
    "rnd_scar_entropy = entanglement_entropy(rnd_scar, half, N)\n",
    "#rnd_scar_entropy_qutip = entanglement_entropy_qutip(rnd_scar, half, N)\n",
    "#rnd_scar_entropy_torch = entanglement_entropy_torch(rnd_scar, half, N)\n",
    "print(\"Random scar coeffs\", random_coeffs)\n",
    "print(f\"Entanglement entropy of random scar state: {rnd_scar_entropy}\")\n",
    "#print(f\"Entanglement entropy of random scar state (Qutip): {rnd_scar_entropy_qutip}\")\n",
    "#print(f\"Entanglement entropy of random scar state (PyTorch): {rnd_scar_entropy_torch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bipartite entanglement entropy for all eigenstates in the full Hilbert space\n",
    "numpy_entropies = [entanglement_entropy(eigenvectors[:, i], half, N) for i in tqdm(range(eigenvectors.shape[1]))]\n",
    "#qutip_entropies = [entanglement_entropy_qutip(eigenvectors[:, i], half, N) for i in tqdm(range(eigenvectors.shape[1]))]\n",
    "#torch_entropies = [entanglement_entropy_torch(eigenvectors[:, i], half, N) for i in tqdm(range(eigenvectors.shape[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight selected eigenvalues in red on a plot\n",
    "\n",
    "plt.scatter(eigenvalues, numpy_entropies, color='C0', s=1, label='numpy')\n",
    "plt.scatter([eigenvalues[i] for i in sparse_indices],\n",
    "            [numpy_entropies[i] for i in sparse_indices],\n",
    "            color='red', s=20, label='Scars')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a colormap for red points\n",
    "red_colors = plt.cm.rainbow(np.linspace(0, 1, len(red_indices_np)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "# Plot all points (blue for non-red)\n",
    "colors = ['red' if i in red_indices_np else 'C0' for i in range(len(eigenvalues))]\n",
    "for i, color in enumerate(colors):\n",
    "    ax.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color if color == 'C0' else 'none', markersize=2)\n",
    "\n",
    "# Plot each red point with a different color and collect handles/labels for legend\n",
    "handles = []\n",
    "labels = []\n",
    "for i, idx in enumerate(red_indices_np):\n",
    "    handle, = ax.plot(eigenvalues[idx], numpy_entropies[idx], 'o', color=red_colors[i], markersize=7)\n",
    "    handles.append(handle)\n",
    "    labels.append(f'Eigenvalue: {eigenvalues[idx]:.2f}, Entropy: {numpy_entropies[idx]:.2f}')\n",
    "\n",
    "# Add legend for each red point\n",
    "ax.legend(handles, labels, title=\"Red Points (Scars)\", loc='best', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Eigenvalue of H')\n",
    "ax.set_ylabel('Entanglement entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print entropies of red points only\n",
    "print(\"Entropies of red points:\")\n",
    "for i in red_indices_np:\n",
    "    print(f'Index: {i}, Entropy: {numpy_entropies[i]}')\n",
    "\n",
    "print(f'Random scar entropy: {rnd_scar_entropy}')\n",
    "\n",
    "# Plot entanglement entropy as a function of energy eigenvalues\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y in sparse_indices else 'C0' for y in min_eigenvalues_np]\n",
    "\n",
    "# Plot entanglement entropy with highlighted points\n",
    "for i, color in enumerate(colors):\n",
    "    plt.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color, markersize=2)\n",
    "\n",
    "# Plot the maximum scar entropy in yellow\n",
    "plt.plot(np.mean(red_eigenvalues), rnd_scar_entropy, 'x', color='yellow', markersize=7, label='Random Scar')\n",
    "\n",
    "# Add legend for red points only with text \"scars\"\n",
    "red_points = [i for i, color in enumerate(colors) if color == 'red']\n",
    "if red_points:\n",
    "    plt.plot([], [], 'o', color='red', label='Scars')\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel('Entanglement entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print entropies of red points only\n",
    "print(\"Entropies of red points:\")\n",
    "for i in red_indices_np:\n",
    "    print(f'Index: {i}, Entropy: {numpy_entropies[i]}')\n",
    "\n",
    "# Find the red index with the lowest entanglement entropy\n",
    "min_entropy_idx = min(red_indices_np, key=lambda i: numpy_entropies[i])\n",
    "min_entropy_val = numpy_entropies[min_entropy_idx]\n",
    "\n",
    "# Plot entanglement entropy as a function of energy eigenvalues\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y in sparse_indices else 'C0' for y in min_eigenvalues_np]\n",
    "\n",
    "# Plot blue points first\n",
    "for i, color in enumerate(colors):\n",
    "    if color != 'red':\n",
    "        plt.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color, markersize=2)\n",
    "# Then plot red points on top\n",
    "for i, color in enumerate(colors):\n",
    "    if color == 'red':\n",
    "        plt.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color, markersize=4)\n",
    "\n",
    "# Plot entanglement entropy with highlighted points\n",
    "#for i, color in enumerate(colors):\n",
    "#    size = 3 if color == 'red' else 2\n",
    "#    plt.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color, markersize=size)\n",
    "\n",
    "# Mark the scar with the lowest entanglement entropy with a yellow cross\n",
    "plt.plot(eigenvalues[min_entropy_idx], min_entropy_val, 'x', color='red', markersize=8, label=f'Min EE (idx={min_entropy_idx + 1})')\n",
    "\n",
    "# Add legend for red points only with text \"scars\"\n",
    "red_points = [i for i, color in enumerate(colors) if color == 'red']\n",
    "if red_points:\n",
    "    plt.plot([], [], 'o', color='red', markersize=4, label='Scars')\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel('Entanglement entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Compute entanglement entropy for the rnd_scar wavefunction - qutip\n",
    "\n",
    "# Print entropies of red points only\n",
    "print(\"Entropies of red points:\")\n",
    "for i in red_indices:\n",
    "    print(f'Index: {i}, Entropy: {qutip_entropies[i]}')\n",
    "\n",
    "print(f'Random scar entropy: {rnd_scar_entropy_qutip}')\n",
    "\n",
    "# Plot entanglement entropy as a function of energy eigenvalues\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues]\n",
    "\n",
    "# Plot entanglement entropy with highlighted points\n",
    "for i, color in enumerate(colors):\n",
    "    plt.plot(eigenvalues[i], qutip_entropies[i], 'o', color=color, markersize=2)\n",
    "\n",
    "# Plot the maximum scar entropy in yellow\n",
    "plt.plot(np.mean(red_eigenvalues), rnd_scar_entropy_qutip, 'x', color='yellow', markersize=7, label='Random Scar')\n",
    "\n",
    "# Add legend for red points only with text \"scars\"\n",
    "red_points = [i for i, color in enumerate(colors) if color == 'red']\n",
    "if red_points:\n",
    "    plt.plot([], [], 'o', color='red', label='Scars')\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel('Entanglement entropy')\n",
    "#plt.title('Entanglement entropy as a function of energy eigenvalues')\n",
    "plt.legend()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Compute entanglement entropy for the rnd_scar wavefunction - torch\n",
    "\n",
    "# Print entropies of red points only\n",
    "print(\"Entropies of red points:\")\n",
    "for i in red_indices:\n",
    "    print(f'Index: {i}, Entropy: {torch_entropies[i]}')\n",
    "\n",
    "print(f'Random scar entropy: {rnd_scar_entropy_torch}')\n",
    "\n",
    "# Plot entanglement entropy as a function of energy eigenvalues\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues]\n",
    "\n",
    "# Plot entanglement entropy with highlighted points\n",
    "for i, color in enumerate(colors):\n",
    "    plt.plot(eigenvalues[i], torch_entropies[i], 'o', color=color, markersize=2)\n",
    "\n",
    "# Plot the maximum scar entropy in yellow\n",
    "plt.plot(np.mean(red_eigenvalues), rnd_scar_entropy_torch, 'x', color='yellow', markersize=7, label='Random Scar')\n",
    "\n",
    "# Add legend for red points only with text \"scars\"\n",
    "red_points = [i for i, color in enumerate(colors) if color == 'red']\n",
    "if red_points:\n",
    "    plt.plot([], [], 'o', color='red', label='Scars')\n",
    "\n",
    "plt.xlabel('Eigenvalue of H')\n",
    "plt.ylabel('Entanglement entropy')\n",
    "#plt.title('Entanglement entropy as a function of energy eigenvalues')\n",
    "plt.legend()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of colors for red points\n",
    "red_colors = plt.cm.rainbow(np.linspace(0, 1, len(red_indices_np)))\n",
    "\n",
    "# Print entropies of red points only\n",
    "print(\"Entropies of red points:\")\n",
    "for i in red_indices_np:\n",
    "    print(f'Index: {i}, Entropy: {numpy_entropies[i]}')\n",
    "\n",
    "print(f'Random scar entropy: {rnd_scar_entropy}')\n",
    "\n",
    "# Plot entanglement entropy as a function of energy eigenvalues\n",
    "fig, ax = plt.subplots(figsize=(11, 6))\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues_np]\n",
    "\n",
    "# Plot entanglement entropy with highlighted points\n",
    "for i, color in enumerate(colors):\n",
    "    ax.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color, markersize=2)\n",
    "\n",
    "# Collect handles and labels for the legend\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "# Plot each red point with a different color and collect handles and labels\n",
    "for i, idx in enumerate(red_indices_np):\n",
    "    handle, = ax.plot(eigenvalues[idx], numpy_entropies[idx], 'o', color=red_colors[i], markersize=5)\n",
    "    handles.append(handle)\n",
    "    labels.append(f'λ_min: {float(min_eigenvalues_np[idx]):.2e}, Entropy: {numpy_entropies[idx]:.2f}')\n",
    "\n",
    "# Plot the maximum scar entropy in yellow and add to handles and labels\n",
    "max_scar_handle, = ax.plot(np.mean(red_eigenvalues), rnd_scar_entropy, 'x', color='yellow', markersize=7)\n",
    "handles.append(max_scar_handle)\n",
    "labels.append('Max Scar, Entropy: {:.2f}'.format(rnd_scar_entropy))\n",
    "\n",
    "# Sort handles and labels by lambda min\n",
    "sorted_handles_labels = sorted(zip(handles, labels), key=lambda hl: float(hl[1].split(': ')[1].split(',')[0]) if 'λ_min' in hl[1] else float('inf'))\n",
    "sorted_handles, sorted_labels = zip(*sorted_handles_labels)\n",
    "\n",
    "# Filter min_eigenvalues to include only those corresponding to red_indices\n",
    "filtered_min_eigenvalues = [min_eigenvalues_np[idx] for idx in red_indices_np]\n",
    "\n",
    "# Create a color bar for the red points using filtered min_eigenvalues\n",
    "norm = Normalize(vmin=min(filtered_min_eigenvalues), vmax=max(filtered_min_eigenvalues))\n",
    "sm = ScalarMappable(cmap='rainbow', norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax, label=r'$\\lambda_{\\mathrm{min}}$')\n",
    "\n",
    "ax.set_xlabel('Eigenvalue of H')\n",
    "ax.set_ylabel('Entanglement entropy')\n",
    "#ax.set_title('Entanglement entropy as a function of energy eigenvalues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### OPTIMAL LINEAR COMBINATION OF SCARS THAT  MINIMIZE/MAXIMIZE EE ##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look closer at the scar points with the lowest and highest entropy (Indices: 1267, 1268)\n",
    "\n",
    "# MIN ENTROPY\n",
    "\n",
    "lowest_entropy_index = 1267\n",
    "lowest_entropy_eigenvector = eigenvectors[:, lowest_entropy_index]\n",
    "entanglement_entropy_value = entanglement_entropy(lowest_entropy_eigenvector, half, N)\n",
    "print(f'Lowest Entropy Index: {lowest_entropy_index}, Entropy: {entanglement_entropy_value}')   \n",
    "\n",
    "# Convert the eigenvector to PyTorch tensors for real and imaginary parts\n",
    "params_real = torch.tensor(lowest_entropy_eigenvector.real, dtype=torch.float, requires_grad=True)\n",
    "params_imag = torch.tensor(lowest_entropy_eigenvector.imag, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "print(\"Initial coeffs, real:\", params_real)\n",
    "print(\"Initial coeffs, imag:\", params_imag)\n",
    "\n",
    "entanglement_entropy_value = entanglement_entropy_torch(lowest_entropy_eigenvector, half, N)\n",
    "print(f'Lowest Entropy Index: {lowest_entropy_index}, Entropy: {entanglement_entropy_value}')\n",
    "\n",
    "# Define coefficients for the linear combination\n",
    "min_coeffs = np.zeros(len(red_eigenvectors_np), dtype=np.complex128)  # Initialize all coefficients to 0\n",
    "min_coeffs[red_indices_np.index(1267)] = 1  # Ensure the coefficient for index 1267 is explicitly set to 1\n",
    "\n",
    "\n",
    "# MAX ENTROPY\n",
    "highest_entropy_index = 1268\n",
    "highest_entropy_eigenvector = eigenvectors[:, highest_entropy_index]\n",
    "entanglement_entropy_value = entanglement_entropy(highest_entropy_eigenvector, half, N)\n",
    "print(f'Highest Entropy Index: {highest_entropy_index}, Entropy: {entanglement_entropy_value}') \n",
    "\n",
    "# Convert the eigenvector to PyTorch tensors for real and imaginary parts\n",
    "params_real = torch.tensor(lowest_entropy_eigenvector.real, dtype=torch.float, requires_grad=True)\n",
    "params_imag = torch.tensor(lowest_entropy_eigenvector.imag, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "print(\"Initial coeffs, real:\", params_real)\n",
    "print(\"Initial coeffs, imag:\", params_imag)\n",
    "\n",
    "entanglement_entropy_value = entanglement_entropy_torch(highest_entropy_eigenvector, half, N)\n",
    "print(f'Highest Entropy Index: {highest_entropy_index}, Entropy: {entanglement_entropy_value}')\n",
    "\n",
    "# Define coefficients for the linear combination\n",
    "max_coeffs = np.zeros(len(red_eigenvectors_np), dtype=np.complex128)  # Initialize all coefficients to 0\n",
    "max_coeffs[red_indices_np.index(1268)] = 1  # Ensure the coefficient for index 1268 is explicitly set to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find entropy min coeffs - everything  has to be in torch\n",
    "\n",
    "# Initialize parameters for the coefficients with all values equal\n",
    "#params_real = torch.full((5,), 1/np.sqrt(10), requires_grad=True)\n",
    "#params_imag = torch.full((5,), 1/np.sqrt(10), requires_grad=True)\n",
    "\n",
    "# Initialize parameters for the coefficients with random values\n",
    "#params_real = torch.randn(5, requires_grad=True)\n",
    "#params_imag = torch.randn(5, requires_grad=True)\n",
    "\n",
    "# Convert random_coeffs to PyTorch tensors\n",
    "#params_real = torch.tensor(random_coeffs.real, dtype=torch.float, requires_grad=True)\n",
    "#params_imag = torch.tensor(random_coeffs.imag, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "red_eigenvectors = [torch.tensor(vec, dtype=torch.complex64) for vec in red_eigenvectors_np]\n",
    "\n",
    "\n",
    "params_real = torch.tensor(min_coeffs.real, dtype=torch.float, requires_grad=True)\n",
    "params_imag = torch.tensor(min_coeffs.imag, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "# Compute the linear combination using the defined function\n",
    "psi = linear_combination(torch.complex(params_real, params_imag), red_eigenvectors)\n",
    "\n",
    "# if the outer products between scarred states are computed before optimization loop\n",
    "# ....\n",
    "\n",
    "# Compute entanglement entropy\n",
    "entropy = entanglement_entropy_torch(psi, half, N) \n",
    "print(f'Initial Entropy: {entropy.item()}')\n",
    "\n",
    "# Normalize the parameters to ensure the norm is 1\n",
    "with torch.no_grad():\n",
    "    norm = torch.norm(torch.complex(params_real, params_imag))\n",
    "    params_real /= norm\n",
    "    params_imag /= norm\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam([params_real, params_imag], lr=0.01)\n",
    "\n",
    "# Lists to store the values of parameters and entropy\n",
    "coeffs_history_min = []\n",
    "entropy_history = []\n",
    "\n",
    "# Optimization loop\n",
    "num_iterations = 150\n",
    "for _ in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Combine real and imaginary parts for the coefficients\n",
    "    coeffs = torch.complex(params_real, params_imag)\n",
    "    \n",
    "    # Normalize coefficients to project them onto the unit sphere\n",
    "    coeffs = coeffs / torch.norm(coeffs)\n",
    "    \n",
    "    # Compute psi\n",
    "    psi = linear_combination(coeffs, red_eigenvectors)\n",
    "    \n",
    "    # Compute entanglement entropy\n",
    "    entropy = entanglement_entropy_torch(psi, half, N) # it would be better to compute the outer product of the state before the optimization loop. but optimization is not taking too long so it's ok for now\n",
    "    \n",
    "    # Backpropagation\n",
    "    entropy.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Normalize parameters again to ensure they stay on the unit sphere\n",
    "    with torch.no_grad():\n",
    "        norm = torch.norm(torch.complex(params_real, params_imag))\n",
    "        params_real /= norm\n",
    "        params_imag /= norm\n",
    "    print(\"Coeffs norm:\", torch.norm(torch.complex(params_real, params_imag)).detach().cpu().numpy())\n",
    "    \n",
    "    print(f'Entropy: {entropy.item()}')\n",
    "    print(f'Coeffs: {coeffs.detach().cpu().numpy()}')\n",
    "\n",
    "    # Store the values of parameters and entropy\n",
    "    coeffs_history_min.append(coeffs.detach().cpu().numpy())\n",
    "    entropy_history.append(entropy.item())\n",
    "\n",
    "# Final optimized coefficients\n",
    "optimized_coeffs = torch.complex(params_real, params_imag)\n",
    "optimized_coeffs = optimized_coeffs / torch.norm(optimized_coeffs)\n",
    "\n",
    "print(\"Optimized coefficients:\", optimized_coeffs)\n",
    "\n",
    "# Plot the value of parameters and entropy as a function of num_iterations\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot entropy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(entropy_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Entropy')\n",
    "#plt.title('Entropy vs. Iterations')\n",
    "\n",
    "# Plot coefficients\n",
    "plt.subplot(1, 2, 2)\n",
    "coeffs_history_min = np.array(coeffs_history_min)\n",
    "for i in range(coeffs_history_min.shape[1]):\n",
    "    plt.plot(coeffs_history_min[:, i].real, label=f'Coeff {i+1} Real')\n",
    "    plt.plot(coeffs_history_min[:, i].imag, label=f'Coeff {i+1} Imag', linestyle='--')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Coefficient Value')\n",
    "#plt.title('Coefficients vs. Iterations')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the max_scar wavefunction using the optimized coefficients (min entropy)\n",
    "min_scar = linear_combination_np(coeffs_history_min[-1], red_eigenvectors_np)\n",
    "# Define a list of colors for red points\n",
    "red_colors = plt.cm.rainbow(np.linspace(0, 1, len(red_indices_np)))\n",
    "\n",
    "# Compute entanglement entropy for the max_scar wavefunction\n",
    "min_scar_entropy = entanglement_entropy(min_scar, half, N)\n",
    "\n",
    "# Print entropies of red points only\n",
    "print(\"Entropies of red points:\")\n",
    "for i in red_indices_np:\n",
    "    print(f'Index: {i}, Entropy: {numpy_entropies[i]}')\n",
    "\n",
    "print(f'Min scar entropy: {min_scar_entropy}')\n",
    "\n",
    "# Plot entanglement entropy as a function of energy eigenvalues\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues_np]\n",
    "\n",
    "# Plot entanglement entropy with highlighted points\n",
    "for i, color in enumerate(colors):\n",
    "    ax.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color, markersize=2)\n",
    "\n",
    "# Collect handles and labels for the legend\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "# Plot each red point with a different color and collect handles and labels\n",
    "for i, idx in enumerate(red_indices_np):\n",
    "    handle, = ax.plot(eigenvalues[idx], numpy_entropies[idx], 'o', color=red_colors[i], markersize=5)\n",
    "    handles.append(handle)\n",
    "    labels.append(r'$\\lambda_\\mathrm{min}$: {float(min_eigenvalues[idx]):.2e}, Entropy: {naive_entropies[idx]:.2f}')\n",
    "\n",
    "# Plot the maximum scar entropy in yellow and add to handles and labels\n",
    "min_scar_handle, = ax.plot(np.mean(eigenvalues[red_indices_np]), min_scar_entropy, 'x', color='black', markersize=7)\n",
    "handles.append(min_scar_handle)\n",
    "labels.append('Min Scar, Entropy: {:.2f}'.format(min_scar_entropy))\n",
    "\n",
    "# Sort handles and labels by lambda min\n",
    "sorted_handles_labels = sorted(zip(handles, labels), key=lambda hl: float(hl[1].split(': ')[1].split(',')[0]) if 'λ_min' in hl[1] else float('inf'))\n",
    "sorted_handles, sorted_labels = zip(*sorted_handles_labels)\n",
    "\n",
    "# Filter min_eigenvalues to include only those corresponding to red_indices\n",
    "filtered_min_eigenvalues = [min_eigenvalues_np[idx] for idx in red_indices_np]\n",
    "\n",
    "# Create a color bar for the red points using filtered min_eigenvalues\n",
    "norm = Normalize(vmin=min(filtered_min_eigenvalues), vmax=max(filtered_min_eigenvalues))\n",
    "sm = ScalarMappable(cmap='rainbow', norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax, label=r'$\\lambda_{\\mathrm{min}}$')\n",
    "\n",
    "ax.set_xlabel('Eigenvalue of H')\n",
    "ax.set_ylabel('Entanglement entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find entropy max coeffs - everything  has to be in torch\n",
    "\n",
    "# Initialize parameters for the coefficients with all values equal\n",
    "#params_real = torch.full((5,), 1/np.sqrt(10), requires_grad=True)\n",
    "#params_imag = torch.full((5,), 1/np.sqrt(10), requires_grad=True)\n",
    "\n",
    "# Initialize parameters for the coefficients with random values\n",
    "#params_real = torch.randn(5, requires_grad=True)\n",
    "#params_imag = torch.randn(5, requires_grad=True)\n",
    "\n",
    "# Convert random_coeffs to PyTorch tensors\n",
    "#params_real = torch.tensor(random_coeffs.real, dtype=torch.float, requires_grad=True)\n",
    "#params_imag = torch.tensor(random_coeffs.imag, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "params_real = torch.tensor(max_coeffs.real, dtype=torch.float, requires_grad=True)\n",
    "params_imag = torch.tensor(max_coeffs.imag, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "print(\"Initial coeffs, real\", params_real)\n",
    "print(\"Initial coeffs imag\",  params_imag)\n",
    "\n",
    "# Compute psi\n",
    "psi = linear_combination(torch.complex(params_real, params_imag), red_eigenvectors)\n",
    "\n",
    "# Compute entanglement entropy\n",
    "entropy = entanglement_entropy_torch(psi, half, N) \n",
    "print(f'Initial Entropy: {entropy.item()}')\n",
    "\n",
    "# Normalize the parameters to ensure the norm is 1\n",
    "with torch.no_grad():\n",
    "    norm = torch.norm(torch.complex(params_real, params_imag))\n",
    "    params_real /= norm\n",
    "    params_imag /= norm\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam([params_real, params_imag], lr=0.01)\n",
    "\n",
    "# Lists to store the values of parameters and entropy\n",
    "coeffs_history_max = []\n",
    "entropy_history_max = []\n",
    "\n",
    "# Optimization loop\n",
    "num_iterations = 150\n",
    "for _ in range(num_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Combine real and imaginary parts for the coefficients\n",
    "    coeffs = torch.complex(params_real, params_imag)\n",
    "    \n",
    "    # Normalize coefficients to project them onto the unit sphere\n",
    "    coeffs = coeffs / torch.norm(coeffs)\n",
    "    \n",
    "    # Compute psi\n",
    "    psi = linear_combination(coeffs, red_eigenvectors)\n",
    "    \n",
    "    # Compute - entanglement entropy\n",
    "    entropy = - entanglement_entropy_torch(psi, half, N) # it would be better to compute the outer product of the state before the optimization loop. but optimization is not taking too long so it's ok for now\n",
    "    \n",
    "    # Backpropagation\n",
    "    entropy.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Normalize parameters again to ensure they stay on the unit sphere\n",
    "    with torch.no_grad():\n",
    "        norm = torch.norm(torch.complex(params_real, params_imag))\n",
    "        params_real /= norm\n",
    "        params_imag /= norm\n",
    "    print(\"Coeffs norm:\", torch.norm(torch.complex(params_real, params_imag)).detach().cpu().numpy())\n",
    "    \n",
    "    print(f'Entropy: {abs(entropy.item())}')\n",
    "    print(f'Coeffs: {coeffs.detach().cpu().numpy()}')\n",
    "\n",
    "    # Store the values of parameters and entropy\n",
    "    coeffs_history_max.append(coeffs.detach().cpu().numpy())\n",
    "    entropy_history_max.append(abs(entropy.item()))\n",
    "\n",
    "# Final optimized coefficients\n",
    "optimized_coeffs_max = torch.complex(params_real, params_imag)\n",
    "optimized_coeffs_max = optimized_coeffs_max / torch.norm(optimized_coeffs_max)\n",
    "\n",
    "print(\"Optimized coefficients:\", optimized_coeffs_max)\n",
    "\n",
    "# Plot the value of parameters and entropy as a function of num_iterations\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot entropy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.abs(entropy_history_max))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Entropy')\n",
    "#plt.title('Entropy vs. Iterations')\n",
    "\n",
    "# Plot coefficients\n",
    "plt.subplot(1, 2, 2)\n",
    "coeffs_history_max = np.array(coeffs_history_max)\n",
    "for i in range(coeffs_history_max.shape[1]):\n",
    "    plt.plot(coeffs_history_max[:, i].real, label=f'Coeff {i+1} Real')\n",
    "    plt.plot(coeffs_history_max[:, i].imag, label=f'Coeff {i+1} Imag', linestyle='--')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Coefficient Value')\n",
    "#plt.title('Coefficients vs. Iterations')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the max_scar wavefunction using the optimized coefficients (min entropy)\n",
    "max_scar = linear_combination_np(coeffs_history_max[-1], red_eigenvectors_np)\n",
    "# Define a list of colors for red points\n",
    "red_colors = plt.cm.rainbow(np.linspace(0, 1, len(red_indices_np)))\n",
    "\n",
    "# Compute entanglement entropy for the max_scar wavefunction\n",
    "max_scar_entropy = entanglement_entropy(max_scar, half, N)\n",
    "\n",
    "# Print entropies of red points only\n",
    "print(\"Entropies of red points:\")\n",
    "for i in red_indices_np:\n",
    "    print(f'Index: {i}, Entropy: {numpy_entropies[i]}')\n",
    "\n",
    "print(f'Max scar entropy: {max_scar_entropy}')\n",
    "\n",
    "# Plot entanglement entropy as a function of energy eigenvalues\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Highlight points with y-component less than the threshold in red\n",
    "colors = ['red' if y < threshold else 'C0' for y in min_eigenvalues_np]\n",
    "\n",
    "# Plot entanglement entropy with highlighted points\n",
    "for i, color in enumerate(colors):\n",
    "    ax.plot(eigenvalues[i], numpy_entropies[i], 'o', color=color, markersize=2)\n",
    "\n",
    "# Collect handles and labels for the legend\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "# Plot each red point with a different color and collect handles and labels\n",
    "for i, idx in enumerate(red_indices_np):\n",
    "    handle, = ax.plot(eigenvalues[idx], numpy_entropies[idx], 'o', color=red_colors[i], markersize=5)\n",
    "    handles.append(handle)\n",
    "    labels.append(r'$\\lambda_\\mathrm{min}$: {float(min_eigenvalues[idx]):.2e}, Entropy: {naive_entropies[idx]:.2f}')\n",
    "\n",
    "# Plot the maximum scar entropy in yellow and add to handles and labels\n",
    "max_scar_handle, = ax.plot(np.mean(eigenvalues[red_indices_np]), max_scar_entropy, 'x', color='black', markersize=7)\n",
    "handles.append(max_scar_handle)\n",
    "labels.append('Max Scar, Entropy: {:.2f}'.format(max_scar_entropy))\n",
    "\n",
    "# Sort handles and labels by lambda min\n",
    "sorted_handles_labels = sorted(zip(handles, labels), key=lambda hl: float(hl[1].split(': ')[1].split(',')[0]) if 'λ_min' in hl[1] else float('inf'))\n",
    "sorted_handles, sorted_labels = zip(*sorted_handles_labels)\n",
    "\n",
    "# Filter min_eigenvalues to include only those corresponding to red_indices\n",
    "filtered_min_eigenvalues = [min_eigenvalues_np[idx] for idx in red_indices_np]\n",
    "\n",
    "# Create a color bar for the red points using filtered min_eigenvalues\n",
    "norm = Normalize(vmin=min(filtered_min_eigenvalues), vmax=max(filtered_min_eigenvalues))\n",
    "sm = ScalarMappable(cmap='rainbow', norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cbar = fig.colorbar(sm, ax=ax, label=r'$\\lambda_{\\mathrm{min}}$')\n",
    "\n",
    "ax.set_xlabel('Eigenvalue of H')\n",
    "ax.set_ylabel('Entanglement entropy')\n",
    "#ax.set_title('Entanglement entropy as a function of energy eigenvalues')\n",
    "#ax.legend(sorted_handles, sorted_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## PROPERTIES OF EACH SCARRED STATE AND THEIR RDM ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the number of dependent columns and their indices for each matrix\n",
    "dependent_columns_info = []\n",
    "\n",
    "for idx, rdm in enumerate(min_rdms_np):\n",
    "    print(f\"RDM Index: {idx}\")\n",
    "    \n",
    "    # Perform QR decomposition with column pivoting\n",
    "    Q, R, pivot_indices = qr(rdm, pivoting=True)\n",
    "    \n",
    "    # Determine rank using a threshold on the diagonal of R\n",
    "    tol = 1e-12\n",
    "    rank = np.sum(np.abs(np.diag(R)) > tol)\n",
    "    \n",
    "    # Calculate the number of dependent columns\n",
    "    num_dependent_columns = 16 - rank\n",
    "    \n",
    "    # Identify dependent columns\n",
    "    dependent_columns = sorted(set(range(16)) - set(pivot_indices[:rank]))\n",
    "    dependent_columns_info.append((num_dependent_columns, dependent_columns))\n",
    "    \n",
    "    print(f\"Number of dependent columns: {num_dependent_columns}\")\n",
    "    print(f\"Dependent columns indices: {dependent_columns}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Print the results\n",
    "print(\"Dependent columns info for each matrix:\", dependent_columns_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the null space information for each matrix\n",
    "null_spaces_info = []\n",
    "\n",
    "for idx, rdm in enumerate(min_rdms_np):\n",
    "    print(f\"RDM Index: {idx}\")\n",
    "    \n",
    "    # Compute the null space of the RDM\n",
    "    null_space_rdm = null_space(rdm)\n",
    "    \n",
    "    # Store the null space information\n",
    "    null_spaces_info.append(null_space_rdm)\n",
    "    \n",
    "    # Print the null space dimensions and basis vectors\n",
    "    print(f\"Null space dimension: {null_space_rdm.shape[1]}\")\n",
    "    print(f\"Null space basis vectors:\\n{null_space_rdm}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Apply the RDM to each null basis vector\n",
    "    for i, basis_vector in enumerate(null_space_rdm.T):  # Transpose to iterate over columns\n",
    "        result = np.dot(rdm, basis_vector)\n",
    "        print(f\"RDM {idx}, Null Basis Vector {i}:\")\n",
    "        print(f\"Result: {result}\")\n",
    "        print(f\"Norm of Result: {np.linalg.norm(result)}\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Null space information for each matrix computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each RDM, check if any row in its null space basis matrix is (close to) zero\n",
    "for idx, rdm in enumerate(min_rdms_np):\n",
    "    null_space_rdm = null_space(rdm)\n",
    "    for i, row in enumerate(null_space_rdm):\n",
    "        if np.allclose(row, 0, atol=1e-12):\n",
    "            print(f\"RDM {idx}: Row {i} in null space is (close to) zero.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of distinct rows in the null space basis of RDM 0\n",
    "rdm = min_rdms_np[4]\n",
    "null_space_rdm = null_space(rdm)\n",
    "\n",
    "# Use np.allclose to group rows that are numerically identical\n",
    "distinct_rows = []\n",
    "for i, row in enumerate(null_space_rdm):\n",
    "    is_new = True\n",
    "    for drow in distinct_rows:\n",
    "        if np.allclose(row, drow, atol=1e-12):\n",
    "            is_new = False\n",
    "            break\n",
    "    if is_new:\n",
    "        distinct_rows.append(row)\n",
    "\n",
    "print(f\"Number of distinct rows in null space basis of RDM 0: {len(distinct_rows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the binary basis states for each group of identical rows in the null space basis of RDM 0 (5 spins)\n",
    "# Also print the smallest row index for each group\n",
    "\n",
    "def index_to_binary(index, num_qubits):\n",
    "    return format(index, f'0{num_qubits}b')\n",
    "\n",
    "rdm = min_rdms_np[0]\n",
    "null_space_rdm = null_space(rdm)\n",
    "\n",
    "# Group row indices by their unique row (up to numerical tolerance)\n",
    "groups = []\n",
    "group_indices = []\n",
    "\n",
    "for i, row in enumerate(null_space_rdm):\n",
    "    found = False\n",
    "    for g, grow in enumerate(groups):\n",
    "        if np.allclose(row, grow, atol=1e-12):\n",
    "            group_indices[g].append(i)\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        groups.append(row)\n",
    "        group_indices.append([i])\n",
    "\n",
    "print(f\"Number of distinct rows: {len(groups)}\")\n",
    "for indices in group_indices:\n",
    "    basis_states = [index_to_binary(idx, 5) for idx in indices]\n",
    "    min_row = min(indices)\n",
    "    print(f\"Row {min_row}: Basis states: {', '.join(basis_states)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the null space information for each matrix\n",
    "null_spaces_info = []\n",
    "\n",
    "for idx, rdm in enumerate(min_rdms_np):\n",
    "    print(f\"RDM Index: {idx}\")\n",
    "    \n",
    "    # Compute the null space of the RDM\n",
    "    null_space_rdm = null_space(rdm)\n",
    "    \n",
    "    # Store the null space information\n",
    "    null_spaces_info.append(null_space_rdm)\n",
    "    \n",
    "    # Print the null space dimensions and basis vectors\n",
    "    print(f\"Null space dimension: {null_space_rdm.shape[1]}\")\n",
    "    #print(f\"Null space basis vectors:\\n{null_space_rdm}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Apply the RDM to each null basis vector\n",
    "    #for i, basis_vector in enumerate(null_space_rdm.T):  # Transpose to iterate over columns\n",
    "        #result = np.dot(rdm, basis_vector)\n",
    "        #print(f\"RDM {idx}, Null Basis Vector {i}:\")\n",
    "        #print(f\"Result: {result}\")\n",
    "        #print(f\"Norm of Result: {np.linalg.norm(result)}\")\n",
    "    \n",
    "    # Check for repeating rows in the null space basis vectors\n",
    "    print(f\"Repeating rows in the null space basis vectors for RDM {idx}:\")\n",
    "    for i in range(null_space_rdm.shape[0]):\n",
    "        for j in range(i + 1, null_space_rdm.shape[0]):\n",
    "            if np.allclose(null_space_rdm[i, :], null_space_rdm[j, :], atol=1e-12):  # Compare rows with a tolerance\n",
    "                print(f\"Row {i} is identical to Row {j}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over scarred eigenvectors\n",
    "for i, eigenvector in enumerate(red_eigenvectors_np):\n",
    "    # Print the entire eigenvector\n",
    "    non_zero_count = 0  # Counter for non-zero components\n",
    "    print(f\"Full Eigenvector {i}:\")\n",
    "    for index, component in enumerate(eigenvector):\n",
    "        # Set components of the order 10^-12 or smaller to zero\n",
    "        if np.abs(component) < 1e-12: # I noticed that  most components are of the order 10^-13 or smaller - only a handful are mucgh larger\n",
    "            eigenvector[index] = 0.0\n",
    "        else:\n",
    "            non_zero_count += 1\n",
    "        binary_basis = index_to_binary(index, N)\n",
    "        print(f\"{binary_basis}: {eigenvector[index]}\")\n",
    "\n",
    "    print(f\"Total Non-Zero Components in Scarred Eigenvector {i}: {non_zero_count}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over scarred eigenvectors\n",
    "for i, eigenvector in enumerate(red_eigenvectors_np):\n",
    "    print(f\"Scarred Eigenvector {i}:\")\n",
    "    \n",
    "    # Dictionary to track processed coefficients\n",
    "    processed_coeffs = set()\n",
    "    \n",
    "    # Iterate over components of the eigenvector\n",
    "    for index, component in enumerate(eigenvector):\n",
    "        if np.abs(component) > 1e-12:  # Check if the component is non-zero\n",
    "            binary_basis = index_to_binary(index, N)\n",
    "            coeff = component\n",
    "            \n",
    "            # Skip if this coefficient (or its negative) has already been processed\n",
    "            if coeff in processed_coeffs or -coeff in processed_coeffs:\n",
    "                continue\n",
    "            \n",
    "            # Count the number of 1's in the binary representation\n",
    "            num_ones = binary_basis.count('1')\n",
    "            \n",
    "            # Print the coefficient, binary representation, and number of 1's\n",
    "            print(f\"  Coefficient: {coeff}\")\n",
    "            print(f\"    Binary Representation: {binary_basis}\")\n",
    "            print(f\"    Elements [0, 4, 5, 9]: {binary_basis[0]}, {binary_basis[4]}, {binary_basis[5]}, {binary_basis[9]}\")\n",
    "            print(f\"    Number of 1's: {num_ones}\")\n",
    "            \n",
    "            # Check for the negative of the coefficient\n",
    "            for j, other_component in enumerate(eigenvector):\n",
    "                if np.abs(other_component + coeff) < 1e-10:  # Compare with tolerance\n",
    "                    binary_basis_neg = index_to_binary(j, N)\n",
    "                    num_ones_neg = binary_basis_neg.count('1')\n",
    "                    print(f\"  Negative Coefficient: {-coeff}\")\n",
    "                    print(f\"    Binary Representation: {binary_basis_neg}\")\n",
    "                    print(f\"    Elements [0, 4, 5, 9]: {binary_basis_neg[0]}, {binary_basis_neg[4]}, {binary_basis_neg[5]}, {binary_basis_neg[9]}\")\n",
    "                    print(f\"    Number of 1's: {num_ones_neg}\")\n",
    "                    break\n",
    "            \n",
    "            # Mark this coefficient and its negative as processed\n",
    "            processed_coeffs.add(coeff)\n",
    "            processed_coeffs.add(-coeff)\n",
    "    \n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store even swaps numbers\n",
    "even_swaps_numbers = []\n",
    "\n",
    "# Dictionary to track spin exchange arrays and their counts\n",
    "spin_exchange_counts = {}\n",
    "\n",
    "# Iterate over scarred eigenvectors\n",
    "for i, eigenvector in enumerate(red_eigenvectors_np):\n",
    "    print(f\"Scarred Eigenvector {i}:\")\n",
    "\n",
    "    # Dictionary to track processed coefficients\n",
    "    processed_coeffs = set()\n",
    "\n",
    "    # Iterate over components of the eigenvector\n",
    "    for index, component in enumerate(eigenvector):\n",
    "        if np.abs(component) > 1e-12:  # Check if the component is non-zero\n",
    "            binary_basis = index_to_binary(index, N)\n",
    "            coeff = component\n",
    "\n",
    "            # Skip if this coefficient (or its negative) has already been processed\n",
    "            if coeff in processed_coeffs or -coeff in processed_coeffs:\n",
    "                continue\n",
    "\n",
    "            # Check for the negative of the coefficient\n",
    "            for j, other_component in enumerate(eigenvector):\n",
    "                if np.abs(other_component + coeff) < 1e-10:  # Compare with tolerance\n",
    "                    binary_basis_neg = index_to_binary(j, N)\n",
    "\n",
    "                    # Identify the spins that are exchanged\n",
    "                    spin_exchange = [\n",
    "                        k for k in range(N) if binary_basis[k] != binary_basis_neg[k]\n",
    "                    ]\n",
    "\n",
    "                    # Compute swaps number\n",
    "                    swaps_number = len(spin_exchange) // 2\n",
    "\n",
    "                    # Check if swaps number is odd\n",
    "                    is_odd = swaps_number % 2 == 1\n",
    "\n",
    "                    print(f\"  Coefficient: {coeff}\")\n",
    "                    print(f\"    Binary Representation: {binary_basis}\")\n",
    "                    print(f\"  Negative Coefficient: {-coeff}\")\n",
    "                    print(f\"    Binary Representation: {binary_basis_neg}\")\n",
    "                    print(f\"    Spin Exchange: {spin_exchange}\")\n",
    "                    print(f\"    Swaps Number: {swaps_number} (Odd: {is_odd})\")\n",
    "\n",
    "                    # Add to even swaps numbers if swaps number is even\n",
    "                    if not is_odd:\n",
    "                        even_swaps_numbers.append(swaps_number)\n",
    "\n",
    "                    # Track spin exchange arrays\n",
    "                    spin_exchange_tuple = tuple(spin_exchange)\n",
    "                    if spin_exchange_tuple in spin_exchange_counts:\n",
    "                        spin_exchange_counts[spin_exchange_tuple] += 1\n",
    "                    else:\n",
    "                        spin_exchange_counts[spin_exchange_tuple] = 1\n",
    "\n",
    "                    break\n",
    "\n",
    "            # Mark this coefficient and its negative as processed\n",
    "            processed_coeffs.add(coeff)\n",
    "            processed_coeffs.add(-coeff)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# Print the list of even swaps numbers\n",
    "print(\"Even swaps numbers:\", even_swaps_numbers)\n",
    "\n",
    "# Check for repeated spin exchange arrays\n",
    "repeated_spin_exchanges = [\n",
    "    spin_exchange for spin_exchange, count in spin_exchange_counts.items() if count > 1\n",
    "]\n",
    "if repeated_spin_exchanges:\n",
    "    print(\"Repeated spin exchange arrays:\", repeated_spin_exchanges)\n",
    "else:\n",
    "    print(\"No repeated spin exchange arrays found.\")\n",
    "\n",
    "print(len(spin_exchange_counts), \"spin exchange arrays found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_scar\n",
    "\n",
    "non_zero_count = 0  # Counter for non-zero components\n",
    "\n",
    "for index, component in enumerate(min_scar):\n",
    "    # Set components of the order 10^-12 or smaller to zero\n",
    "    if np.abs(component) < 1e-12: # I noticed that  most components are of the order 10^-13 or smaller - only a handful are mucgh larger\n",
    "        min_scar[index] = 0.0\n",
    "    else:\n",
    "        non_zero_count += 1\n",
    "    binary_basis = index_to_binary(index, N)\n",
    "    print(f\"{binary_basis}: {np.real(min_scar[index])}\")\n",
    "\n",
    "print(f\"Total Non-Zero Components in min_scar: {non_zero_count}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if other states have 280 non-zero components - it's only the 5 scars!\n",
    "\n",
    "# Count distinct non_zero_count values\n",
    "distinct_counts = set()\n",
    "\n",
    "# Counter to track occurrences of each non_zero_count\n",
    "non_zero_count_occurrences = Counter()\n",
    "\n",
    "# Iterate over all eigenvectors\n",
    "for i in range(eigenvectors.shape[1]):\n",
    "    eigenvector = eigenvectors[:, i]\n",
    "    non_zero_count = 0  # Counter for non-zero components\n",
    "    \n",
    "    # Count non-zero components\n",
    "    for component in eigenvector:\n",
    "        if np.abs(component) >= 1e-12:\n",
    "            non_zero_count += 1\n",
    "    \n",
    "    # Update the counter\n",
    "    non_zero_count_occurrences[non_zero_count] += 1\n",
    "    print(f\"Total Non-Zero Components in Eigenvector {i}: {non_zero_count}\")\n",
    "\n",
    "# Print the number of distinct non_zero_count values\n",
    "print(f\"Number of distinct non_zero_count values: {len(non_zero_count_occurrences)}\")\n",
    "print(f\"Distinct non_zero_count values: {sorted(non_zero_count_occurrences.keys())}\")\n",
    "\n",
    "# Print how many times each distinct non_zero_count appears\n",
    "print(\"Occurrences of each non_zero_count:\")\n",
    "for count, occurrences in sorted(non_zero_count_occurrences.items()):\n",
    "    print(f\"Non-Zero Count: {count}, Occurrences: {occurrences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#find a 4/5 spins charge commuting with the rdm - let's first use quantum channel to derive the effective action of the global C5 symmetry operator on the 4 spins subsystem:\n",
    "\n",
    "##   rho4' = Tr_8[C5 (rho4 cross rho8) C5^dagger], and compare it to rho4\n",
    "##   C5^4 = Tr_8[C5 (I4 cross rho8)] --- not sure if this is correct, but let's try it anyway\n",
    "\n",
    "# let's first find rho8 - we already have rho4 and C5=P\n",
    "\n",
    "###### USELESS ############\n",
    "\n",
    "# Compute RDM on the complement of keep_qubits for scarred eigenstates\n",
    "complement_rdms = []  # List to store RDMs on the complement of keep_qubits\n",
    "\n",
    "# Define the complement of keep_qubits\n",
    "all_qubits = set(range(N))\n",
    "for i in red_indices_np:\n",
    "    min_eigenvector = eigenvectors[:, i]\n",
    "    density_matrix = np.outer(min_eigenvector, min_eigenvector.conj())\n",
    "    density_matrix_qobj = Qobj(density_matrix, dims=[[2]*N, [2]*N])\n",
    "\n",
    "    # Complement of keep_qubits\n",
    "    complement_qubits = list(all_qubits - set(keep_qubits))\n",
    "\n",
    "    # Trace out the complement qubits\n",
    "    traced_out_complement = ptrace(density_matrix_qobj, complement_qubits)\n",
    "\n",
    "    # Convert the result back to a dense matrix if needed\n",
    "    traced_out_complement_dense = traced_out_complement.full()\n",
    "    complement_rdms.append(traced_out_complement_dense)\n",
    "\n",
    "    # Compute the trace of the complement RDM\n",
    "    trace_value = np.trace(traced_out_complement_dense)\n",
    "\n",
    "    # Check if the complement RDM is Hermitian\n",
    "    is_hermitian = np.allclose(traced_out_complement_dense, traced_out_complement_dense.conj().T)\n",
    "\n",
    "    # Print the results for debugging\n",
    "    print(f\"Complement RDM for eigenstate {i}:\")\n",
    "    print(f\"Shape: {traced_out_complement_dense.shape}\")\n",
    "    print(f\"Trace: {trace_value}\")\n",
    "    print(f\"Is Hermitian: {is_hermitian}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Now `complement_rdms` contains the RDMs on the complement of keep_qubits for all scarred eigenstates\n",
    "\n",
    "# full P=C5\n",
    "\n",
    "P = dok_matrix((2**N, 2**N), dtype=np.float64)\n",
    "\n",
    "# Go through all basis states\n",
    "for index in range(2**N):\n",
    "    # Convert index to spin bits\n",
    "    state_bits = list(map(int, np.binary_repr(index, width=N)))\n",
    "    \n",
    "    # Apply the permutation\n",
    "    new_bits = apply_permutation(state_bits, N, perm)\n",
    "    \n",
    "    # Convert back to integer index\n",
    "    new_index = int(\"\".join(map(str, new_bits)), 2)\n",
    "    \n",
    "    # Set the permutation matrix entry\n",
    "    P[new_index, index] = 1.0\n",
    "\n",
    "# Optionally convert to CSR format for efficient multiplication\n",
    "P = P.toarray()\n",
    "\n",
    "print(\"Permutation matrix P constructed with shape:\", P.shape)\n",
    "\n",
    "# first attempt for the effective 4-spins operator C5^4\n",
    "\n",
    "C5_4s = []\n",
    "\n",
    "P_qobj = Qobj(P, dims=[[2]*N, [2]*N])\n",
    "\n",
    "\n",
    "for i in range(len(complement_rdms)):\n",
    "    rho8 = complement_rdms[i]\n",
    "    # Convert rho8 (NumPy matrix) back to Qobj\n",
    "    rho8_qobj = Qobj(rho8, dims=[[2] * (N - len(keep_qubits)), [2] * (N - len(keep_qubits))])\n",
    "\n",
    "    # Define subsystem dimensions\n",
    "    dim_A = 2**(len(keep_qubits))   # e.g., 4 spins → dimension 16\n",
    "    dim_B = rho8_qobj.dims[0][0]  # This should be 2**(N-4) for N spins total\n",
    "\n",
    "    # Identity on subsystem A\n",
    "    IA_qobj = qeye(dim_A)\n",
    "    IA = np.eye(dim_A, dtype=np.float64)  # Identity matrix for subsystem A\n",
    "\n",
    "    # Build the product state (I_A ⊗ rhoB)\n",
    "    #IA_rho8 = tensor(IA, rho8_qobj)\n",
    "    IA_rho8 = np.kron(IA, rho8)  # Kronecker product of I_A and rhoB\n",
    "    IA_rho8_qobj = Qobj(IA_rho8, dims=[[2] * N, [2] * N])\n",
    "\n",
    "    # Print dimensions\n",
    "    print(f\"Dimension of IA: {IA.shape}\")\n",
    "    print(f\"Dimension of rho8_qobj: {rho8.shape}\")\n",
    "    print(f\"Dimension of IA_rho8: {IA_rho8_qobj.dims}\")\n",
    "\n",
    "    # Apply global C5 (P) to this state\n",
    "    U_rho = P_qobj * IA_rho8_qobj\n",
    "\n",
    "    # Partial trace over subsystem B → result acts on subsystem A\n",
    "    # If A is the first subsystem in the tensor product, trace out B (which is subsystem 1)\n",
    "    #C5_4 = ptrace(U_rho, 0)  # 0 → subsystem A (remaining after tracing out B)\n",
    "    C5_4 = ptrace(U_rho, keep_qubits)  # Trace out the complement of keep_qubits\n",
    "\n",
    "    # Now C5_tilde is the effective operator acting on subsystem A (4 spins)\n",
    "    C5_4s.append(C5_4.full())  # Convert to dense matrix if needed\n",
    "    print(f\"Effective operator C5^4 for eigenstate {i}:\")\n",
    "    print(f\"Shape: {C5_4.shape}\")\n",
    "\n",
    "for i in range(len(C5_4s)):\n",
    "    print(f\"Effective operator C5^4 for eigenstate {i}:\")\n",
    "    print(f\"Shape: {C5_4s[i].shape}\")\n",
    "    print(C5_4s[i])\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Compute commutators between each C5_4 and the corresponding rho4\n",
    "commutators = []\n",
    "\n",
    "for i in range(len(C5_4s)):\n",
    "    # Convert rho4 (min_rdms) to a dense matrix if needed\n",
    "    rho4 = min_rdms_np[i]  # Corresponding reduced density matrix (rho4)\n",
    "    C5_4 = C5_4s[i]     # Corresponding effective operator (C5_4)\n",
    "\n",
    "    # Compute the commutator: [C5_4, rho4] = C5_4 * rho4 - rho4 * C5_4\n",
    "    commutator = np.dot(C5_4, rho4) - np.dot(rho4, C5_4)\n",
    "    commutators.append(commutator)\n",
    "\n",
    "    # Print the commutator for debugging\n",
    "    print(f\"Commutator for scar {i}:\")\n",
    "    print(commutator)\n",
    "    print(f\"Norm of commutator: {np.linalg.norm(commutator)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Now `commutators` contains the commutators for all eigenstates\n",
    "\n",
    "rho4Us = []\n",
    "\n",
    "for i in range(len(complement_rdms)):\n",
    "\n",
    "    rho4 = min_rdms_np[i]\n",
    "    # Convert rho4 (NumPy matrix) back to Qobj\n",
    "    rho4_qobj = Qobj(rho4, dims=[[2] * (len(keep_qubits)), [2] * (len(keep_qubits))])\n",
    "\n",
    "    rho8 = complement_rdms[i]\n",
    "    # Convert rho8 (NumPy matrix) back to Qobj\n",
    "    rho8_qobj = Qobj(rho8, dims=[[2] * (N - len(keep_qubits)), [2] * (N - len(keep_qubits))])\n",
    "\n",
    "    # Build the product state (rhoA ⊗ rhoB)\n",
    "    rho4_rho8 = np.kron(rho4, rho8)  # Kronecker product of rhoA and rhoB\n",
    "    rho4_rho8_qobj = Qobj(rho4_rho8, dims=[[2] * N, [2] * N])\n",
    "\n",
    "    # Apply C5 and its adjoint to this state\n",
    "    U_rho_U = P_qobj * rho4_rho8_qobj * (P_qobj).dag()\n",
    "\n",
    "    # Partial trace over subsystem B → result acts on subsystem A\n",
    "    rho4U = ptrace(U_rho_U, keep_qubits)  # Trace out the complement of keep_qubits\n",
    "\n",
    "    # rho4U is the 4 spins rdm after effective action of C5 on subsystem A (4 spins)\n",
    "    rho4U_dense = rho4U.full()  # Convert to dense matrix if needed\n",
    "    rho4Us.append(rho4U_dense)\n",
    "\n",
    "    # Check trace\n",
    "    trace_value = np.trace(rho4U_dense)\n",
    "    print(f\"Trace of rho4U for eigenstate {i}: {trace_value}\")\n",
    "\n",
    "    # Check if Hermitian\n",
    "    is_hermitian = np.allclose(rho4U_dense, rho4U_dense.conj().T)\n",
    "    print(f\"Is rho4U Hermitian for eigenstate {i}: {is_hermitian}\")\n",
    "\n",
    "    print(f\"rho4U for eigenstate {i}:\")\n",
    "    print(f\"Shape: {rho4U_dense.shape}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "for i in range(len(rho4Us)):\n",
    "    norm_rho4U = np.linalg.norm(rho4Us[i], ord='fro')  # Frobenius norm\n",
    "    print(f\"Norm of rho4U for eigenstate {i}: {norm_rho4U}\")\n",
    "    norm_rho4 = np.linalg.norm(min_rdms_np[i], ord='fro')  # Frobenius norm\n",
    "    print(f\"Norm of rho4 for eigenstate {i}: {norm_rho4}\")\n",
    "    distance = np.linalg.norm(rho4Us[i] - min_rdms_np[i], ord='fro')  # Frobenius norm\n",
    "    print(f\"Distance between rho4U and rho4 for eigenstate {i}: {distance}\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
